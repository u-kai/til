Culture of Data Curiosity and Experimentation One of the most notable changes in Daff is the ubiquitous culture that dares to obsessively ask, “What if …”: what if we could make a change to make things just a little bit better? There is a culture that obsessively
runs experiments, observes the results, analyzes the data, makes sense of it, learns from it, and adapts. This culture is built on a technical foundation that has just made it so easy for everyone to dare to try: try big experiments with applied machine learning or little ones just tweaking user interface features. Daff is organized around business units that it refers to as domains. The player domain focuses on the core music player used on mobile devices, the partnership domain works with business partners such as exercise applications and art venues, and the playlist domain investigates advanced approaches for generating playlists. Each domain combines software development and broader business capabilities and is responsible for the software components that support that domain. Walking around Daff you notice that at any point in time, there are many concurrent experiments being run by each domain to improve their applications and services. For example, player teams are continuously experimenting with better engagement with users. The partnership domain team is experimenting with data captured from a variety of external sources such as exercise platforms, art venues, etc. The playlist teams keep applying more advanced machine learning in curating and recommending engaging compilations. And the artist domain team is utilizing machine learning to discover, attract, and onboard artists who normally would have gone unnoticed. Every domain of the business and their collaborating technology teams have a deep appreciation for meaningful, trustworthy, and secure data. Not only that, everyone has an expectation that on-demand access to data across the organization is a norm. They know their role in making that happen. They are all responsible for data and have a stake in it. Every domain is enthusiastically applying machine learning models wherever the feature or the function of the domain can be implemented through the exploitation of past data and patterns in it. For example, the playlist teams are using generative machine learning models to create weird and wonderful compilations. The compilations are targeted for different activities, from running to focusing on learning. The artist team is exploiting multiple datasets from social media and other agencies outside of Daff to detect emerging artists and onboard, promote, and connect them with their new audience.
You can feel the enthusiasm around data usage and learning a new reality that allows for the creation and discovery of signals that would have been just noise to our human senses.4 Data culture before data mesh This culture vastly contrasts what Daff was three years ago. Data collection, experimentation, and intelligence were outsourced to a separate data team. The data team was under sheer pressure. Domains did not have trust in the data, or often couldn’t find the data they needed. The data team was always playing catchup, either chasing the data pipeline havoc caused by every little change in upstream applications and their databases or trying to meet the needs of the impatient domains needing a data solution yesterday. The domains themselves had taken no responsibility and interest in making data readily available, reliable, and usable. The lead time and friction to get to the right data made it incredibly difficult for domains to dare imagine new experiments. Comparing the two experiences shows how far Daff has come in three years after their pivot to data mesh. An Embedded Partnership with Data and ML The data experimentation culture just seems too good to be true. To see what it looks like in practice, let’s follow the story of a recent data-driven business feature Daff has worked on and follow the experience of the people involved. Smart music playlists have been a successful feature of the Daff platform. The music playlist domain has worked on multiple ML models that cross-correlate data from a variety of sources to recommend better-matched playlists for listeners, depending on where they are, what they’re doing, where their interest lies, and what the occasion is. The playlist ML models exploit patterns in analytical data products from a variety of sources across the organization such as: Data shared by the listener domain, listener profiles, listener social networks, listener locations, etc., to understand the context and cohorts of listeners. Data shared by the player domain, play sessions and play events, to understand the behavior and preferences of listeners on their player devices.
Data from the music album domain, music tracks, and music profiles, to get an understanding of the profiles and classifications of music tracks. There are multiple trained machine learning models that generate smart playlists such as monday playlists, sunday morning playlists, focus playlists, and so on. The playlist team shares these continuously improved compilations as data products to other teams. Data as a product is a well-established concept that refers to data shared following Daff’s established data sharing standards. Data products are automatically accessible through the global data discovery tool. They share and guarantee a set of service-level objectives (SLOs), such as how often each playlist is refreshed, its accuracy, and timeliness. They have up-to-date and easy to understand documentation. In short, data products are high-quality data available to users with the right access permissions, and they are easy to understand and use. The player domain team that focuses on the presentation of content to listeners across different player user interfaces—such as mobile, desktop, car, etc.—is one of the main users of the playlist data products. They continuously consume the latest and greatest playlists and present them to the listeners. The playlist team is planning to advance their models to recommend a new variety of playlists for different sports activities, e.g., running playlists, cycling playlists, and so on. They need to find existing data that has information about music that listeners have liked and played during sports activities. To get started, the playlist team goes to the mesh discovery portal and searches for all data products that might have something related to sports activities. Through the discovery mechanism they find that the partnership domain has some data related to this. The discovery tool allows the team to automatically get access to documentation, sample code, and more information about the data products. They automatically request access and get a connection to the partnership data products and examine sample datasets. While they find some useful data involving joint members (listeners who are members of partner workout platforms), they don’t find any information about the music they listen to or like on those platforms when they run, cycle, or do yoga. The playlist team gets in contact with the partnership data product owner. Each domain has a dedicated product owner who focuses on the data shared by that domain. Through a direct conversation they let the partnership team know that they need to get access to the music tracks that workout platforms play during different activities as well as the ones that their members like. This conversation leads to the prioritization of creating partner playlists data products. The partnership business team’s purpose is to create a better experience for listeners through seamless integration with partner platforms such as the workout platforms and sharing music. Creating partner playlists data products is aligned with their business objective. The partnership team is best positioned to create these data products. They work most closely with partner platforms and are aware of their integration APIs and the life cycle of those APIs, which directly feed the partner playlists data products. Given the self-serve data infrastructure and platform capabilities that Daff has built over the course of the last three years, it is fairly simple for the partnership team to create new data products. They start working with one of the most popular cycling and workout partners and use their APIs to access the tracks their members have played and liked. The partnership team uses the platform data product life cycle management tools to build the transformation logic that presents this data as a data product in multiple modes, near-real-time snapshots of delta files initially. To make the integration of partner playlists with other data products easier, the transformation code focuses on harmonizing the music track ID with the global track ID system that Daff uses across all data products. In the span of a few hours, they have the new partner playlists data product built and deployed to the mesh, and made available to the playlist teams to continue their experiment. In this simple scenario there are a few fundamentals of data mesh principles at play: one is the decentralized domain ownership of data5 to remove the gap between data users and data providers, in this case allowing the playlist domain to work directly with the partnership domain, with each team having long-term accountability for providing data, playlists, and partner playlists. The culture and technology of treating data as a product6 is the second principle of data mesh we see in action. The teams have the responsibility to provide data that is easily discoverable, understandable, accessible, and usable, known as data products. There are established roles such as data product owners in each cross-functional domain team that are responsible for data and sharing it successfully. The feasibility of sharing new partner playlists data products in a span of a few hours or maybe at most a day or two and the possibility of discovering the right data and using it without friction are all dependent on the self-serve data platform.7 The platform provides services to cross-functional teams for sharing and using data, and it paves the path to efficiently and securely create and share data products for that purpose. For example, automated access control, encryption of personal information by default, and registering all data products with a global discovery tool are among the platform services. Daff depends on a well-established set of governance policies to share data confidently and effectively. For example, a collective understanding around who should own what data is an example of such a policy. In this case, the partnership team became the owners of partner playlists. They are the team closest to the source and control the relationship with the partners. They are closely aware of factors that impact partnership data. While this appeared to be a simple and organic decision, it was made based on a set of heuristics that Daff had established to govern the policy of “assigning long-term owners to data products.” A federated group of domain representatives defines the policies and the data platform automates them. This is data mesh’s federated computational governance8 principle. Daff has come a long way to arrive at this seamless and frictionless journey. Figure P-1 shows this peer-to-peer and decentralized collaboration.
Data work before data mesh The same scenario three years ago would have faced weeks of work, many points of friction and bottlenecks, and multiple handovers across multiple teams, likely resulting in poor quality data. Three years ago, the expected length of the effort and all the friction likely inhibited the initiative from starting, leaving it abandoned or in the best case costing a lot more. Three years ago, the playlist team would have needed to ask a central data and AI team to prioritize building and training a new model for sports playlists. The data scientists within the central data and AI team would have needed to prioritize this among many other ML-based initiatives demanded across the organization. In the best-case scenario of highly prioritizing the playlists request, the data scientists would have had to go to a centralized lake or warehouse team for data and request access to the data from a centralized governance team. This would have added another few days. Even then, after finding the data, it was likely that data scientists couldn’t quite understand the data. The data would have been stale, as the partnership team had established
many new integrations that hadn’t yet made it to the central warehouse or lake. The central data scientist team likely had trust issues with the data. After realizing that data scientists needed more music-related data from partners, the data lake team would have needed to go to a data engineering team in charge of pipelines to get the new extract, transform, load/extract, load, transform (ETL/ELT) pipelines set up to get data from partner integration APIs and get them to the warehouse or lake, yet another backlog to get stuck behind. The centralized data engineering teams had to spend days negotiating and understanding a completely new domain, the partnership domain, to get the data from their application databases into the pipeline and then into the lake. They had to understand their internal databases to map internal music IDs to the global ID, among other internal application nuances. This would have taken some more time. Without direct involvement and understanding of the business case, the partnership team had low incentives to prioritize high-quality partnership music integration9 and support the data engineers’ ETL pipelines. The ad hoc integrations faced days of debugging until some data flew into the lake. And the saga continues. Daff’s functionally divided organizational design and technology was simply not conducive to data-driven experimentation.10 Figure P-2 shows Daff ’s organizational structure and architecture before data mesh. They had a modern software development architecture and organization structure as they had aligned their business and technology development teams around autonomous domains. However, their data and analytics team and architecture were functionally divided and centralized, using the monolithic architecture of the lake and warehouse. The central data team and the monolithic architecture had become a bottleneck in response to the proliferation of data sources—inside and outside of the company—and diversity of their use cases. The data team had been under a large amount of pressure and had substantially slowed down in response to the growth of Daff. The returns of investments had now plateaued. In short, Daff’s data team structure and architecture were out of step with its aspirations and organizational growth.11
The Invisible Platform and Policies Post data mesh, in the sports playlist scenario I just shared with you, the experience of data users and providers almost feels magical: no friction, rapid end-to-end results, a sense of shared accountability with clear boundaries of responsibilities. For this to be remotely possible, Daff has created a set of self-service technologies and automations that feel native to use and almost invisible. Beneath the experience of the data providers and data users, to rapidly and autonomously share data, sits a platform composed of self-service capabilities that enable a set of key experiences: The experience of building, deploying, monitoring, and evolving data products In this example, the data platform facilitated a frictionless experience to create and evolve partner playlists and sports playlists data products in a short amount of time, including integration with the source, building and testing the data transformation code, and serving the data.
The experience of working with a mesh of data products as a whole In this case, the platform services enable searching and discovering data products, connecting to them, querying their data, subscribing to their evolving data changes, and joining and correlating multiple data products to create new and novel playlists. These experience-based capabilities of the platform are optimized for the users—data product developers, owners, users—to minimize their cognitive load in data sharing and experimentation. For Daff, it is not acceptable to optimize the users’ experience—data product developers and users—at the cost of machine deoptimization. The invisible part of the platform, closer to the physical layer and further away from the user, takes care of physical and machine optimizations. While the platform’s experience plane—a set of cohesive services—optimizes the user experience to work with autonomous and yet connected data products, the utility plane of the platform optimizes physical and machine-level performance.12 For example, it supports: Efficient polyglot storage of data products Efficient query and workload processing across data products Efficient search and indexing Reduced data movement The seamless experience of the playlist team using and correlating multiple data products sourced from different teams such as partnerships, listeners, and music profiles depends on a set of global standard policies governing all data products:13 Standardization of data sharing APIs Standardization of metadata including SLOs, documentation, and data modeling language Standardization of shared data entity IDs Limitless Scale with Autonomous Data Products Data mesh meets Daff’s growth aspirations with a scale-out organizational and technical structure. As you saw in the example of smart playlists, the introduction of new playlists or improving existing ones
is simply a matter of adding more data products and connecting them, e.g., running playlists, cycling playlists, workout platform X partner playlists, workout platform Y partner playlists, etc. This is a scale-out architecture where you can achieve limitless scale by adding more coequal nodes and connecting them with each other. Data products are implemented as an architecture quantum, the smallest unit of an architecture that can be deployed independently and still have all the structural components to do its job. The architecture assures that each data product implements a standard set of contracts for data access and data sharing in a way that each can connect to other data quanta on the mesh to share data and semantics. Each data product encapsulates the data transformation logic and policies that govern their data. The architecture matches the domain-oriented organizational autonomy, with a corresponding data-product-oriented distributed architecture. Daff’s standardization of data products has given it speed and scale.14 The Positive Network Effect The success of Daff in using data and analytics can be summarized by the positive network effect created by peer-to-peer connectivity of domains exchanging data products as units of value. The larger the network and the more connections established, the more data that is shared between domains to generate intelligence and high-order insights, ultimately improving the business. Daff has invested significantly to execute its data mesh strategy, making an organizational and cultural shift and creating the infrastructure and platform foundation. But they have been diligent in tracking the return of their investment with measurable benefits. Based on their measurements, externally, they have created deeper user engagement and have grown the number of active listeners by applying ML and data to improve the listeners’ experience across multiple touchpoints. Internally, they have reduced the lead time to access data by removing central and middleman bottlenecks. They have reduced the risk of change of data by creating standard contracts and interfaces for discovering and sharing data products. They have reduced the waste of developing data products by adopting automated continuous delivery practices for data products. They have increased the application of data
across the business measured by the amount of connectivity between their data products. They have increased the number of teams engaged in creating data-driven solutions by embedding the ownership of data in each domain and team. They reduced the cost of data ownership and end-to-end data solution creation by utilizing the platform services and focusing on the experience of data developers. These are some of the areas of improvement that they measure against their data mesh investments.15 Why Transform to Data Mesh? Let’s go back to the year 2019, the year of an inflection point for Daff.16 Over the last few years, Daff had substantially invested in their data solutions such as data lakes and data warehousing to capture data at scale. They had built a large data and AI team under the chief data and AI officer who had been charged with organizational-wide data capture, modeling, and serving, as well as building analytical and ML solutions the business needed. The organizational structure and operating model that Daff had adopted was the industry standard at the time. This was the year that Daff reflected and realized that their data aspirations had outgrown their ability to execute on them. The central data team and the monolithic architecture had become a bottleneck in response to the proliferation of data sources—inside and outside of the company—and diversity of their use cases. The data team was under a large amount of pressure and had substantially slowed down in response to the growth of Daff. The returns of investments had now plateaued. They needed to change, and that was when they discovered data mesh. Before embarking on data mesh, Daff looked closely at the alignment between their business—goals, organization, technical capabilities—and data mesh. The expected outcomes of data mesh were aligned with addressing their pain points: Rapid growth and increased complexity They were growing fast, their business was becoming more complex, and implementing their diverse and audacious analytical aspirations was becoming slow. Data mesh is designed to get value from data and retain agility in complex and large environments.
Getting value from data at scale They were making substantial investments on their technical foundation for data and analytics and yet the results were plateauing. Data mesh gets value from data more cost effectively by mobilizing the larger population of generalist technologists to become data developers and users. The objectives of data mesh and the overall scope of the impact sounded promising. However, there was a question of whether this was the right choice for them, right now, given the context of Daff. The answer to this question was promising. Data mesh was compatible with the existing domain-oriented organizational design of Daff. It was an extension to their existing design and architecture. Data mesh built up on a decentralized model of data ownership that simply extended their existing business-aligned development teams. In reality, the centralized data team was one of the last functionally divided teams, somewhat at odds with their current domain-oriented business and tech organizational design. Given their aspirations to make every domain data-driven and embed intelligent decision making in them, it made sense to move the ownership of data and analytics to domains. The company was already operating with business-dev-ops domain-aligned teams, so the extension of these teams with data capabilities and responsibilities seemed like a natural progression to truly democratize access and utilization of data. Naturally, governance needed to follow these organizational seams too. They knew that as a lead adopter of data mesh, they needed to dedicate their time and resources to building the foundational technology and enabling platforms. Daff viewed itself as a software company with technology at its core, not only enabling its business but shaping and extending it. They didn’t shy away from technical investments.17 Daff realized that implementing a new approach—encompassing changes to data culture, data organizational structure, data roles, data architecture, and technology—was going to be a multiyear transformation. So, they dedicated the next three years to make the pivot to data mesh incrementally. Throughout the journey they delivered carefully selected data-driven use cases, while transforming the organization and establishing the platform and the technology.18 The Way Forward Despite the business, cultural, and technical successes, Daff has a way to go. Their evolution of data mesh execution has certainly passed the phases of exploration, which established the ways of working and the foundational platform. They have expanded the mesh to many of their domains. However, to continue to extract value from the mesh, they need to continuously optimize and refine their approach. They need to work on domains that are laggards in becoming active members of the mesh and extend their platform capabilities to domains that work with legacy systems and don’t yet work in a domain-oriented cross-functional team. This is the expected trajectory of data mesh transformation: an evolutionary path, punctuated with repeating cycles of explore, expand, and extract.19 I hope the tale of data mesh at Daff has nudged you to keep reading past this point, in which case I will see you in the next chapter.

データの好奇心と実験の文化「もしも...」と問いかけ、ものを少しでも良くするために変化を起こせるのではないかという挑戦的な文化が Daff にはあります。実験を繰り返し、その結果を観察し、データを分析し、それを理解し、学び、適応するという文化があります。この文化は、技術的な基盤に基づいて構築されており、誰もが大規模な機械学習を用いた実験や、ユーザーインターフェースの微調整など、試してみることに躊躇しないようになったのです。Daff は、ドメインと呼ばれるビジネスユニットを中心に組織されています。プレイヤードメインは、モバイルデバイスで使用されるコアの音楽プレイヤーに焦点を当て、パートナーシップドメインは、エクササイズアプリやアート会場などのビジネスパートナーと協力し、プレイリストドメインは、プレイリストの生成における高度な手法を調査しています。各ドメインは、ソフトウェア開発と広範なビジネス能力を組み合わせ、そのドメインをサポートするソフトウェアコンポーネントに責任を持っています。Daff を歩いていると、いつでも各ドメインで同時に多くの実験が行われていることに気付きます。例えば、プレイヤーチームはユーザーとの関与をより良くするために継続的に実験を行っています。パートナーシップドメインチームは、エクササイズプラットフォームやアート会場などさまざまな外部ソースからキャプチャされたデータを実験しています。プレイリストチームは、より高度な機械学習を用いて興味を引くコンピレーションを作成し、推奨しています。そして、アーティストドメインチームは、通常注目されなかったアーティストを発見し、引き付け、受け入れるために機械学習を活用しています。ビジネスの各ドメインと協力するテクノロジーチームは、意味のある信頼性の高い安全なデータに対する深い理解を持っています。それだけでなく、組織全体でデータにオンデマンドでアクセスできることを当然のこととして期待しています。彼らはその実現に向けた役割を知っています。彼らはすべてデータに責任を持ち、それに参加しています。すべてのドメインは、過去のデータやその中のパターンを利用してドメインの機能や特徴が実装される場所では、積極的に機械学習モデルを適用しています。例えば、プレイリストチームは生成型の機械学習モデルを使用して奇妙で素晴らしいコンピレーションを作成しています。コンピレーションは、ランニングから学習に焦点を当てたさまざまな活動に向けてターゲットされています。アーティストチームは、Daff の外部のソーシャルメディアや他の機関から複数のデータセットを活用し、新たな視聴者にアーティストを紹介し、プロモーションを行い、接続します。
データの使用と新たな現実の学習に対する熱意が感じられます。それは、私たちの人間の感覚ではただのノイズでしかなかった信号の創造と発見を可能にすることができるのです。4 データメッシュ前のデータ文化 この文化は、3 年前の Daff とは大きく異なります。データの収集、実験、インテリジェンスは、別のデータチームに外部委託されていました。データチームは非常な圧力にさらされていました。ドメインはデータを信頼しておらず、必要なデータを見つけることができないことも多かったのです。データチームは常にデータパイプラインの混乱に追い立てられており、上流アプリケーションやデータベースのささいな変更によって引き起こされる問題を解決するか、昨日中にデータの解決策を求めるドメインの要求を満たすために努力していました。ドメイン自体は、データを利用可能で信頼性があり使いやすい状態にするための責任や関心を持っていませんでした。正しいデータに到達するまでのリードタイムと摩擦は、ドメインが新たな実験を想像することを非常に困難にしていました。これらの 2 つの経験を比較すると、データメッシュへの転換から 3 年後の Daff がどれだけ進歩したかがわかります。データと機械学習との組み込まれたパートナーシップ データの実験文化はあまりにも良くて信じられないほどです。実際にどのような様子かを見るために、最近のデータ駆動型ビジネス機能の Daff での取り組みのストーリーを追い、関わる人々の経験を追ってみましょう。スマートミュージックプレイリストは、Daff プラットフォームの成功した機能です。音楽プレイリストドメインは、さまざまなソースからのデータを相互に関連付けて、リスナーによりマッチしたプレイリストをおすすめするための複数の ML モデルを開発してきました。それは、彼らがどこにいるか、何をしているか、彼らの関心がどこにあるか、そしてどんな機会かに応じて、リスナーのためのより適したプレイリストをおすすめするためです。プレイリストの ML モデルは、聞き手ドメイン、リスナープロファイル、リスナーソーシャルネットワーク、リスナーの位置など、組織全体のさまざまなソースからの分析データのパターンを利用して、リスナーのコンテキストとコホートを理解します。プレイヤードメインからのデータ共有、プレイセッションやプレイイベント、リスナーのプレイヤーデバイスでの動作と嗜好を理解します。

音楽アルバムドメインのデータ、音楽トラック、音楽プロファイルからは、音楽トラックのプロファイルと分類を理解するために使用されます。月曜プレイリスト、日曜の朝のプレイリスト、フォーカスプレイリストなど、複数のトレーニング済み機械学習モデルがスマートプレイリストを生成しています。プレイリストチームは、これらの継続的に改善されたコンピレーションを他のチームとしてデータ製品として共有しています。データは製品というのは、Daff の確立されたデータ共有の基準に従って共有されるデータを指す確立された概念です。データ製品は、グローバルデータ検索ツールを介して自動的にアクセス可能です。それらは一連のサービスレベル目標（SLO）を共有し、プレイリストが更新される頻度、正確さ、タイムリーさなどを保証します。それらには最新でわかりやすいドキュメンテーションがあります。つまり、データ製品は、適切なアクセス許可を持つユーザーが簡単に理解して使用できる高品質なデータです。プレイヤードメインチームは、さまざまなプレイヤーのユーザーインターフェイス（モバイル、デスクトップ、車など）でコンテンツをリスナーに提示することに焦点を当てており、プレイリストのデータ製品の主要なユーザーの 1 つです。彼らは最新かつ最高のプレイリストを継続的に利用し、リスナーに提示します。プレイリストチームは、ランニングプレイリスト、サイクリングプレイリストなど、さまざまなスポーツ活動に適した新しい種類のプレイリストをおすすめするために、自分たちのモデルを進化させる予定です。彼らは、リスナーがスポーツ活動中に好きな音楽や再生した音楽に関する情報が含まれている既存のデータを見つける必要があります。プレイリストチームは、メッシュ探索ポータルにアクセスし、スポーツ活動に関連する可能性のあるすべてのデータ製品を検索します。発見のメカニズムを通じて、パートナーシップドメインに関連するデータがいくつかあることがわかります。発見ツールを使用して、チームは自動的にドキュメンテーション、サンプルコード、およびデータ製品に関する詳細情報を取得できます。彼らは自動的にアクセスを要求し、パートナーシップのデータ製品に接続し、サンプルデータセットを調査します。パートナーシップメンバー（パートナーのワークアウトプラットフォームのメンバー）に関連する有用なデータをいくつか見つけることができますが、彼らはランニング、サイクリング、ヨガを行う際にそれらのプラットフォームで聞いたり好んだりする音楽の情報は見つかりません。プレイリストチームはパートナーシップデータ製品の所有者に連絡を取ります。各ドメインには、そのドメインで共有されるデータに焦点を当てる専任の製品オーナーがいます。直接の会話を通じて、プレイリストチームはパートナーシップチームに、ワークアウトプラットフォームでさまざまな活動中に再生される音楽トラックやメンバーが好む音楽を取得する必要があることを伝えます。この会話は、パートナープレイリストデータ製品の作成の優先順位付けにつながります。パートナーシップビジネスチームの目的は、ワークアウトプラットフォームや音楽などのパートナープラットフォームとのシームレスな統合を通じてリスナーにより良い体験を提供することです。パートナープレイリストデータ製品の作成は、彼らのビジネス目標と一致しています。パートナーシップチームは、これらのデータ製品を作成するために最適な立場にあります。三年前、プレイリストチームは、スポーツプレイリストのために新しいモデルを構築し、トレーニングするために中央のデータおよび AI チームに依頼する必要がありました。中央のデータと AI チームのデータサイエンティストたちは、組織全体で要求される他の多くの ML ベースのイニシアチブの中で、これを優先する必要があったでしょう。プレイリストのリクエストを高い優先度で処理するためには、データサイエンティストたちは中央のデータ倉庫チームやデータへのアクセスを要求するために中央のガバナンスチームに行かなければならなかったでしょう。これにはさらに数日かかったでしょう。それでも、データを見つけた後も、データサイエンティストたちはデータを十分に理解できなかった可能性があります。データは古くなっていたかもしれず、パートナーシップチームが中央の倉庫やデータ湖にまだ反映されていない多くの新しい統合を確立していたかもしれません。中央のデータサイエンティストチームはデータに対して信頼性の問題を抱えていたでしょう。データサイエンティストがパートナーからもっと音楽関連のデータを必要としていることに気付いた後、データ湖チームはデータエンジニアリングチームにアクセスし、新しい抽出、変換、読み込み/抽出、読み込み、変換（ETL/ELT）パイプラインを設定するために、パートナー統合 API からデータを取得し、それを倉庫やデータ湖に移す必要がありました。これにより、別の遅延が発生しました。集中化されたデータエンジニアリングチームは、データをアプリケーションデータベースからパイプラインに移し、それをデータ湖に移すために、完全に新しいドメインであるパートナーシップドメインを交渉し理解するために数日間を費やさなければなりませんでした。内部のデータベースを理解し、内部の音楽 ID をグローバル ID にマッピングするなど、他の内部アプリケーションの微妙なニュアンスも理解しなければなりませんでした。これにはさらに時間がかかるでしょう。ビジネスケースに直接関与し、理解していないために、パートナーシップチームは高品質なパートナーシップ音楽統合とデータエンジニアの ETL パイプラインを優先させるインセンティブが低かったでしょう。アドホックな統合はデータがデータ湖に流れ込むまで数日間のデバッグを経験しました。そして、物語は続きます。ダフの機能的に分割された組織設計とテクノロジーは、データ駆動型の実験環境に適していませんでした。図 P-2 は、データメッシュを導入する前のダフの組織構造とアーキテクチャを示しています。彼らは自律的なドメインを中心にビジネスと技術の開発チームを整備していたため、モダンなソフトウェア開発アーキテクチャと組織構造を持っていました。しかし、データと分析チームとアーキテクチャは、湖と倉庫のモノリシックなアーキテクチャを使用して機能的に分割され、集中化されていました。中央のデータチームとモノリシックなアーキテクチャは、会社内外のデータソースの急増とその使用例の多様性に対応するためにボトルネックになってしまいました。データチームは多くのプレッシャーにさらされ、Daff の成長に対応するために大幅に遅延してしまいました。投資の収益は停滞しました。つまり、ダフのデータチームの構造とアーキテクチャは、その志向と組織の成長に合わなくなっていたのです。パートナーシップの不可視なプラットフォームとポリシー データメッシュ以降、私が共有したスポーツプレイリストのシナリオでは、データのユーザーと提供者の経験はまるで魔法のようです。摩擦がなく、迅速なエンドツーエンドの結果が得られ、明確な責任範囲と共有責任の感覚があります。これを実現するためには、Daff はユーザーと提供者のデータの経験を裏で支える、ネイティブに使用できるほぼ目に見えない自己サービスの技術と自動化のセットを作成しました。データの提供者とデータのユーザーの経験の下には、データを迅速かつ自律的に共有するための自己サービスの機能から成るプラットフォームがあります。この例では、データプラットフォームが、ソースとの統合、データ変換コードの構築とテスト、データの提供を含む、短期間でパートナープレイリストとスポーツプレイリストのデータ製品を作成および進化させるための摩擦のない経験を支援しました。データプロダクトのメッシュとしての全体としての作業の経験。この場合、プラットフォームサービスは、データプロダクトを検索し見つけること、それらに接続し、データをクエリし、変動するデータ変更に対して購読し、複数のデータプロダクトを結合および相関させ、新しい革新的なプレイリストを作成することを可能にします。プラットフォームの経験に基づくこれらの機能は、ユーザーであるデータプロダクトの開発者、所有者、ユーザーの認識負荷を最小限に抑えるために最適化されています。Daff にとって、ユーザーの経験（データプロダクトの開発者およびユーザー）を最適化する代わりに、マシンの最適化のコストを受け入れることは受け入れられません。プラットフォームの目に見えない部分は、物理層に近く、ユーザーから遠く離れており、物理的な最適化とマシンレベルの最適化を担当します。プラットフォームの経験レベル（一連の統合されたサービス）では、自律かつ接続されたデータプロダクトで作業するためのユーザー体験を最適化し、プラットフォームの効用レベルでは物理的なパフォーマンスとマシンレベルのパフォーマンスを最適化します。例えば、以下をサポートします：- データプロダクトの効率的な多言語ストレージ- データプロダクト全体での効率的なクエリとワークロード処理- 効率的な検索とインデックス設定- データ移動の削減- プレイリストチームのシームレスな体験は、提携、リスナー、音楽プロフィールなどさまざまなチームから取得した複数のデータプロダクトを使用し相関させることに依存します。これには、すべてのデータプロダクトに適用される一連のグローバル標準ポリシーが必要です：- データ共有 API の標準化- SLO、ドキュメント、データモデリング言語を含むメタデータの標準化- 共有データエンティティ ID の標準化- 自律データプロダクトと無制限スケール- Daff の成長志向とデータメッシュは、組織と技術のスケールアウト構造に合致しています。スマートプレイリストの例で見たように、新しいプレイリストの導入や既存のプレイリストの改善は、単により多くのデータプロダクトを追加し、それらを接続することにより実現されます。つまり、ランニングプレイリスト、サイクリングプレイリスト、ワークアウトプラットフォーム X のパートナープレイリスト、ワークアウトプラットフォーム Y のパートナープレイリストなどです。これは、相互に連携し合うより多くの同等ノードを追加することで無制限のスケールを実現できるスケールアウトアーキテクチャです。データプロダクトは、アーキテクチャの量子として実装されます。それは独立して展開される最小のアーキテクチャ単位であり、構造的構成要素をすべて備えてそれ自体の役割を果たすことができます。このアーキテクチャは、各データプロダクトがデータアクセスとデータ共有のための標準的な一連の契約を実装することを保証します。そして、それぞれが他のメッシュ上のデータクォンタに接続してデータと意味を共有できるようになります。各データプロダクトは、データ変換ロジックとデータを管理するポリシーをカプセル化しています。このアーキテクチャは、ドメイン指向の組織的自律性と対応するデータプロダクト指向の分散アーキテクチャに合致しています。Daff のデータプロダクトの標準化は、速度とスケールを実現しています。Daff がデータと分析を使用することで生み出される成功は、ドメイン間のピアツーピアの接続によって作成される正のネットワーク効果を要約したものです。ネットワークが大きくなり、より多くの接続が確立されれば、ビジネスを向上させるて知識と高次の洞察を生成するためにドメイン間で共有されるデータが増えます。Daff はデータメッシュ戦略を実行するために、組織と文化のシフトを行い、インフラストラクチャとプラットフォームの基盤を作り上げるために大きな投資をしています。しかし、計測可能な利益をもたらす投資のリターンを追跡することには慎重でした。彼らの測定に基づいて、外部では ML とデータを活用してリスナーのエクスペリエンスを複数のタッチポイントで向上させることで、より深いユーザーエンゲージメントを作り出し、アクティブなリスナーの数を増やしました。内部では、中央と仲介者のボトルネックを取り除くことで、データへのアクセスのリードタイムを短縮しました。また、データの変化のリスクを減らすために、標準的な契約とインターフェースを作成しました。彼らは、データ製品の開発において自動化された継続的なデリバリー手法を採用することで、データ製品の無駄を削減しました。彼らは、データ製品間の接続性の量で測定されるビジネス全体へのデータの適用を増やしました。彼らは、各ドメインとチームにデータの所有権を組み込むことにより、データに基づいたソリューションを作成するための関与するチームの数を増やしました。彼らは、プラットフォームサービスを活用し、データ開発者の経験に焦点を当てることで、データの所有コストとエンドツーエンドのデータソリューションの作成コストを削減しました。これらは、彼らがデータメッシュの投資に対して測定する改善領域の一部です。15 データメッシュへの変革の必要性なぜデータメッシュに変革するのでしょうか？2019 年にさかのぼってみましょう。それは Daff にとって転換点の年でした。数年前から、Daff はデータレイクやデータウェアハウスなどのデータソリューションに大規模に投資して、データを収集してきました。彼らは、組織全体のデータの収集、モデリング、提供、および必要な分析および機械学習ソリューションの構築など、データと AI に関する大規模なチームを構築していました。Daff が採用した組織構造と運営モデルは、当時の業界標準でした。この年、Daff は反省し、自分たちのデータの志向が実現する能力を超えていることに気付きました。中央データチームとモノリシックアーキテクチャは、会社内外のデータソースの増加とその用途の多様性に対応するために、ボトルネックとなっていました。データチームは大きなプレッシャーにさらされ、成長に対応するために大幅に遅くなっていました。投資のリターンはすでに停滞していました。彼らは変わる必要がありました。そして、それが彼らがデータメッシュを見つけた時でした。データメッシュに取り組む前に、Daff は自社のビジネスの目標、組織、技術的な能力とデータメッシュの整合性を注意深く見ました。データメッシュの期待される成果は、彼らの課題に対処することと合致していました。 急速な成長と増加する複雑さ 彼らは急速に成長し、彼らのビジネスはより複雑になり、多様で野心的な分析の志向を実現することが遅くなっていました。データメッシュは、複雑で大規模な環境でデータから価値を得るために設計されています。
大規模なデータから価値を得る 彼らはデータと分析のための技術基盤に莫大な投資をしていますが、結果は停滞しています。データメッシュは、一般的なテクノロジストの大規模な人口をデータの開発者およびユーザーとして動員することで、効果的にデータから価値を得ます。データメッシュの目標と全体的な影響の範囲は、有望なものでした。ただし、Daff の状況を考慮して、これが彼らにとって今の時点で正しい選択肢なのかという問題がありました。この質問への回答は有望でした。データメッシュは、Daff の既存のドメイン指向の組織設計と互換性がありました。それは彼らの既存のデザインとアーキテクチャの拡張でした。データメッシュは、単に既存のビジネスに合わせた開発チームを拡張した分散型のデータ所有モデルに基づいて構築されています。実際には、集中型のデータチームは、現在のドメイン指向のビジネスおよび技術組織設計にやや不釣り合いな、比較的分割されたチームの最後の 1 つでした。データと分析の所有権をドメインに移すことは、すべてのドメインをデータに基づいたものにし、インテリジェントな意思決定を埋め込むという彼らの志向に合致していました。会社は既にビジネスデブオプスにドメインを合わせたチームで運営していましたので、これらのチームをデータの能力と責任を持ったものに拡張することは、データへのアクセスと利用の民主化にとって自然な進行でした。当然、ガバナンスもこれらの組織の縫い目に従う必要がありました。彼らはデータメッシュのリードアドプターとして、基盤技術の構築とプラットフォームの活用に時間とリソースを割く必要があることを知っていました。ダフは、自らを技術を核としたソフトウェア会社と位置づけており、ビジネスを可能にするだけでなく、形作り拡張していると考えていました。彼らは技術への投資を避けることはありませんでした。ダフは、データの文化、データの組織構造、データの役割、データのアーキテクチャ、およびテクノロジーの変更を含む新しいアプローチを実施することが、複数年かけての変革になることを認識していました。したがって、彼らはデータメッシュへの移行を逐次的に行うために、次の 3 年間を専念しました。旅の途中で彼らは慎重に選ばれたデータ駆動のユースケースを提供しながら、組織の変革とプラットフォームとテクノロジーの確立を行いました。 18 これからの道 事業、文化、技術の成功にもかかわらず、ダフにはまだ進むべき道があります。データメッシュの実行の進化は、確かに探索の段階を経ており、作業の方法や基盤プラットフォームを確立しました。彼らはメッシュを多くのドメインに拡大しました。しかし、メッシュから価値を引き出し続けるためには、アプローチを継続的に最適化し洗練させる必要があります。彼らは、メッシュの活発なメンバーになるために遅れているドメインで取り組む必要があり、レガシーシステムとまだドメイン指向のクロスファンクショナルチームで作業していないドメインに対するプラットフォームの機能を拡張する必要があります。これがデータメッシュ変革の予想される軌道です：探索、拡大、抽出の繰り返しを繰り返す進化の道です。19 私は、ダフでのデータメッシュの物語があなたをこのポイントを越えて読み続けるように促したことを望みます。その場合、次の章でお会いしましょう。

