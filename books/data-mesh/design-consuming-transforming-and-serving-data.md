データ製品の主な役割は、入力データポートを使用して上流ソースからデータを取り込み、それを変換し、出力データポートを介して恒久的にアクセス可能なデータとして提供することです
この章では、すべてのデータ製品が実装する 3 つの基本機能であるデータの取り込み（「データの取り込み」）、データの変換（「データの変換」）、データの提供（「データの提供」）の設計特性について説明します
まず、データメッシュのアプローチに最も固有の特性を持つ機能から始めましょう

データの提供
データ製品は、さまざまな分析的な消費者に対して、ドメイン指向のデータを提供します
これは、第 9 章で紹介された出力データポート（インターフェース）を通じて行われます
出力データポートには明示的に定義された契約と API があります
これは「ドメイン指向のデータの提供」というシンプルな機能ですが、そのエコシステム内のエージェントとの関係や彼らの能力とニーズとの関係を考慮すると、興味深い特性を持ちます
データ製品とデータユーザーの関係を見てみましょう
データユーザーのニーズ
図 12-1 は、データユーザーのニーズとデータ製品がそれを満たすための特性を示しています
図 12-1
データユーザーとそのニーズを満たすためのデータ提供の特性
データユーザーによって要求される要件は、データ製品がデータを提供する方法に一連の設計上の考慮事項を課します
分析的なデータユーザーは多様なプロフィールを持っています
データユーザー（データにアクセスして読み取るクライアント）は、データアナリスト、データサイエンティスト、データ駆動型アプリケーション開発者などの人物、およびレポート、可視化、統計モデル、機械学習モデルなどのシステムを含む、幅広いスペクトラムのペルソナとアプリケーションタイプです
第 3 章を思い出すと、データ製品は、そのデータを異なる形式とアクセス方法で提供することで、これらの多様なペルソナにとってネイティブにアクセス可能な方法でデータを提供します
これを基本的な使いやすさの特性と呼びました
この要件の設計上の含意は、データに複数のモードでアクセスすることでデータを提供することです
分析的なデータユーザーは、長期間のデータが必要です
メッシュは、分析用途においてデータのグローバルな状態を完全に長期間保持し、それもメッシュ外のデータレイク、データウェアハウス、または他の外部システムなしで保持します
データの連続的に変化するグローバルな状態は、データ製品の接続されたグラフによって保存および維持される唯一の要素です
これがアーキテクチャの分散化の意味です
洞察は、時間の経過を考慮に入れることで最も強力になります
連続的なデータ変更を時間の経過にわたってアクセスできることにより、トレンドを形成し、予測を行い、複数のドメインにまたがるさまざまなイベント間の相関関係を発見できます
データメッシュは、データのプレゼンテーションおよびクエリングの両方で常に存在するパラメータとして時間を前提としています
時系列データ、つまりイベントと状態の変化を表すデータにアクセスするための設計上の含意は、各データ量子が二時的なデータを提供することです
分析的なデータユーザーは、特定の時点で複数のドメインの一貫したビューが必要です
大部分の分析的なユースケースでは、複数のデータ製品からデータを処理します
このようなユースケースでは、一貫した時点で複数のデータ製品を相関させます
例えば、ダフが 2021 年 7 月 1 日に次の月の加入者増加を予測するために機械学習モデルをトレーニングする場合、それは 2021 年 7 月 1 日に複数のデータ製品によって既知のデータと処理されたデータに基づいて行われます
この成長モデルの特定バージョンの再現性をサポートするためには、2021 年 7 月 21 日に処理されたデータ製品の複数にわたるデータの変更不能な状態を維持する必要があります
複数のデータ製品にまたがる時点毎の一貫したデータの提供と、再現性のためのデータのバージョン管理を組み合わせることで、データの提供には複数の設計上の考慮事項が導入されます: 二時変性、変性しなさ、読み取り専用アクセス
データの提供設計特性 それでは、先ほど発見した各特性について少し深く掘り下げてみましょう: マルチモーダル、変更不可能、二時的、読み取り専用アクセスという特性です
これらの特徴は、データメッシュの動作に不可欠です

マルチモーダルデータ
データ製品の役割は、特定のドメインの分析データを特定かつ一意のドメインセマンティクスで提供することです
しかし、データ製品が多様なコンシューマーにネイティブにサービスを提供するためには、同じドメインセマンティクスを異なる構文で共有する必要があります
セマンティクスはカラム形式のファイル、関係データベースのテーブル、イベントなどの形式で提供することができます
同じセマンティクスは、データコンシューマーの体験を損なうことなく提供されます
レポートを作成する人は、データを関係テーブルとして消費します
機械学習モデルをトレーニングする人は、カラム形式のファイルでデータを消費し、リアルタイムのアプリ開発者はイベントを消費します
私は、分析データの性質を空間と時間の寸法として視覚化することが役立つと考えています
空間の次元を使用してデータの異なる構文的具現化、データの形式を表します
任意のデータ製品は、複数の形式でデータを表示することができます
または、マルチモーダル形式で、例えば： 半構造化ファイル、例：列ファイル エンティティ関係、例：関連テーブル グラフ、例：プロパティグラフ イベント データユーザーがデータ製品にアクセスする際には、最上位のデータ製品発見 API（「発見、理解、信頼、探索」）を使用します
最初にデータ製品のセマンティクスについて学びます
どのドメイン情報を提供しているか（例：ポッドキャスト、ポッドキャストのリスナーなど）その後、データの特定のアクセス方法に対してデータ製品の出力 API（「出力データポート」）の 1 つにアクセスします
データの提供方法は、基礎（物理）テクノロジーによるものです
イベントログに登録する、分散列ファイルを読み取る、関連テーブル上の SQL クエリを実行するなど
ドメイン指向のセマンティクスは最上位の関心事であり、形式とアクセスのモードは二次的な関心事です
これは、既存のアーキテクチャとは逆のモデルであり、ストレージおよびエンコーディング技術がデータが最初にどのように組織化され、それから提供されるかを指示するものです
図 12-2 は、多様なアクセスモードを例として示しています
プレイイベントデータ製品は、3 つのアクセスモードを介してプレイイベントデータにアクセスできます： 「プレイイベント」トピックにサブスクライブする（リスナーの状態変化をキャプチャし、ログイン、ポッドキャストの再生、再生停止などを行う）、同じプレイイベントに SQL クエリを介してアクセスする（イベントの属性の行を持つテーブルを使用）、および列オブジェクトファイル（すべてのイベントの属性ごとにファイルを作成）
「図 12-2 データ製品のマルチモーダルアクセスの例」 これらの 3 つのアクセスモードとデータのトポロジーは、さまざまな役割の消費者のニーズを満たすことができます： データ集約的なアプリ開発者はエラーイベントを監視してプレーヤーの品質を向上させるため、同期 SQL アクセスモデルを使用してデイリーレポートを作成するデータアナリスト、およびファイルアクセスモードを使用して ML モデルをトレーニングするデータ科学者はプレイパターンの分類を見つけます
これは、個々の出力データポートを介して可能になります
注意
現在、マルチモーダルアクセスのサポートの複雑さは、データの上位のアピールと抽象 API の欠如の症状です
これは、データの表現や形式に対して意味論的かつ前向きに問い合わせるためのものです
不変データ
同じ川を 2 回渡ることはできない -ヘラクレイトス 不変データは、一度作成されると変更されません
データ製品は、データを処理してデータユーザーに利用可能にする際に、その特定のデータが変更されないようにデータを提供します
削除や更新はできません
データの変更はしばしば複雑さとエラーを引き起こすため、経験豊富なプログラマーなら誰でも知っていることです
これが関連性のある分析ユースケースに特に関連します
不変のデータを使用することで、データユーザーは繰り返し可能な方法で分析を再実行することができます
モデルの再トレーニングや特定の時点のデータセットでのレポートの再生成は、同じ結果を繰り返し得るものです
再現性は必要です
なぜなら、結果が驚くべき観察結果を生み出すことが多く、アナリストがより深く掘り下げる必要があるからです
使用しているデータが変更されると、驚くべき結果を再現することができなくなり、これがデータの変更によるものなのか、プログラミングのエラーなのかを疑問に思うことがあります
分析にバグがある場合、不安定なデータソースで作業する際には、同じコードを繰り返し実行しても同じ回答を得ることができないため、追跡がはるかに難しくなります
データメッシュでは、ソースデータが複数のデータ製品で使用され、複数のデータ製品が特定の分析のソースとなることがあり、複数のデータ製品が 1 つのビジネス状態のより大きな理解に貢献する真実の一部を保持しているため、可変データの混乱と複雑さはさらに悪化します
データメッシュの分散した性質は、データユーザーに対して次の自信を与えるために、変更不可能性が要求されます：（1）時間刻みのデータの複数のデータ製品間に一貫性があり、（2）ある時点でデータを読み取った後、そのデータが変更されず、信頼性のある読み取りと処理を繰り返すことができます
図 12-3 は、シンプルな例を示しています：リスナーの人口統計データ製品は、リスナーの地理的な人口統計を日々提供し、リスナーが接続する場所を提供します
これには、2 つの下流データ製品があります
アーティストの地域人気（特定のアーティストのリスナーが最も多い場所）と地域の市場規模（異なる地域のリスナー数）
これら 2 つのデータ製品は、地域マーケティングデータ製品のソースの一部であり、地域に対してターゲットを絞ったマーケティング活動を推奨します
このデータ製品は、A/B テストや実験を行うために市場リスクの少ない国を特定するために地域の市場規模を使用し、人気に基づいてアーティストをプロモートするためにアーティストの地域人気を使用します
図 12-3
相関しないデータの例これらのデータ製品のそれぞれは、データの処理と提供に独自のリズムを持っています
したがって、すべてのデータが同時に更新されることを保証する方法はありません
これによって致命的なダイヤモンドが生じる可能性があります
リスナーの人口統計がデータを更新する時に、地域マーケティングが分析を実行している場合、リスナーの人口統計は更新前にデータを提供し、地域の市場規模は更新後に提供するため、一貫性のないデータを消費する可能性があります
さらに悪いことに、地域マーケティングはこの不一致についてさえ知りません
データメッシュは、データユーザーが更新されたデータを検出できないようにすることで、この問題に対処します
データの変更は常に、異なるデータ製品から来る異なるデータの断片を関連付けることなく、時系列の属性を識別するための新しいデータの断片として提示されます
これを行う最も一般的な方法は、次のセクションで説明する 2 つの時間軸を持つデータを使用することです
たとえば、リスナーの人口統計は、{リスナー ID：'123'、場所：'サンフランシスコ'、接続時間：'2021-08-12T14:23:00、処理時間：'2021-08-13T01:00'}のようなタプルとしてデータを共有します
各情報には、2 つの時間変動の識別フィールド、「接続時間」（音楽を聴くためにリスナーが接続した時刻）と「処理時間」（リスナーの人口統計がこの情報を処理した時刻）があります
このタプルが処理され、データユーザーに利用可能になると、絶対に変更されません
もちろん、同じリスナーが翌日には別の場所からコンテンツを聴くことがあり、それは新しいデータエンティティの追加として現れます（リスナー ID：'123'、場所：'ニューヨーク'、接続時間：'2021-08-13T10:00'、処理時間：'2021-08-14T01:00'）
これらは 2 つの異なる時間であり、更新を伴っていますが、リスナーの新しい場所を示しています
データの不変性は、付随的な複雑さの機会を減らし、分散メッシュ上の共有ステートの更新とそれに伴う副作用の取り扱いの複雑さ、および分散トランザクションという扱いにくいコンピュータサイエンスの問題を解決する機会を減らします
メッシュがすでに消費されたデータが変化し続けることを許容する場合、または同じ読み取りを繰り返すことで異なる結果が得られる場合、メッシュ上の各下流データリーダのコードにどれほどの複雑さが組み込まれているかを想像してみてください
不変性は変更の設計とメッシュの最終的な整合性を維持するための新しい処理時間とその不変な状態の伝播を通じて、変更の設計を可能にするもう一つの重要な要素です
データを不変に保つことはいつでも重要ですが、データメッシュにとっては特に重要です
ただし、新しい情報が利用可能になったり、データ処理のバグが修正されるにつれて、過去のデータも変更されることがあります
したがって、データに対して取り消し可能な変更を行うことができる必要があります
データメッシュが不変性と取り消された変更を実装し、変更可能である必要があるにもかかわらず、データが不変であるようにする方法を見るために、バイテンポラリティを見てみましょう
バイテンポラリティデータ変化と時間は切り離せないようです
変化には時間がかかり、時間的に配置および順序付けられ、時間的に区切られています
時間と変化の切り離せなさは、一種の論理的な真実です
--レイモンド・タリス
バイテンポラリティデータは、実際のイベントが発生した時間または実際の状態が存在した時間"実際の時間"と、データが処理された時間"処理時間"の 2 つのタイムスタンプを記録するようにデータをモデリングする方法です
バイテンポラリティデータモデリングにより、不変なエンティティとしてデータを提供することができます
つまり、データの不変性により、偶発的な複雑さが減少し、分散メッシュ内の共有状態の更新の副作用や分散トランザクションの解決における複雑さが軽減されます
メッシュがすでに消費したデータが変更され続けることを許可する場合、または同じ読み取りを繰り返すと異なる結果が得られる場合、メッシュ上の各下流データリーダーのコードに関連する複雑さを想像してみてください
不変性は変更の設計とメッシュの最終的な一貫性の維持を可能にするもう一つの重要な要因です
新しい処理時間とその不変の状態を伝播することによって
データを不変に保つことはいつでも重要ですが、データメッシュでは特に重要です
ただし、新しい情報が利用可能になるか、データ処理のバグが修正されることで、過去のデータが変更されることも事実です
したがって、データに撤回可能な変更を行う必要があります
データメッシュが不変性と撤回可能な変更を実装し、データが不変である必要があるにもかかわらず変更を許可する方法、つまり、バイテンポラリティを見てみましょう
バイテンポラリティ データ 変更と時間は切り離せない関係にあるようです：変更には時間がかかり、時間的に位置づけられます
そして、時間によって区切られます
時間と変化の切り離せなさは、ある種の論理的な真実です
バイテンポラリティデータは、データの各部分が 2 つのタイムスタンプを記録する方法です
つまり、「イベントが実際に発生した時点または状態が実際にあった時点」である実際の時間と、「データが処理された時点」である処理時間です
バイテンポラリティデータモデリングにより、データを不変なエンティティとして提供することが可能になります
つまり、{データプロダクトのフィールド、実際の時間、処理時間}のタプルとして、新しいデータエンティティが処理されるたびに処理時間は単調に増加します
また、時系列分析とタイムトラベル(過去の傾向を見て将来の可能性を予測すること)も行うことができます
これらの結果は、データメッシュにとって重要です
たとえば、Daff のビジネスの成長を予測する典型的な時系列分析のユースケースを考えてみましょう
このモデルは、長期間にわたる加入者の変更を使用してパターンや傾向を発見します
データプロダクトは、異なる処理速度でデータを処理し提供するという特徴があります
成長予測モデルは、異なるデータプロダクトから一貫したデータを使用して、繰り返し可能なモデルのトレーニングにおいて共通の処理時間を選択します
つまり、データプロダクトがイベントを処理し認識するタイミングです
例えば、2022-01-02T12:00 にトレーニングされたモデルでは、2022-01-02T12:00 までの過去三年間（実際の時間）の加入者情報、サポート問題、マーケティングイベントを使用します
実際の時間と処理時間は、データプロダクトが保持し提供する時間の 2 つの絡まった軸です
実際の時間の変動
分析用途のニーズを満たす形式でデータを表現するため、データプロダクトは時間の経過に伴うドメインの状態（またはイベント）をキャプチャし共有します
たとえば、ポッドキャストのリスナーデータプロダクトは、「1 年前から現在までの毎日のポッドキャストのリスナー情報」を共有することができます
実際の時間は、イベントが発生する時点または特定の状態が存在する時間です
たとえば、2021-07-15 は、この日に Daff のポッドキャストを実際に聴いたポッドキャストリスナー（データ）の実際の時間です
実際の時間の存在は重要です
なぜなら、予測分析や診断分析は、実際に何が起こったかの時間に敏感だからです
これはオペレーションの機能の場合には当てはまりません
オペレーションの機能のほとんどは、データの現在の状態に対処します
例えば、「現在のポッドキャストリスナーの住所を教えてください
印刷されたマーケティング資料を送るために必要です」といった具体的な要求です
実際の時刻は変動します
データ製品は、順序外の実際の時刻を観測したり、ソースデータの修正後に同じ実際の時刻に関する新しいデータを受け取ることができます
処理時間の連続処理時間は、データ製品が特定の実際の時刻についてその知識または理解を観測し、処理し、記録し、提供する時間です
例えば、2021-08-12T01:00 に、ポッドキャストのリスナーデータ製品は、2021-08-11 にポッドキャストを聞いた人々に関するすべてのデータを処理し、当時の世界の状態を理解します
2021-08-12T01:00 が処理時間です
データの必須属性としての処理時間の提供は、変化に対応するための設計の鍵です
過去の理解は変化します
過去に発生したエラーを修正したり、過去の理解を改善する新しい情報に気付いたりすることがあります
過去を変えることはできませんが、過去の処理時間を変えることはできます
過去の実際の時刻の修正を反映した新しい処理時間で新しいデータを提供します
処理時間は、前進的な時間として信頼できる唯一の時間です
注記
処理時間は、4 つの異なる時間を 1 つの時間に統合するために使用します
観測時間は、データ製品がイベントや状態に気付く時の時間です
処理時間は、データ製品がデータを処理し、変換する時間です
記録時間は、データ製品が処理されたデータを保存する時間です
公開時間は、データがデータユーザーにアクセス可能になる時間です
これらの微妙な時差は、データ製品の内部に最も関連があり、データユーザーに関係がありません
したがって、それらをデータユーザーにとって最も重要な処理時間にまとめました
マーティン・ファウラーは、「Bitemporal History」というシンプルで優れた記事でこの二重時間性を紹介しています
このセクションでは、データ製品がこのコンセプトを統一モデルで採用する方法をまとめています
過去への影響の影響それでは、いくつかのシナリオで二重時間性の正の影響について簡単に説明しましょう
取り消し世界の理解は継続的に進化しています
世界の理解にはエラーや情報の欠落があるかもしれません
この場合、後の処理時間で誤解を修正します
例えば、2021-08-12T1:00 に「2021-08-11 にポッドキャストを聴いた人々」に関する情報をすべて処理しますが、リスナーの数を数える際に誤りがあり、3000 人と計算します
次に、2021-08-13T10:00 に情報を処理する際に、エラーを修正し、新しい数値である 2021-08-11 の 2,005 人のリスナーを作成します
3,000 と 2,005 は、同じアイデンティティ「2021-08-11 のポッドキャストリスナー数」のために 2 つの異なる値として捉えられ、2021-08-12T10:00 で処理された状態と 2021-08-13T10:00 で処理された状態として別々の状態としてキャプチャされ、共有されます
二重時間性を使用することで、データの状態、データモデル、SLO メトリックなどの変更が組み込ま実際の時間は変動します
データ製品は、順序が逆になった実際の時間を観測したり、ソースデータに修正が加えられた後でも同じ実際の時間に関する新しいデータを受け取ることがあります
処理時間の連続
処理時間とは、データ製品が特定の実際の時間における状態やイベントの知識または理解を観測し、処理し、記録し、提供する時間です
例えば、2021 年 08 月 12 日 01:00 に、ポッドキャストのリスナーデータ製品は 2021 年 08 月 11 日にポッドキャストを聴いた人々に関するすべてのデータを処理し、その当時の世界の状態を理解します
2021 年 08 月 12 日 01:00 が処理時間です
データの必須属性として処理時間を提供することが変更に対する設計の鍵です
誤りの修正
世界の理解は常に進化しています
世界の理解には誤りや欠落した情報がある場合があります
この場合、後の処理時間において、私たちは誤解を修正します
例えば、2021 年 08 月 12 日 01:00 に「2021 年 08 月 11 日にポッドキャストを聴いた人々」に関する情報をすべて処理しますが、リスナーの数を誤って 3,000 人と計算します
次に、2021 年 08 月 13 日 10:00 に情報を再処理すると、エラーを修正し、新しいカウントとして 2021 年 08 月 11 日に 2,005 人のリスナーを算出します
3,000 人と 2,005 人は、同じ識別子「2021 年 08 月 11 日のポッドキャストリスナーの数」に対して、2021 年 08 月 12 日 10:00 に処理された状態と 2021 年 08 月 13 日 10:00 に処理された状態として記録および共有される 2 つの異なる値となります
二重時系列を使用することで、データの状態、データモデル、SLO メトリックなどの変更が組み込まれます
変更の連続的な処理は、すべてのコンシューマーとメッシュ全体にデフォルトの振る舞いとして組み込まれます
これにより、データユーザーのロジックが大幅に簡素化されます
過去の更新は特別なケースや驚きではなくなります
それらは過去について新しいストーリーを伝えるために処理される新しいデータです
コンシューマーは、過去のデータの過去のリビジョンにアクセスするために、過去のある時点で処理したデータを追跡し、固定することができます
もちろん、そのようなシステムを構築することは容易なエンジニアリングの課題ではありません
処理時間と実際の時間のずれ ずれとは、実際の時間と処理時間の時間差です
真のリアルタイムシステムの場合、ずれは無視できるほど小さいです
イベントが処理され、世界の理解が形成されるのは、ほぼイベントが発生した時とほぼ同じです
これは、特にデータ製品の連鎖でデータ製品が実際のイベントのソースから複数のホップ先でデータを処理する分析データ処理では非常に珍しいです
二つの時間の存在は、データの利用者にスキューを通知し、それに基づいてデータの処理方法を決定することができるようにします
ソースに合わせたデータ製品から遠く離れるほど、スキューは大きくなります
時間枠データ製品の上流データを一定の時間枠で集計することは一般的です
例えば、プレイセッションはリスナーがプレーヤーデバイスと関わる間に発生するすべてのイベントを集計します
つまり、リスナーがポッドキャストから別のポッドキャストに移動し、最終的に 1 つを選び、数分間聞いてからプレーヤーをしまうまでの一連の再生イベントです
これは、リスナーがプレーヤーと関わる際の行動分析を支援します
この場合、再生イベントの実際の時間は複数の分（時間枠）にわたる場合があります
時間枠の知識を持つデータの利用者は、データ上で時間に関連する操作を行うことができます
連続する変更の反応的処理データメッシュでは、常に変化し続ける世界を前提としています
この定常的な変化は、新しいデータの到着や過去のデータの理解の進化の形で現れ、処理時間によって示されます
データ製品は、上流データ製品が変更されたことに反応して、連続的に変更を処理することができます
つまり、新しい処理時間が利用可能になったことを意味します
処理時間は、接続されたデータ製品間の反応的で非同期なデータ処理を作成するための基本的なメカニズムとなります
データ製品のすべての属性とプロパティには、時間の概念が組み込まれており、時間の経過とともに変化します
データスキーマ、データセマンティクス、データ間の関係、SLO（Service Level Objective）などのメタ情報も同様です
これらは、自動的に時間によってバージョン管理されます
処理時間は、データスキーマなどのデータ製品の永続的なプロパティのバージョン管理のための基本的な要素となります
処理時間は、データ製品の SLO などの時間変動情報と相関付けるためのパラメータとなります
例えば、前の例を見てみましょう
図 12-4 は、単一のデータ製品における時間の数値とその関係を示しています
図 12-4 ではいくつかの注目すべき点が示されています
スキュー データの量子がイベントを処理し、そのデータの状態についての理解を形成するのは、イベントが実際に発生した時点よりも遅いことは避けられません
例えば、2021 年 8 月 11 日のデイリーリスナーの状態は、2021 年 8 月 12 日の 1:00 よりも後にシステムによって把握されます
ポッドキャストリスナーのデイリー状態を把握するためには、最低でも 1 時間から 25 時間のスキューがあります
処理エラー 2021 年 8 月 12 日の 1:00 に処理された総リスナー数には、計算上のエラーがあり、2021 年 8 月 11 日のデイリーリスナーの総数を 2,005 人ではなく 3,000 人として捉えています
訂正 2021 年 8 月 12 日の 1:00 に発生したエラーは、データ製品開発者によって発見され、処理コードに修正が加えられ、次の処理間隔である 2021 年 8 月 13 日の 1:00 に正しい値である 2,005 が報告されます
したがって、処理時間 2021 年 8 月 13 日の 1:00 で提供されるデータには、2021 年 8 月 11 日と 2021 年 8 月 12 日のデイリーポッドキャストリスナーのデータが含まれます
図 12-4 では、データの提供インターフェースや API が 2 つの時間パラメータ、処理時間と実際の時間を持つ関数として機能していることが示されています
使用の簡便さのために、最新のデータの状態に関心があるデータ利用者のために latest のような特別なデフォルトパラメータを使用することができます
この例では、簡単のために低解像度のウォールタイムを使用しています
ガバナンスは、時間の標準化方法を標準化し、プラットフォームがそれを一貫して実装する役割を果たします
処理時間は、順序付けられた読み取りを保証します
これは、内部システム時間、エポック以降の増分カウンタ、または単調に増加する数値として実装することができます
データ消費者は、処理時間をインデックスとして使用して、自分が消費したデータを知ることができます
実時間は ISO 8601 などの DateTime 標準に従うことができます
分析データのデータユーザーは、データにアクセスする際に、時間を旅行してデータを遡ったり、前へ進んだりすることができます
遡れる限界は、最初に処理されたデータまでか、最新のデータまでかは、データ製品の保持ポリシーによります
図 12-5 は、この時間軸を横切るタイムトラベルの簡単な可視化を示しています
図 12-5
処理時間の軸上でデータを提供する 状態、イベント、またはその両方 システムがデータをエンコードおよび処理する方法は、状態とイベントの 2 つのキャンプに分かれます
状態は、時間のある時点でのシステムの状態を捉えます
例えば、「今日のポッドキャストのリスナー数」です
イベントは、特定の状態の変化の発生を捉えます
例えば、「新しいポッドキャストのリスナーが接続した」といった具体的な変化の発生です
状態または（変化の）イベントによって、データの格納や提供方法は非常に異なるものになりますが、ここで議論した時間の次元とは異なる関心事だと考えています
ストリーム上の変更イベントをキャプチャしたり提供したりするか、またはシステムの推論された状態のスナップショットのストリームをキャプチャしたり提供したりするかは、データ製品のロジックによりますが、おそらくデータの読み取り手は両方を見たいと考えるでしょう
それにもかかわらず、2 つの時間軸の存在は残ります
取り消された変更の機会を減らす 既に述べたように、過去のデータ（取り消し）は、修正や新たなデータの到着と同様に処理されます
修正されたデータは、過去に属する実際の時間を持つ新しいデータエンティティとして提示されますが、新しい処理時間を持ちます
また、次のセクション「読み取り専用アクセス」では、データ更新の特別なハンドリング（たとえば、メッシュレベルでの削除権の行使）を紹介します
取り消しを処理するための手法に関わらず、データ製品はエラーを減らし、修正の必要性を減らすことを目指す必要があります
以下に、修正の必要性を減らすためのいくつかの戦略を紹介します
品質管理のために処理時間間隔を増やす プレイイベントのデータ製品を想像してください
これは、プレイヤーのデバイスからのシグナルをキャプチャします
データ製品は、時々イベントを見逃したり遅れて受信したりすることがあります
これは、ネットワークの中断、デバイスキャッシュへのアクセス不可などが原因です
しかし、データ製品の変換コードは、欠落したシグナルを予測または生成したもので補正するための処理遅延を導入することができます
または、同じデータの中央値や他の統計的表現にシグナルを集約することもできます
これは、データ製品がエラーを修正し、取り消しを避けるために、実際の時間と処理時間の間により長いズレを導入していることを意味します
これは、和解が必要なビジネスプロセスに対してしばしば適した技術です
例えば、支払いトランザクションをほぼリアルタイムで受け取る一方で、修正されたおよび和解済みの支払い口座データのデイリーダンプが後で提供される場合があります
これには、処理間隔の増加が必要です
支払いの場合、トランザクションの迅速さよりも口座の正確性が優先されます
期待されるエラーを反映したデータ製品の SLO（サービスレベル目標）を調整する
前述の例を続けると、一部のコンシューマーは、ほぼリアルタイムのデータにおけるエラーに完全に寛容です
例えば、プレイヤーエラーを検出するアプリは、ここにあることとかなり関係なく、欠落したイベントを気にしません
この場合、プレイイベントのデータ製品は、「プレイヤーエラー検出」といったカテゴリのコンシューマー向けに和解なしでデータを公開することができます
ただし、この場合、データ製品は、欠落するシグナルに関する予想されるエラー範囲に応じてその品質目標を伝えます
読み取り専用アクセ
データメッシュは、神話的な唯一の真実のソースの概念を受け入れない、他の分析データ管理パラダイムとは異なります
各データ製品は、その能力の範囲内で特定のドメインの現実の真実の一部を提供します
データは 1 つのデータ製品から読み取られ、変形および変換され、次のデータ製品によって提供されることがあります
メッシュは、上流のデータ製品から下流の消費者に対してバイテンポラルな不変のデータを付加することによって、変化の伝播を通じてその完全性を維持します
したがって、新しいデータがグラフを通じて伝搬する際には、メッシュは最終的な整合性の状態を維持します
これまでにも、メッシュまたは個々のデータ製品が直接的な更新機能を持っていないことは明らかになっているかもしれません
更新は、データ製品が入力を処理する結果として間接的に行われます
データ製品への変更は、新しく処理されたデータの追加の形でのみ、データ製品の変換コードによって行われます
これにより、データの不変性が保証され、メッシュの最終的な整合性が維持されます
ただし、GDPR などの規制に従って削除の権利を行使するためのグローバルガバナンス管理機能などの場合には、データが変更されます
これは、メッシュエクスペリエンスプレーンによってトリガーされる特定の管理機能として考えることができます
すべてのデータ製品の制御ポート（「コントロールポート」）上でコマンドを実行し、この場合は暗号化の破棄を行います
データ製品は常にユーザー情報を暗号化してエンコードします
暗号化キー（プラットフォーム上に存在し、データ製品内には存在しない）を破壊することで、ユーザー情報は実質的に読めなくなります
すでに処理されたデータを更新するために特別な操作が必要な特殊なケースがある場合は、この操作はグローバルコントロールポート機能として実装されます
アウトプットポートの機能ではありません
アウトプットポートは、データユーザーがデータを読むだけに使用します
データの提供デザイン それでは、データ製品のデータ提供のデザインをまとめてみましょう
図 12-6 は、おそらくの論理アーキテクチャを示しており、データ製品が自らのドメインのコア表現を所有し維持し、それを複数の空間モダリティで提供するために、アウトプットデータポートアダプタの概念を使用しています
各ポートは常にバイテンポラルで不変で読み取り専用のモードでデータを提供します
データの保持期間は、データ製品のポリシーによって異なります
多くの観測（処理時間）のためにデータを保持しアクセス可能にする場合、最新のデータのみを保持する場合、その中間のどこかにする場合があります
表 12-1 は、データを提供するために関与するデータ製品の構成要素をまとめたものです
表 12-1. データを提供するためのデータ製品の高レベル構成要素 データの提供構成要素 説明 出力データポート 特定のアクセスモード（構文）に従ってデータを提供するためのインターフェース（API）
この実装は、単に特定の物理技術（例：データウェアハウスのバイテンポラルテーブル、データレイクのファイル、イベントログのトピックなど）へのアクセスをリダイレクトする API である場合もあります

出力（データ）ポートアダプタ 特定の出力ポートでデータを表示するためのコード
この実装は、データ製品の変換コード内の単純なステップでデータを特定の構文で格納する場合から、読み取り時にコアデータを多くのアクセスモードに適応するためのランタイムゲートウェイとしての高度なものまで、さまざまです
コアデータの意味 データの意味表現-アクセスモードまたは空間構文に依存しない形での意味表現

データの消費
多くの場合、組織内または外部の運用システムからのデータは、人々やデバイスなどの他の運用エージェントとの相互作用によって生成されます
場合によっては、データは購入または無料でダウンロードしたアーカイブとして受け取られます
例えば、Daff の運用データは、リスナーが異なるコンテンツに購読し、聴取し、コンテンツプロバイダが音楽を公開し、アーティストマネージメントチームがアーティストの業務を支払い、処理することによって生成されます
データ製品は、このデータを消費し、分析用途に適した方法で変換して提供します
したがって、多くの場合、データ製品は 1 つまたは複数のソースからデータを消費します
アーキテクチャ的には、入力データポート（「入力データポート」）は、データ製品がソースデータを定義し実行するために必要なメカニズムを実装します
入力データポートは、データ製品がデータソースに接続し、クエリを実行し、データ（イベントまたはスナップショット）を連続したストリームまたはワンオフのペイロードとして受信するための論理的なアーキテクチャ上の構造です
基礎となる技術の選択は、実装固有の問題であり、データプラットフォームに委ねられています
図 12-7 は、データ製品がデータを消費する方法の高レベルなイメージを示しています
データ製品は、1 つまたは複数のソースからデータを消費します
ソースは、共同の運用システムまたは他のデータ製品である可能性があります
消費されたデータは、次のようにしてコアデータモデルに変換され、出力ポートを介して複数の形式で提供されます
図 12-7
データ製品がデータを消費するための設計
各データ製品には 1 つまたは複数のソースがあります
ソースに合わせられたデータ製品（「ソースに合わせられたドメインデータ」）は、大部分のデータを運用システムから消費します
集約データ製品（「集約ドメインデータ」）になると、他のデータ製品がソースになり、消費者に合わせたデータ製品（「消費者に合わせたドメインデータ」）では、特定の使用ケースのためにローカルにソース化されたデータを提供するためにスマートロジックや機械学習モデルがしばしば含まれています
データ製品の入力データの設計に影響を与えるいくつかの注目すべき特性について詳しく見てみましょう
データソースの原型
入力機能の設計は、複数のデータソースの原型をサポートする必要があります
以下はいくつかの上位カテゴリです： ・共同の運用システム ・他のデータ製品 ・自己
共同の運用システムとしてのデータソース
ソースに合わせられたデータ製品は、ドメインの業務を実行する際にデータを生成する 1 つまたは複数のアプリケーションからデータを消費します
彼らは運用システムに最適化されたデータを消費し、分析目的に適した形式に変換します
彼らは、下流の分析ユースケースを運用アプリケーションの内部の詳細から切り離します
ここでの共同作業というフレーズは、データ製品とそのソース運用システムの密な結合を意味します
両者は同じドメインに属している必要があります
ソースアプリケーションとデータ製品の間の運用データ契約は、しばしば密接に結びついており、運用システムのデータとモデルの変更がデータ製品のデータとモデルに影響を与える場合があります
そのため、共同の運用システムソースとそれらの共同作業データ製品を同じドメインに保つことを強くお勧めします
これにより、運用システムの変更を担当するドメインチームとデータ製品開発者が密接に協力して両者を同期させることができます
CRM COTS（商用の顧客関係管理）製品など、1 つのドメインに統合された複数のドメイン（製品、顧客、販売など）をカプセル化した運用システムが単一のドメインに対応していない場合もあります
その場合、COTS システムは、特定のソースに合わせたデータ製品ごとにドメインに合わせたインターフェースを公開することができます
図 12-8 は、共同の運用システムからの入力を持つデータ製品の例を示しています
リスナーサブスクリプションデータ製品は、そのドメインのマイクロサービスであるリスナーサブスクリプションサービスからデータを消費します
リスナーサブスクリプションの変更をリアルタイムに近いイベントとしてイベントログに公開します
サブスクリプションイベントログは、運用システムによって制御および保守される短期間の保存媒体です
データ製品はイベントを消費し、それらに変換を行い、最終的にはリスナーサブスクリプション情報の長期間のビューとして提供します
図 12-8
共同の運用システムからの入力を持つデータ製品の例
共同の運用システムからデータを消費するための入力ポートを実装するための一般的なメカニズムには、モダンなシステムの場合は非同期のイベント駆動型データ共有、レガシーシステムの場合は変更データキャプチャが含まれます
ドメインイベントを共有するモダンな運用システムは、ますます一般的な実践となり、協調的なデータ製品へのデータ供給には素晴らしいモデルです
データの変更を検出して追跡するための統合パターンのセットである変更データキャプチャは、データ製品の入力ソースとして利用できますが、それは協力している運用システムからデータを受け取る最も望ましくない方法です
データベーストランザクションの内部実装を露出し、ビジネスドメインには対応していません
ただし、旧来のシステムの場合は、これが唯一の利用可能なオプションとなることもあります
データ製品が運用システムからデータを消費する方法は、運用システムの拡張能力に大きく影響を受けます
設計は、ドメインチーム内で、運用システムとデータ製品をどのように統合するかについての合意に最終的に依存します
他のデータ製品としてのデータソース データ製品はメッシュ上の他のデータ製品からデータを消費することができます
例えば、ポッドキャストの人口統計データ製品は、リスナープロファイルとポッドキャストリスナーのデータ製品からリスナーに関する属性を受け取ります
それはリスナープロファイル情報をポッドキャストリスナーと関連付け、これらのソースに分類変換を適用します
それからポッドキャストの人口統計に関する情報を提供します
この例は図 12-9 に示されています
図 12-9. 他のデータ製品からの入力を持つデータ製品の例
この場合、入力ポートは別のデータ製品の出力ポートからデータを消費します
ソースデータ製品は、同じドメインに属するか、他のドメインに属することができます
ただし、入力データポートの実装と、どのようにして他のデータ製品の出力ポートからデータを消費するかは、標準化されています
データ製品は、上流の出力の実際の時間と処理時間を利用して、必要なデータを選択します
ストリーミング入力の場合、入力ポートの仕組みはソースデータの処理時間を追跡して、新しいデータが到着するたびにそのデータを処理します
データ製品としての自己をデータソースとして
一部の場合、データ製品のローカルな計算がデータのソースになることがあります
たとえば、アーティストの分類に関するデータ製品では、アーティストオンボーディングマイクロサービスから受け取った情報に加えて、「新興」や「衰退」などのデータを生成する機械学習モデルの推論など、ローカルな変換が新しいデータを生成します
さらに、データ製品は、入力として可能な分類のリストなど、ローカルに保存されたデータも使用します
図 12-10 に示すアーティストのデータ製品を考えてみましょう
その変換は、アーティストのオンボーディングマイクロサービスから受け取る情報に加えて、「新興」や「衰退」といったアーティストの分類に関する新しいデータを生成する機械学習モデルを実行します
図 12-10. ローカル入力を持つデータ製品の例
データ消費の局所性
データメッシュは、基盤となる技術についてはできるだけ中立です
データメッシュアーキテクチャは、基盤技術やインフラストラクチャに関しては中立であり、可能な限り実装の詳細には立ち入りません
例えば、データが物理的にどこにあるか、データ製品がデータを物理的にコピーして別の場所に移動するかどうかは、プラットフォームによって構築された実装の詳細です
しかし、入出力ポートなどのデータメッシュアーキテクチャの構成要素は、データや処理の移動を物理的な境界を越えて抽象化するための優れたインターフェースです
データ製品の入力ポートを他のデータ製品の出力ポートに接続する一連のシンプルな API を使用すると、データが物理的なストレージや信頼境界を越えて移動することを隠すことができます
同様に、データ消費リクエストの実行は、1 つの計算環境から別の計算環境に発行されるリモートクエリを実行することができます
この設計の結果、メッシュは 1 つまたは複数の物理インフラストラクチャ、複数のクラウド、およびオンプレミスのホスティング環境にまたがることができます
つまり、データ製品がソースからデータを消費する場合、そのプロセスでデータを基盤となるホスティング環境から別のホスティング環境に物理的に移動することができます
このように見える単純な機能は、クラウドへのデータ移行やマルチクラウドデータプラットフォームに深い影響を与える可能性があります
たとえば、Daff は現在、分析データと処理データをクラウド環境に移行しています
今日、ポッドキャストサービスはオンプレミスのインフラストラクチャと、その基盤となる運用データベース上で実行されています
ポッドキャストリスナーデータ製品はクラウド上で動作します
非同期の入力データポートインターフェースを介してデータを消費します
新しいポッドキャストリスナーが登録されると、ポッドキャストリスナーデータ製品は基本的に、オンプレミスのストリームからその情報をクラウドストレージにコピーし、その後クラウドベースの出力データインターフェースを介して利用可能にします
これにより、ビッグバンデータ移行戦略なしで、データ製品間での継続的なデータ移行が実行されます
同じメカニズムを使用して、データを 1 つのクラウドプロバイダから別のクラウドプロバイダに移動することもできます
たとえば、企業がマルチクラウド戦略を持っており、複数のクラウドプロバイダにわたってデータを保持したい場合、入力ポートの実装により、データをソースのクラウドプロバイダから利用者のクラウドプロバイダに移動することができます
もちろん、この実現のためには、基盤となるプラットフォームインフラストラクチャが、データ製品のインターネット対応のデータ利用可能性、トラスト境界を超えたアイデンティティ認証と承認、および出力データポートのインターネットアクセス可能なエンドポイントなど、いくつかの重要な機能をサポートする必要があります
図 12-11 は、2 つの異なる環境間で 2 つの異なるデータ製品間でのデータ消費を示しています
図 12-11
マルチ環境データ消費モデルデータ消費デザインデータ製品は、どのデータをどのソースからどのように消費するかを意図的に指定します
データ製品は、データを消費する能力を明確に定義および制御します
これは、他のデータアーキテクチャとは異なり、ソースがデータがどこにどのように到達するのかを知らずにデータをプロセッサにダンプするものです
たとえば、以前のアーキテクチャでは、外部の有向非循環グラフ（DAG）の仕様が、各プロセッサがデータをどのように受け取り、提供するかを定義するのではなく、各プロセッサが中央的に接続される方法を定義します
図 12-12 は、入力データポートを介してデータを消費するためのデータ製品の高レベルな設計コンポーネントを示しています
図 12-12
データ製品のデータの消費を設計するための高レベルなコンポーネント表 12-2 は、データ製品のデータの消費を設計するための高レベルなコンポーネントの要約です
表 12-2
データ製品のデータの消費を設計するための高レベルなコンポーネントの要約データの消費コンポーネントの説明入力データポートデータ製品がソースデータを受け取り、さらなる内部変換のために利用可能にするメカニズム
入力データポートの仕様入力データポートの宣言的な仕様で、データがどこからどのように消費されるかを構成します
非同期入力データポート非同期入力ポートの実装は、必要なソースデータが利用可能になったときに変換コードを反応的に呼び出します
イベントストリームへのサブスクリプションやファイルへの非同期 I/O 読み取りなどが、非同期入力ポートの例です
非同期入力ポートは、ソースデータ製品の処理時間ポインタを追跡し、新しい処理時間のデータを受け取ると、変換を反応的に実行します
同期入力データポート同期的な入力ポートは、ソースからデータを取得し、データが取得されたときに変換コードを呼び出します

たとえば、「デイリーポッドキャストサマリー」は、ポッドキャストリスナーからデータを同期的に取得し、データが取得されたときにカウントやその他のサマリーを計算します
データは毎日真夜中に取得されます
リモートクエリ入力ポートの仕様には、受け取る必要のあるデータに対してソース上で実行されるクエリを含めることができます
この機能により、重複して取得されるデータの量を削減することができます
クエリは、ソースが理解する問い合わせ言語（SQL、GraphQL、Flux など）で表され、入力ポートの仕様によって定義されます
入力ポートの同期化と一時的なストレージ入力ポートは、しばしばお互いに依存してデータを消費します
たとえば、アーティスト分類の変換コードは、アーティストとリスナーの 2 つの独立したソースからのデータが利用可能になるまで実行を開始することができません
一時的なストレージは、処理が必要な観測済みおよび未処理のデータを追跡するために必要です

データの変換
ほとんどのデータ製品は、どんなにわずかであっても変換を行います
私たちは新しい分析モデルを既存のデータと共有することで価値を見出してデータ製品を作成します
この新しいモデルを作成するには、変換が必要です
変換コードの作成と保守こそが、データ製品開発者が最も注意を払うものです
従来、この変換は、データパイプライン内でデータを入力元から出力先に移動させることで行われていました
データメッシュの設計では、パイプラインとして実装されているかどうかに関わらず、変換はデータ製品によってエンコードされ、抽象化されます
変換はデータ製品の内部実装であり、それによって制御されます
内部の問題であるため、具体的なデザイン方法について指定するつもりはありません
私の意見では、変換の実装方法は、データ製品開発者の好み、能力、ニーズによって選択されるべきです
データ製品の変換の実装方法をいくつか見ておくと役に立ちます
プログラマティックな変換と非プログラマティックな変換
データの処理と変換は、非プログラマティックな変換（例：SQL、Flux、GraphQL）とプログラマティックなデータ処理（例：Apache Beam、Apache Spark、Metaflow）の 2 つの主要な分野に分類されます
非プログラマティックなアプローチでは、SQL などの関係代数を使用したセット演算、または Flux などのフローベースの関数を使用します
いずれの場合も、データがどのように変換されるかの意図をステートメントで捉えることができます
これは多くのデータ製品開発者にとってシンプルでアクセスしやすいアプローチですが、ステートメントの機能に制限があります
より複雑な変換では、ステートメントが理解しにくく、モジュール化が難しく、自動的にテストすることも難しくなります
実際のところ、非プログラマティックな変換のみを行うデータ製品はあまり見つかりません
他の下流データ製品は、同じリモートクエリを自身で実行できるため、中間データ製品は必要ありません
図 12-13 は、非プログラマティックな変換の例を示しています
意図は、トップリスナーの人口統計情報を作成することです
トップリスナーのデータ製品は、今日の曲の再生履歴とリスナープロファイルの入力ポートを使用して、今日曲を聴いたリスナーのプロファイル情報を取得します
その後、リスナーの人口統計情報（例：今日最もリスナーの多い年齢層、あるいは最も少ない年齢層、今日最もリスナーの多い国、あるいは最も少ない国など）をさまざまな統計情報として生成します
図 12-13. 非プログラマティックな変換の例 一方、プログラマティックなデータ処理では、コードのロジック、条件、ステートメントを使用してデータを変換します
Apache Beam や Apache Spark などのプログラミング言語（Python、Java など）を使用したプログラマティックなデータ処理ライブラリを使用できます
変換コードは、ホスティングプログラミング言語の完全な機能にアクセスできます（命令型または宣言型のいずれか）
モジュール化やテストも可能です
このアプローチは、非プログラミングのデータ製品開発者にとってはより複雑ですが、拡張性があります
このアプローチの利点は、再生された曲のレコードが到着するたびに統計情報を増分で計算できることです
データメッシュは、データ製品が変換のためにどのアプローチを採用するかについて立場を取らず、常識に頼るとされています
より複雑なユースケースにはプログラマティックなアプローチを使用し、変換が些細で非プログラマティックな場合は、何もせずに中間データ製品を作成しないでください
最終的な消費者にクエリを実行させます
なお、プログラマティックな変換の場合でも、入力ポートは処理の前にソースで非プログラマティックなクエリを呼び出す場合があります
これにより、変換コードに移動するデータの量が減少し、処理が上流のデータが存在する場所にプッシュされます
データフローベースの変換データフロープログラミングパラダイムは、1960 年代に導入され、データが操作間を流れる有向グラフとしてコンピュータプログラムを定義します
このプログラミングパラダイムは、現代のデータパイプラインデザインに多くの影響を与えています
データパイプラインは、データが一つのステップから別のステップに流れるときに実行される一連の変換ステップ（関数）です
データメッシュは、パイプラインをトップレベルのアーキテクチャパラダイムやデータ製品の間で使用しないようにします
現在使用されているパイプラインの問題は、パイプラインの複雑さが増すにつれて、明確なインターフェース、契約、および抽象化が容易に維持できないことです
抽象化の不足により、パイプライン内の単一の障害が連鎖的な障害を引き起こします
パイプラインまたはデータ製品の範囲内でのパイプラインまたはデータフローベースのプログラミングモデルは、変換コードを実装するための自然なパラダイムです
このシナリオでは、パイプラインは単一のデータ製品のコンテキストと変換によって制約されるため、複雑さが低くなります
また、データ製品とともに単一のユニットとしてアップグレード、テスト、展開されます
したがって、パイプラインステージのタイトカプリングはあまり心配されません
要するに、データ製品の範囲内での変換にはデータパイプラインを使用しても構わないということですが、パイプラインステージがデータ製品の範囲を超えない限りです
データ製品間で変換が行われることはなく、読み取り専用の出力および入力データポートを通じてデータの提供と消費が行われるだけです
私はこれを「ダンブパイプとスマートフィルタの原則」と呼んでいます
図 12-14 は、パイプライン変換に関与するハイレベルのコンポーネントを示しています
図 12-14
パイプライン変換 ML としての変換三つ目の変換カテゴリはモデルベースです
機械学習や統計モデルをデータ製品の変換として展開し、実行することです
例えば、リスナーの既存のプレイリストを拡張するための TensorFlow リコメンダを使用して、デフが曲を推薦すると想像してください
TensorFlow モデルはシリアライズされ、プレイリストリコメンダデータ製品として展開されます
データ製品はリスナーのプレイリストを消費し、次に推薦される曲を予測し、それらをプレイリストの拡張推薦として保存します
それらはリスナーがリストを再生する際に読み取られて使用されます
リコメンダモデルはプログラムと所望のプログラミング言語内で実行されますが、その計算は主にモデルによって行われます
ML モデルは、マイクロサービスやアプリケーション、データ製品など、さまざまなコンテキストで展開できます
時間変動変換すべての変換の共通の特徴は、時間の軸に敬意を払うことです
処理時間と実際の時間です
変換コードは、入力を処理するときと出力を生成するときに、時間パラメータを意識しています
入力ポートメカニズムは、各ソースの処理時間を追跡します
変換コードは、ソースデータ上で行われた計算に基づいて出力の実際の時間を生成します
出力ポートは、データ製品の内部処理時間のカウントと共に変換されたデータを提供します
変換デザイン変換のデザイン、ビルドタイムの定義、展開、実行は、選択したフレームワークや基礎となる技術に大きく依存しています
変換が宣言的な文またはプログラミングコードによって実装されるかどうかにかかわらず、変換をビルド、テスト、展開、実行するためにプラットフォーム機能が必要です
図 12-15 は、データ製品の変換に関与するいくつかのハイレベルなデザイン要素を示しています
図 12-15
データ製品の変換を設計するためのハイレベルのコンポーネント表 12-3 は、データ製品の変換機能を設計するために関与するハイレベルコンポーネントをまとめたものです
表 12-3
データ製品のデータ変換に関与するハイレベルコンポ―ネントのまとめデータ変換コンポーネントの説明変換アーティファクト変換を定義するコード、設定、文またはモデル
このアーティファクトは、特定のレコード時間のために入力データ上で実行され、出力を生成します
変換ランタイム環境は、変換の設定に基づいて呼び出されます
例えば、定期的な時間基準や必要な入力データの可用性に基づいて呼び出されます
呼び出されると、データ製品コンテナによって制約される計算環境が必要です
基礎となるプラットフォームはこの環境を提供します
一時的なストレージ変換コードのステップは、変換のさまざまなフェーズで状態を保持するために一時的なストレージへのアクセスが必要となる場合があります
これは基礎となるプラットフォームによって提供されます

要約
この章では、データ製品のデザイン要素と特性をアーキテクチャの量子として紹介し、データの自律的な消費、変換、提供を行います
分散メッシュアーキテクチャでデータを提供するために、データ製品の出力ポートにはいくつかのプロパティがあります
読み取り専用およびマルチモーダルな API を介して、時間的にバイアスを持った不変のデータを提供します
これらの制約は、データメッシュの目標と前提によって駆動されました
データ製品は、ドメイン指向のデータを多様なデータユーザーにネイティブに提供します（マルチモーダルアクセス）
データ製品は、時間的な分析ユースケースで使用できます（時間的バイアス）
データ製品は、他のデータ製品からデータを安全に取得し、変換して提供すると同時に、特定の時点での一貫性のグローバルな状態を維持します（時間的バイアス）
データ製品のユーザーはデータを分析および機械学習のために処理します（読み取り専用）
データ製品は、どこからどのように上流データを受け取るかを制御できます
入力ポートを使用して、同じドメイン内の協力的な運用システムまたは上流データ製品からデータを取得します
入力ポートは、マルチクラウド展開またはインクリメンタルなクラウド移行を支援するために、異なるホスティング環境間でのデータ移動を実装することができます
データ製品はほぼ常に、より高い価値のあるデータを提供するために何らかの形式の変換を行います
変換の具体的な実装方法は、データパイプライン関数、高度なクエリ、または機械学習モデルの推論など、複数の形式を取ることがあります
この章では、データ製品のデザインにおけるデータ共有のコア機能に対する高レベルな思考とアプローチを提示しました
将来のデータメッシュの実装では、この思考を評価し、改善することを期待しています

## 感想とまとめ

- いろんなことが書いてあって難しかった
- 実際の時間と処理時間を属性としてもつデータにするにことでイミュータブルなデータにして、一貫性を保つということはなるほどって感じ
- どのような input port が必要か、output port が必要かってのがわかったので、これをプラットフォームとして実装する必要がありそう
  - どのクラウド、もしくは k8s にするかみたいなところは難しそう
  - あとは、現在あるデータの仕組みにどくらい透過的にこの仕組みを実装できるのかが肝になりそう
  - 全く邪魔しない様に作って、その仕組み自体はなんでも変更できるって感じだったら良い
  - っていうか本当はそうのようにするべきだし、実装する部署のデータ構造などを気にしてプラットフォームを作ることはよくない気がする
  - 本当にアダプターとポートって感じにするべき
    - その API には簡単かつ安全に push pull できる様にすべき
    - まずは簡単なでも環境は k8s とかで作ってみるのが面白そう
