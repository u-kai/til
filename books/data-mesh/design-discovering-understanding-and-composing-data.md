データメッシュのアプローチの特徴は、中央集権的なボトルネックを作成せずに、相互に接続された自律データ製品の分散メッシュ内でデータを発見、理解、信頼する方法です
同様に、既存の複数のデータの交差点や集計から新しいデータを構成することは、すべてのデータ作業に必要な基本的な機能です
データメッシュは、変更のためのボトルネックにならないように、分散型の方法で複数のデータ製品を構成する能力を導入します
この章では、データの発見性と合成性の各要素を簡単に紹介します
各個々のデータ製品が、それぞれの地域で発見性、理解性、合成性を果たすようにデザインされるように、データメッシュのポジションを説明し、デザイン上の考慮事項を紹介します
これにより、多くのデータ製品間でメッシュレベルの機能が提供され、緊密に結合された同期ポイントが作成されることなく、各データ製品のローカルな特徴が明らかになります
この章では、データメッシュアプローチの範囲、データメッシュの目標と互換性のあるもの、およびないものを説明します
具体的な仕様はまだ定義されており、テストされていないため、本書の範囲外です

Discover, Understand, Trust, and Explore
データメッシュは、データ製品の本質的な特性として、つまり、発見可能性、理解可能性、信頼性、および探索可能性として、データの発見、理解、信頼、探索を定義します
私は第 3 章でこれらを簡単に紹介しましたが、これらの特性は、データユーザーの旅を可能にするために重要です
つまり、適切なデータを見つけて、それを理解し、信頼し、分析のユースケースに適したものかどうかを探求するためのものです
これらの特性は、次のような質問に答えます
リスナーに関する情報を提供するデータ製品はありますか？リスナーに関するデータ製品が実際に提供する情報は何ですか？それを信頼できますか？特定のデータ要件を持つ特定のユースケースで使用できますか？早期の実験のためにアクセスする方法はありますか？など
これまでにこの点については議論はないと思います

データメッシュが現在の大多数のデータ発見手法、つまりデータカタログサービスと異なる点は、それらの能力をどのように実現するかです
執筆時点では、2 つの確立されたアプローチがあります
私は、最初のアプローチを事後のキュレーションと統合、と呼んでいます
このアプローチでは、データスチュワードやガバナンスチームのメンバーが、ドメインで既に生成されたデータに関する識別、タグ付け、文書化、統合のタスクを担当します
その後、このキュレーションされた情報が発見の情報源となります
もう 1 つのアプローチは、事後の調査型インテリジェンスと呼んでいます
このアプローチでは、既に生成されたデータに対して事後に解放されるインテリジェントマシンの観察を適用して、メタデータを抽出します
たとえば、大量の運用データに対してアルゴリズムを実行して、テーブルの信頼性を決定することができます
それは、誰がアクセスしたか、どれだけ広く使用されているか、どのように使用されているかを分析します
この情報は、発見性のための有用なデータの知識の層を作成します

ただし、インテリジェントで調査型のアルゴリズムは、データメッシュをブートストラップするのに役立つだけでなく、データメッシュを実施する前に組織が利用可能なデータを見つけるための情報を追加することで、メッシュの観測可能性を支援しますが、それだけでは不十分です
データメッシュの最も大きな違いは、発見性を左にシフトさせることです
データの発見性、理解性などは、データ製品そのものが作成され、そのライフサイクル全体で始まります
データ製品が自分自身を発見可能、理解可能、信頼できる、探索可能にするために必要な情報を共有する責任があります
データメッシュは、機械と人間がデータ製品を発見、理解、信頼、探索するためのアクセスのために、発見性を設計します
機械はこれらの機能を自動化し、上位の能力を構築することができます
例えば、メッシュエクスペリエンスプレーンは、各データ製品が提供する発見データを使用して、データ製品の検索を自動化することができます
発見（ポート）API の概念は、Chapter 9 で簡単に紹介されました
このセクションでは、発見ポートの実装におけるいくつかの設計要素について説明し、他のアプローチと比較してデータメッシュと異なる点に焦点を当てます
発見と理解は、この章でカバーする内容に限られていません
Chapter 14 の「観察、デバッグ、監査」セクションでさらに詳しく説明します
図 13-1 は、発見プロセスに関わるハイレベルな相互作用を示しています
図 13-1. データ製品の発見性、理解性、信頼性、探索性に関するハイレベルな設計の例
メッシュエクスペリエンスプレーンは、検索やブラウズ機能などのメッシュレベルの発見性において重要な役割を果たします
メッシュレベルの操作は、データ製品が提供するデータと API を介して可能になります
一部の発見性情報は、データ製品にスコープを限定されます（たとえば、そのセマンティック仕様やドキュメントなど）、また、その出力ポートごとにスコープを限定されるものもあります（たとえば、データの形式仕様、統計的な特性やデータの形状、品質メトリクスと SLO など）
もう少し詳しく見てみましょう
自己登録での発見の開始
エンティティの発見は、その存在の認識とその場所やアドレスを特定する能力から始まります
データメッシュでは、発見はデータ製品が広いエコシステム、特に検索やブラウズなどのデータプラットフォームのメッシュエクスペリエンスプレーンサービスにその存在を知らせることから始まります
名前、アドレス、場所などの様々な情報の割り当ては、データ製品の構築、デプロイメント、実行時の異なる段階で行われます
サービスメッシュなどの運用プラットフォームには、サービスの登録、アドレスの指定、および特定の場所の指定に関する先行技術があります
同様の技術とアプローチをここで展開することができます
データ製品が発見を開始するために必要な最小限の情報は、さらなる情報のクエリングのための唯一の名前（識別子）としてのアドレス可能なエンドポイントです
グローバル URI を発見してください
理想的には、すべてのデータ製品には自身を記述するための標準的なインタフェースがあります
これは、データ製品の他の発見要素にアクセスするためのルートとなるグローバルにアクセス可能な URI（Uniform Resource Identifier）です
このような発見 API で提供される情報には、コアデータのセマンティック仕様、全体的なドキュメント、アクセスログ、およびそれぞれの出力ポートに特有のデータ構文などの深層情報が含まれます
データ製品の発見 API によって提供される情報は、ライフサイクルの異なる段階で更新することができます
スキーマの仕様などの一部はビルド時に既知であり、データの形状を説明する統計などの他の情報はランタイムで作成されます
データ製品の開発者は、データ製品の発見可能性情報をデータ製品のデータと一緒に維持し、データ製品エクスペリエンスプレーンが提供する標準化された発見 API などのデータプラットフォームコンポーネントを使用します
データユーザーは通常、メッシュエクスペリエンスプレーンを介して発見と検索を開始し、特定のデータ製品の発見情報に迅速に深入りすることができます
セマンティックおよび構文モデルの理解 すべてのモデルは間違っているが、一部は有用である -ジョージボックス データは、モデルに従って集められた事実の集まりです
データモデルは、（分析の）タスクに十分なだけの現実の近似です
時間の経過とともに、データモデリングのアプローチは進化してきました
執筆時点では、複数の一般的な実践があります：リレーショナルテーブル（SQL データストア）、ネストされたツリー構造に関係をフラット化したもの（JSON 構造）を列または行として保存したもの、エンティティと関係の両方にプロパティがあるもの（グラフデータベース）、セマンティックウェブ（Semantic Web）、時系列データモデリングなど
一部のモデリングスタイルは、より表現豊かで、直感的な人間の世界理解により近いものであり、一部のスタイルは機械処理に最適化された損失モデルです
例えば、プロパティグラフは、エンティティ、そのタイプ、プロパティ、およびエンティティ間の関係を説明することで、世界をより直感的にモデル化することができます
最も重要なことは、関係のタイプとプロパティを明示的にモデル化することができることです
これは、階層化された表形式とは異なり、属性値に基づいて関係の性質について仮定をする必要がある場合があります
図 13-2 は、プレイリストドメインをプロパティグラフとしてモデリングした高レベルのモデル化を示しています
図 13-2
プレイリストドメインのプロパティグラフとしてのセマンティックモデリングの例
理想的には、データ製品はビジネスドメインデータをビジネスの現実にできるだけ近づけてモデル化します
これをデータ製品のセマンティックモデルと呼びます
これは、マシンと人間が読めるモデル定義であり、データのドメインモデルを記述します
どのようにデータ製品がドメインをモデル化し、データに含まれるエンティティの種類、エンティティのプロパティ、エンティティ間の関係などです
セマンティックモデルに加えて、データ製品はアウトプットポートがサポートするアクセスモデルに応じて、その意味論をエンコードします
これを構文モデルと呼びます
各アウトプットポートには独自の構文モデルがあります
例えば、プレイリストファイルのアウトプットポートは、プレイリストをネストされたテーブルとしてモデル化し、カラム形式のファイルとして保存し、JSON スキーマに従って定義します
このモデリングは、フィーチャー（すべてのレコードにまたがる列）を使用した機械学習トレーニングに最適化されています
セマンティックモデルは、構文モデルを見るだけでは隠れた仮定をしないでデータが意図するものを機械と人間の理解に役立ちます
データを意図されたモデルに対して自動的に検証するのにも役立ちます
また、より大きな知識グラフの作成にも参加します
構文とセマンティックのモデリングに加えて、データ製品のユーザーや開発者によって定義されたコード化されたデータの期待値は、データの理解に非常に役立ちます
データを保証するための信頼の確立 データを見つけるための探求において、データユーザーは特定の使用ケースに必要な保証を満たしているかどうかを評価するために、データの特定の重要な特性を評価する必要があります
これらの特性は、データ品質の客観的な指標、成熟度のレベル、標準への適合性、時間的特性など、さまざまなカテゴリに分類されます
データ製品は、これらの客観的なメトリックを計算し、共有します
これらのメトリックのいくつかについては、保証（SLOs）を定義し、維持します
例えば、プレイイベントのデータ製品は、イベントのタイムリネスを 10〜30 ミリ秒（遅延範囲）の保証として定義します
データを処理するにつれて、最新のタイムリネスメトリックを提供し、その保証を満たすよう努めます
これらのメトリックは、信頼の確立と期待設定の契約として、データユーザーとの信頼を構築する手段です
これらのメトリックの定義方法、計算方法、表示方法は、グローバルなガバナンスの関心事であり、標準化された方法で基礎となるデータ製品エクスペリエンスプレーンによって可能にされます
以下は、保証のカテゴリのリストです
このリストは例としてのみ意図されており、決して完全ではありません
これらのメトリックは、データ製品が新しいデータを処理するにつれて継続的に更新されます
他のメタデータと同様に、メトリックは時間的であり、データ製品の処理と実際の時間（または時間ウィンドウ）に依存します
「データ品質メトリック」データ品質の一連の特性がグループ化され、品質を示します
これらの属性は、データ製品が良いか悪いかを定義するものではありません
それらは単にデータ製品が達成することを期待する保証の閾値を伝えるものであり、特定の使用ケースに対して受け入れ可能な範囲内にある場合があります
例えば、プレーヤーのドメインでは、2 つの異なるデータ製品を提供することがあります
1 つはほぼリアルタイムのデータを含むプレイイベントデータ製品であり、不足や重複したイベントを含むデータの一貫性が低いです
もう 1 つはプレイセッションデータ製品であり、遅延が長いですが、データの一貫性が高いです
それぞれのユースケースにおいて信頼性が考慮されます
以下に、このカテゴリのいくつかの例を示します

- 正確さ: データが現実世界の文脈で属性の真の値をどの程度正確に表しているかを示す度合い
- 完全性: データがすべてのプロパティと実例をどの程度表しているかを示す度合い
- 一貫性: 矛盾のないデータの度合い
- 精度: 属性の忠実度の度合い

データの成熟度メトリクスについては、組織がデータ駆動型の運営モデルに対するロードマップや志向に基づいて、組織ごとに主観的に定義されると考えられます
例えば、組織は利用度（データが広範に使用されている程度）、ライフサイクル（データ製品が開発中であり、積極的に進化と最適化が行われているか、休眠状態か）、多様性（アクセスと使用ケースの数）、リンク（タイプとデータの再利用の形で他のデータ製品にリンクしている程度）など、いくつかの要素に基づいて成熟度モデルを定義することができます
データ製品は組織の標準モデルに従ってその成熟度を計算して共有します

データ標準の遵守に関しては、データ製品が相互運用性レベルを向上させるために従うことができるドメイン固有のデータモデルが存在します
例えば、医療のドメインでは、FHIR HL7 リソース定義を使用することで、組織内外の多数のデータ消費者との相互運用性レベルを向上させることができます
業界標準に適合するかどうかの決定は、利点（例：外部の相互運用性）とデメリット（例：一つのサイズに合わせたモデルへの変換コスト）を考慮に入れる必要があります
データ製品は、それらのデータモデルがどの標準に従っているかを示すことができます

時間性メトリクスについては、データ製品は本質的に時間的なデータを提供します
データの時間的な形状を示すパラメータは、データの適合性を評価するのに役立ちます
以下に、いくつかの例を示します

- エポック（実際の時間と処理時間）: データが利用可能な最も早い実際の時間と処理時間
  これはデータユーザがデータにアクセスするために過去にどれだけ遡ることができるかを示します
  データ製品のデータ保持期間を示します

- 処理間隔: データ製品がデータをどれくらい頻繁に処理するかを報告することができます
  特定の間隔がない場合、データ製品は平均、最大、最小の間隔の統計情報を提供することができます
  これにより、データ消費者は新しいデータを読み込み、処理する頻度を期待することができます

- 最後の処理時間: 最新のデータの処理時間

- 最新の実際の時間（ウィンドウ）: 最新のデータの実際の時間（またはウィンドウ）

- 実際のウィンドウ: 入力データが時間のウィンドウごとに集計され、新しいデータが作成される実際の時間のウィンドウ
  データ製品は、データの集計に使用される時間のウィンドウの範囲を示すことができます

- タイムリネス: 実際の時間と処理時間の間隔の程度
  データがよりタイムリーであれば、実際の時間とレコード時間の間隔が小さいです
  前の章で、この特性をスキューという用語を使用しました

これまでのところ、以前に挙げたすべてのカテゴリはデータ製品の提供者によって提供されています
データユーザは、データを使用する際のフェローデータユーザの経験に基づいて信頼を築きます
したがって、データ製品は、その消費者の知覚と経験を品質メトリクスのセットとして捉え、提示する必要があります
例えば、企業はデータユーザが経験に基づいてデータ製品に割り当てることができるスターなどの認識システムを開発することがあります（例：データの理解と使用におけるリードタイムの短縮、データの知覚される品質、データ製品開発チームの対応性など）
私は、前述のリストを提供したのは、データ製品が最も適切な情報を計算し、データ処理の流れの中でキャプチャし、消費者に自律的に提供して信頼レベルを高めるための指針を示すためです
現在、メタデータ管理技術の過剰な数がこのような情報を定義し、公開しようとしています
データメッシュアプローチはこれらのツールに関係なく、すべてのデータ製品が信頼メトリックを一貫して提供および管理することを期待しています
信頼メトリックを一貫したセットとして確立するためには、2 つの注目すべき過去のオープンソースの標準を参照することがあります
ウェブでのデータのベストプラクティス：データ品質語彙と、関連するデータカタログ語彙です
それらは、ウェブ上でのオープンなデータエコシステムの確立を使命として一貫した語彙を作成しようとしました
成長するにつれて、モジュール化可能でテスト可能かつスケーラブルなコードを作成するためのプログラミングサポートの不足は、それらを長期間のプロダクションコードとして維持することを困難にします
デザインの発見、探索、理解ほとんどの発見情報は、メッシュとのシームレスなエクスペリエンス、および異なるデータ製品間の公正な評価と比較を可能にするため、すべてのデータ製品で標準化する必要があります
これは、プラットフォームが情報の計算、キャプチャ、共有における標準化されたアプローチを提供するために、密接に関与する必要があることを意味します
そのために、データ製品のサイドカー（ "データ製品サイドカー"）が発見性の機能を拡張するために最適な位置にあります
第 9 章で紹介したように、データ製品サイドカーは、データ量子の計算上下文内で実行され、すべてのデータ製品で標準化されることを意図したクロスカッティングな関心事を担当するプラットフォーム提供のエージェントです
図 13-3 は、データ製品サイドカーが発見性のサポートを行うインタラクションを示しています
ここで議論されたすべての機能のリストではありません
図 13-3
データ製品サイドカーは、すべてのデータ製品の発見性の統一モデルを提供します
データの構成データを見る方法を学びます
すべてがすべてと繋がっていることに気づきましょう
—レオナルド・ダ・ヴィンチ

強力な分析ユースケースでは、複数のデータ製品と異なるドメイン間のデータの相関と接続が必要です
たとえば、新進アーティストの特定のユースケースでは、アーティストが一定期間で人気を得ているかどうかを分類する機械学習モデルをトレーニングする必要があります
このモデルのトレーニングには、アーティストの曲が含まれるプレイリスト、リスナーがアーティストの音楽を再生するプレイセッション、アーティストを言及するソーシャルメディアのコンテンツなど、メッシュ全体のさまざまなデータ製品からのデータの相関が必要です
モデルは、各アーティストと特定の時間枠のデータ製品を相関させる必要があります
図 13-4 は、この例を示しています
図 13-4
データ製品の組み合わせの例
メッシュ全体でデータを接続する必要があるデータユーザーは、複数のソースで変換を実行しているメッシュ上のデータ製品または分析レポートのようなメッシュ外の分析アプリケーションのどちらかです
私はジョイン、ユニオン、フィルター、インターセクション、検索（トラバース）など、2 つ以上のデータ製品上で実行できる操作のプレースホルダーとして、一般的な用語の相関または組み合わせを使用しています
データサービス データメッシュの実装において、データの組み合わせ可能性の設計には以下の要件が課せられます
異なるアクセスモードとトポロジーをまたいでデータを組み合わせる能力
以前の第 12 章で述べたデータの利用、変換、提供の利点を思い出してください
データは、ファイル、データベーステーブル、ストリームなどのさまざまなモードで提供される可能性があります
したがって、データを組み合わせる能力は、データの構文、基になるストレージタイプ、およびアクセスモードに対して中立的である必要があります
たとえば、前述の例にプレイイベントを追加すると、新進アーティストモデルのトレーニングは、イベントのストリームとカラムファイルとして提供されるデータを横断的に組み合わせる必要があります
その結果、単一スキーマのテーブル間で主キーと外部キーの関係を定義するという、同質のデータを前提とする既存の組み合わせ技術の多くは機能しません
分散化されたデータ製品では、リレーションシップや組み合わせ可能な情報を分散して学び、見つけることができる能力 異なるデータ製品をまたいでデータを組み合わせる前に、データユーザーは異なるデータ製品間でどのような情報が関連しているかを見つける必要があります
前述の例では、新進アーティストデータ製品の開発者は、プレイリスト、ソーシャルメディアのメンション、アーティストプロファイルなどのデータ製品でアーティストに関する情報が存在し、関連付け可能であることを知る必要があります
これは従来、共有された中央集権的な型システムまたはスキーマを介して達成されていました
一方、データメッシュでは、分散データモデリングの手法を採用する必要があります
関連性のあるデータをシームレスにリンクする能力
データユーザーがアーティスト情報がソーシャルメディアのメンション、プレイリスト、アーティストプロフィールに存在することを発見した場合、これらのデータ製品全体で同じアーティストの個々のエンティティをマップや相関させることができる必要があります
どのフィールドが各データ製品でアーティストを表しているか、また、たとえば、すべてのデータ製品が一貫してアーティストを識別するために使用するグローバルに一意のアーティスト識別子をマッピングする方法などを知る必要があります
データの時間的関連付け能力
データ製品は 2 つの時間次元、処理時間と実際の時間（または時間枠）を介してデータを提供します
時間は、2 つのデータエンティティを関連付けるためのパラメータです
たとえば、新興アーティストを発見する際に、ソーシャルメディアのメンションとプレイリストを横断してデータを変換し相関させるコード（またはクエリ）には、アーティストのメンションが行われた実際の時間やアーティストがプレイリストに追加された時点などの情報が含まれます
時間をデフォルトで組み込むことの美しいところは、他のすべての操作が自然に時間の関数になるということです
データメッシュのデータコンポーザビリティ設計について議論するために、データコンポーザビリティの既存のアプローチのいくつかを簡単に見て、それらがデータメッシュとどのように一致するかを評価してみましょう
データコンポーザビリティへの従来のアプローチ
既存のデータ技術の状況を見ると、データコンポーザビリティに関していくつかの注目すべきアプローチが見つかります
執筆時点では、これらのアプローチはそのままではデータメッシュに対応していませんが、学ぶべき興味深い教訓があります
これらのアプローチでは、関係性と共有タイプシステムの明示的な定義によってコンポーザビリティが可能になっています
明示的に定義された関係性を使用することで、システムはどの情報が他の情報と関連付けられ、どのように関連付けることができるかを推論します
ファクトテーブルで定義された関係性、特にデータウェアハウジングシステムで採用されるスターやスノーフレークのような関係スキーマは、異なるタイプのデータ間の明示的な関係を定義します
たとえば、新興アーティストのモデルトレーニング用のデータにアクセスするために、スキーマはアーティストプロフィール、ソーシャルメディアのメンション、プレイリストの 3 つのディメンションテーブルを定義します
これらのデータ製品を各アーティストごとに構成し関連付けるために、外部キーが各テーブルを指すファクトテーブルが作成されます
図 13-5 は、ファクトテーブルとその外部キーのリンクの例を示しています
このデータコンポーザビリティの方法は、中央集権的なシステムでクエリを実行するためにパフォーマンスが高く柔軟性がありますが、データメッシュには適していません
データ製品間での緊密で脆弱な結合を作成します
データ製品のスキーマは独立して変更することができません
すべてのデータ製品が同じスキーマに厳密にリンクしているためです
データ製品全体で均質なデータ構文（表形式）を前提とし、内部ストレージシステム識別子は特定の実装に対して緊密な結合を作成します
図 13-5
ファクトとディメンションテーブルを使用したコンポーザビリティの例データメッシュは、事実やテーブルの結合を明示的に定義することから離れています
分散タイプシステムを使用した関係性の定義関連データを発見する別のアプローチは、タイプシステムを使用する方法です
たとえば、GraphQL の Apollo federation では、個々のサービスがサブグラフを定義し、サービスが解決しデータを提供できるデータ型のセットに対するスキーマを定義します
それぞれのサブグラフには独自のスキーマがあり、一連のタイプ、オブジェクト、およびそれらのプロパティを定義します
各サブグラフスキーマは、他のサブグラフスキーマで定義された他のタイプを参照したり、拡張したりすることができます
ゲートウェイはその後、異なるサブグラフを組み合わせます
ゲートウェイは、連合されたタイプシステムを使用してサブグラフを相関させ、スーパーグラフを作成します
関係性はネストされた（ツリー状の）タイプを介して表示されます
たとえば、私たちの例では、プレイリストのスキーマ（タイプ定義）にはアーティストを表すネストされたメンバーフィールドがあり、そのタイプはアーティストプロフィールスキーマで定義されたアーティストタイプを参照します://アーティストプロファイルスキーマタイプアーティストプロフィール{アーティスト：アーティスト active_since：Date ...}タイプアーティスト {
id：ID！
名前：文字列
}

---

// プレイリストスキーマ
タイププレイリスト {
ユーザー：文字列
トラック：[トラック]
...
}
// アーティストプロファイルスキーマで定義された共有タイプ、アーティストを使用しています
タイプトラック {
アーティスト：アーティスト
期間：整数
...
}
データメッシュには、再利用可能なタイプの緩いカップリングと明確な所有権を尊重する分散型タイプシステムが適しています
ただし、タイプ（スキーマ）の変更と（バージョンの）タイプの次元を独立して考慮し、タイプの再利用を許可するには、さらなる改良が必要です
共有の型システムを使用して定義された関係
関連データを定義する別の方法は、スキーマ内の共有データ型への HTTP ハイパーリンクを使用することで、これらのスキーマは通常、schema.org などの集中型および共有のスキーマレジストリを介して利用できます
スキーマへの直接のハイパーリンクは、しばしば異なるセット全体で個々のデータインスタンスへの直接のハイパーリンクと共に提供されます
例えば、このアプローチは、Linked Data と、セマンティックウェブを中心に展開された標準化が採用している方法です-グローバルスケールのデータウェブ
Linked Data の採用は、企業の分析データ管理に広く浸透していませんが、関連データの分散データリンクと合成性を、ウェブリンクを介して関連データにリンクすることに重点を置いて、グローバルスケールで取り組もうとした興味深いインスピレーションの源です
次に、データリンクとスキーマリンクを示す、JSON-LD の簡単（かつ不完全な）例を示します：//（一部の）JSON-LD 形式で提供されたサンプルデータ//集中型スキーマ内の明示的な//定義を参照して使用される用語を定義しています{
"@context"：{
"@vocab"： "https://schemas.daff.com/playlist＃",
"listeners"： "https://schema.org/Person＃"，
"artist"： "https://schemas.daff.com/artist＃"，
"album"： "https://schemas.daff.com/album＃"，
"track"： "https：/ / schemas.daff.com/track＃"，
"track：id"： {"@type "： "@id"}，
}，
"@id"： "https://daff.com/playlist/19378"，
"@type"： "Playlist"，
"name"： "Indie Playlist"，
"genre"： ["Indie Rock"]，
"tracks"： [{
"@id"： "https://daff.com/playlist/19378/1"，
"@type"： "PlaylistElement"，
"artist：name "： "Sonic Youth"，
"album：name "： "Daydream Nation"
"track：name "： "Teen Age Riot"
"track:id"： "https://daff.com/tracks/39438434"
}、{
"@id"： "https://daff.com/playlist/19378/2"，
"@type"： "PlaylistElement"，
"artist：name "： "Thurston Moore"，
"album：name "： "The Best Day"
"track：name "： "Speak to the Wild"
"track:id"： "https://daff.com/tracks/1275756"
}
]
}
このモデルでは、各個のエンティティとデータタイプには明示的に定義されたスキーマがあり、これはスキーマ URI で識別され、他のスキーマへのリンクを定義した本体論や語彙でリンクできます
オントロジーは、ドメイン内の用語とその間の関係、および他のドメインへの関係の明示的かつ形式的な仕様です
たとえば、プレイリストには、トラックが含まれ、トラックとアーティストの定義へのリンクが含まれています
この JSON-LD ドキュメントの@context セクションを使用してこれらのオントロジーを参照することができます
これらの各個の概念には、一意の URI を持つスキーマがあります
例えば、アーティストプロファイルの各アーティストには、他の関連エンティティがリンクできる一意の URI があります
このデータリンクはグラフを作成し、既存の関係をたどることで新しい関係を推論することができます
このモデルは、分散データモデリングと合成性に適していますが、維持および変更が困難になる可能性のある共有の集中的に管理されたスキーマを使用しないようにさらなる改良が必要です
コンポーズデータデザイン前節では、データメッシュのデータ合成性の既存のアプローチを対比しました
これにより、データメッシュのデータの合成性の設計とその主要な設計要素のいくつかをまとめましょう
デザインは、データ製品間の緩やかな結合と、集中型の同期ポイントを最小限に抑えることを優先します
メッシュを通じたデータの相互運用性は、分散型の型システム（スキーマ）に依存しています
各データ製品は、独自のスキーマのライフサイクルを所有および制御します
1 つのデータ製品は、他のデータ製品のスキーマやデータを使用し、1 つのデータ製品から隣接するデータ製品へのマッピングを使用して、関連性と方法を特定することができます
ただし、執筆時点では、データメッシュの相互運用性のアプローチは開発の途中です
デザイン要素をもう少し詳しく見てみましょう

分散型の型システム
各データ製品は独自に、提供するデータのセマンティックタイプを定義します
このようなセマンティックの定義（スキーマ）は、データ利用者によって一意にアドレス指定できます
データ製品のセマンティックは、他のデータ製品のセマンティックで定義されたタイプを参照し、拡張することができます - セマンティックリンキングと呼ばれます
参照システムが URI のインターネットアドレッシングスキームを使用する場合、それは単に複数のホスティング環境と組織にスコープを拡張する分散型の型システムを可能にします
メッシュエクスペリエンスピラミッドでは、おそらくメッシュ上のすべてのデータ製品が定義したすべての型の集中的なインデックスが作成されます
このインデックスは、個々のデータ製品への読み取り専用のリダイレクションメカニズムにすぎません
新しいデータ製品が作成されたり、既存の製品が更新または削除されたりするたびに、継続的に更新される可能性があります

データ製品のグローバル URI
各データ製品は、IDEALLY、URI の形式で一意のアドレスを持っており、異なるデータメッシュインスタンス内および間でプログラムでアクセスできます
このアドレスは、データ製品の他の共有可能なプロパティ（セマンティックスキーマ、出力ポート、データエンティティなど）にアクセスするためのルートです

データエンティティの URI
複数のデータ製品に表示されるエンティティは、グローバルに一意な識別子で識別する必要があります
これらの識別子は、最終的に特定のエンティティのアドレスに解決することができる URI の形式で表すことができます
先に共有した例では、「アーティスト」という概念は、プレイリストやアーティストプロフィールなど、複数のデータ製品に表示される多義的な概念です
データ製品はこれらの URI を生成するためのソースとなります
この例では、アーティストプロファイルがアーティストのオンボーディング時に URI を割り当てます
グローバル識別子がどのように割り当てられ、データ製品が特定のアーティストに関する情報を指すためにどのように解決するかは、洗練された検索とパターンマッチングの機能を必要とします
例えば、ソーシャルメディアのメンションデータ製品では、Twitter のコメントで特定の名前が言及されます
それらのメンションを既知のアーティストとアーティストの URI にマッピングする方法は、アルバム、トラック、イベントなどのメンションを含む、多くの異なるコンテキストパラメータを調べる洗練されたパターンマッチングです
アーティストドメインでは、この目的のためにアーティストの解決サービスを提供することがあり、ML モデルを使用します

機械の最適化
データ製品の設計は、論理レベルで人間と組織、および機械の両方に最適化されています
例えば、緩く結合されたハイパーリンクを使って密結合された外部キー-主キータブの関係に優先して、データメッシュは組織の最適化を優先します
例えば、URI は変わらずに残りますが、データ製品は時間の経過とともに変化し、異なる場所に展開されるかもしれません
プラットフォームがクエリの高速化の最適化を要求する場合、フェデレーテッドクエリエンジンは、異なるデータ製品間で提供されるデータに対して内部インデックスを作成できます
これらの内部インデックスは、より密結合されており、データ製品開発者から隠されて継続的に更新されます
クエリエンジンによって内部的に使用されます
類似のシナリオは、Google がウェブリンクをトラバースするウェブインデックスです
検索ユーザーとしては、人間がアクセス可能な URI に対処するだけであり、Google の検索エンジンは内部で最適化されたハッシュされたインデックスを使用します
要約すると、論理レベルでは、データの表現はユーザーにとってより理解しやすく、物理的レベルでは機械の操作に対してより配慮しています
人間の要素
データの構成要素を支援するための技術的な手段があることは重要ですが、データの構成には人間の要素も必要です
データ製品の所有者は関連するデータを認識し、データユーザーが有意義な関係を築きやすくするために動機付けされる必要があります
製品の所有者は顧客のニーズを聞き、構成を容易にする方法を見つける必要があります
図 13-6 は、データ製品のデータ構成性の設計に重要な上位コンポーネントを示しています
図 13-6
データ製品のデータ構成性の設計に重要な上位コンポーネント リキャップ データ製品は、データユーザーが信頼できるように既知と未知のギャップを埋める責任があります
データの発見、理解、信頼、探索は、データ製品から始まります
データ製品の意図的なインターフェースと振る舞いの設計により、データの意味論、データ形式、使用文書、統計的特性、期待される品質、タイムリネス、その他のメトリックに関する情報が共有されます
これらの基本機能とメタデータ共有が各データ製品に組み込まれると、接続されたデータ製品のメッシュから検索、閲覧、調査、および意味を把握するためのより洗練された、機械学習ベースの機能が構築できるようになります
個々のデータ製品から高次の知能と知識を引き出すためには、データユーザーがそれらを相関させ、構成する必要があります
集中型モデルではデータを織り合わせる能力は比較的簡単ですが、スキーマによってすべてのエンティティとその関係を定義することができます
データメッシュでは、いくつかの設計上の考慮事項が必要です
これらの設計上の考慮事項は、1 つの主要な目標から生じます：緊密に結びついたまたは集中化されたモデルを作成せずに、迅速に進化することができる分散データモデルのシステムを定義します
データ製品の所有者が連続的に他のデータ製品との有意義な関係を発見し、作成する機会を探す責任、データ製品の所有権のある時変、共有可能、参照可能な意味論的データモデル、意味モデルリンク、データ製品間でデータをマッピングするためのグローバルな識別システムなどのデザインコンセプトを紹介しました
私はこの章が将来のデータメッシュの実装者にオープンなデータモデリングと構成可能性の言語を創造するインスピレーションになることを望んでいます
また、使用されるデータストレージやフォーマッティング技術には依存しない

## 感想とまとめ

- 正直よくわからなかった
- ただ、発見性を高めるためのエンドポイントなどがあるので、大事そう
- 9 章がこのそうまとめ？みたいな感じなのでもう一度読んだ方が良いのかも
- Getting Started 見てからの方がいいかも？

