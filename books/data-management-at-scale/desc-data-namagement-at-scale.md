### 3.3.1 メタデータ

- まず考慮すべきなのは、企業のデータがガバナンス基準を満たすように共有プラットフォームを設計すること

- 1.データプロバイダー
  - スキーマデータ、データ品質メトリクス、どのような参照データが利用されているかを直接取得できる
- 2.変換とリネージ
  - ETL、変換時に自動でメタデータを抽出する
    - どのようなデータからどのようなデータに変化したか、とか?
- 3.ETL されたあとのデータを読み込み用 RDS へ
  - データ配信契約に照らし合わせて、基準を満たしていない場合は拒否する
- 4. 読み込み RDS にあるデータの正確性、完全性、一貫性などのデータ品質を読み出す
- 5. ETL ツールなどから、データに何が起きてどこに移動したかを収集
- 6. データコンシューマ側でも 1 と同じデータを取得できる

---

# 5.8 　ガバナンスとセルフサービスモデルのためのメタデータ

ストリーミングアーキテクチャには、メタデータ機能やメタデータ要件が付加できるものもある

特に、先述のスキーマレジストリが重要　スキーマレジストリでは以下を行う

- メッセージキューとトピックの所有権登録
  - メッセージをパブリックとプライベートに振り分けるのに使う
- スキーマドキュメント管理
  - メッセージのスキーマレイアウトをドキュメント化しておく
- スキーマのバージョン管理
  - バージョン管理することで、イベントがどのバージョンのスキーマで処理されたかを記録でき、コンシューマ側での処理に役立つ
  - RDS や API のバージョン管理と同じようなもの
- リネージ
  - イベントを後から追跡するために、一意のリネージ識別番号を組み込む必要がある(uuid のようなもの)
  - バグなどがあったときに、このリネージをもとに追跡する
    - > 例: 追加 → 削除 → 追加　のようなレコードがあったときに、そのままでは 1 つ目と 2 つ目の追加を区別できない。この際、リネージが役に立つ

---

# 6

## 6.1 アーキテクチャの振り返り

- 誰でもデータが利用できるようにするために、下記を守るのがどのアーキテクチャでも重要
  - 内部ドメインとアプリケーションの複雑さは、ほかのドメインから隠さなければならない
  - データレイヤーを介して消費に最適化されたデータを公開する

### 6.1.1 RDS アーキテクチャ

- 大量のデータを扱うユースケース向き(BI や分析など)
- 耐久性、受動性、永続性のあるデータを保持、大量に読み出すことに向く
- 強一貫性が必要ないのであれば API を設けることも可能(RDS アーキテクチャは非同期なので厳密な一貫性はないということ？)

### 6.1.2 API アーキテクチャ

- リアルタイムの同期通信を要するユースケース向き
- データとビジネス機能の両方を提供できる

### 6.1.3 ストリーミングアーキテクチャ

- リアルタイムにデータを変換し、ほかのアプリケーションに通知する
- ストリーミングアーキテクチャで構成したプラットフォーム(データレイヤー)を RDS として使うことも可能
- アプリケーションの状態を伝えるイベントを流通し、(それをトリガーに)データのレプリケーションをとることもできる

#### 本当に重要なのは…

- 各ドメインチームが自分たちに適したアーキテクチャを選択できること
- 各ドメインはアプリケーションをデータレイヤーにのみ公開する

### 6.1.4 強化パターン

- これらのアーキテクチャは組み合わせて使うことでより強力にできる

#### ゲートウェイルーティングとインデックステーブル

- RDS × API
- クエリトラフィック(変更を伴わない)は RDS へ、コマンドトラフィック(変更を伴う)は運用システム(プロバイダー)へルーティングする
- 頻繁に読み出されるデータについて運用システムへのトラフィックを減少させ、クエリ性能も向上する
  - 読み出し専用のレプリケーションを作るイメージ

#### キューベースの負荷平準化

- API × ストリーミング
- API にリクエストが殺到してダウンすることを防ぐために、リクエストをキューで保持する
  - ストリーミングアーキテクチャなんて大仰な言い方しなくても普通のキューの使い方では…？

#### ノーティファイア

- RDS × ストリーミング
- RDS でデータが利用できるようになった際に通知をストリーミングアーキテクチャで行う

#### ストリーミングインジェスト

- RDS × ストリーミング
- ストリーミングアーキテクチャで構成したプラットフォームでアプリケーションの状態を転送して RDS を構築
- 複数のネットワークにまたがる分散型の RDS に使える

#### これらのアーキテクチャは…

- 通常データレイヤーに適用される
- プロバイダーやコンシューマで使われるソフトウェアアーキテクチャパターンも色々ある
- ネットワークの接続性の問題を回避するには非同期通信がおすすめ
- コンテキスト境界を越える(ドメインが異なる)ときにはデータレイヤーを使うこと
  - すべてのメタデータを補足しなければならない
  - データレイヤーを介さない直接通信はインタフェースの変更を検知できないリスクを認識すること

#### 6.2.4.4 例外的な場合

- 唯一データレイヤーを用いるべきでないケースは遅延が問題になるアプリケーション
  - 銀行業界など

### 6.3.1 消費最適化の原則

- データ品質、表現力、粒度、情報のリッチさについては、データ所有者が責任を負わなければならない
- データ所有者の繰り返し作業をなくすために、データは再利用可能で、できるだけ多くの顧客に対応できることが重要
- 複雑なデータを生のまま投入することは、近視眼的には利点があるかもしれないが、データコンシューマに複雑なデータ処理を生じさせるため、避けるべき
- 以下のような設計に従うべき
  - RDS、API、ストリームどのアーキテクチャでも、汎用的なブループリントとしてデータエンドポイントを設計すること
  - 消費最適化すること。再利用しやすく論理的にグループ化された形で提供すること
  - 命名はドメインから継承すること
  - ほかのドメインのニーズに合わせないこと
  - できるだけ多くのドメインが再利用できるようにすること
  - データ利用者が本当に関心のあるデータのみを提供すること(システム内でしか使わないことを提供しない)
  - データ要素はそれ以上意味のある単位に分割できないようにすること
  - 一貫性のあるドメイン ID をつけること
  - データ形式に一貫性をもたせること(表記法や小数点精度など)
  - ローカルでマスタでない参照データは変化しやすいため、安定した粗い粒度にすること
  - マスタデータ管理対象である場合はエンタープライズ ID を提供すること
- どこまでがプロバイダの仕事で、どこまでがコンシューマの仕事かを分離するのは難しく、合意形成が必要
  - 知識、経験、常識に基づくほかない…

### 6.3.2 メタデータの検索性

- データレイヤー用のプラットフォームは誰が提供してもいいが、データエンドポイントの所有権と説明責任はプロバイダーにある
- メタデータをすべてのドメインで利用できるようにする方法のひとつがエンタープライズメタデータモデル
- 密結合を避けるため、メタデータも抽象化しておくこと
  - たとえば所有権情報が物理データ属性に直接関係していると、それが変更された際にすべてのインタフェースも変更しなければならない
- スキーマの進化と互換性のために、インタフェースはバージョン管理されること
- ドメインが自らデータセットやインタフェースを登録できるようなアーキテクチャにしておく

↓ 要するにこういうこと(どないすんねんはあまり書いていなかった)。

> 検索しやすくするために、対応するインタフェースやスキーマ設計など、すべてのメタデータに簡単にアクセスできるようにすることをお勧めします。

### 6.3.3 意味的一貫性

- 一貫性を実現するために、すべてのドメインで、アプリケーションのデータモデルとインタフェースモデルを十分にドキュメント化する必要がある
- 各データ要素が何を意味し、どこで生成され、物理的にどこに保存されているかを理解すること
- 単一のリポジトリでさまざまなモデル間の相互関係を結びつけて、検証するための簡単な方法はない
  - 可能性を高めるために、ツールを開発し、メタデータを組み合わせ、統合する必要がある
  - まずはカタログ、リポジトリ、ドキュメントポータルからはじめるのがいい
- すべてのメタデータを接続するのには、ゴールデンデータセットの要素を参照するためのインタフェーススキーマをプロバイダーから提供してもらうのが賢い
- モデル間の一貫性を確保するための手順として
  - ビジネスエンティティとゴールデンデータセットの要素感の関係がすべて設定されているかどうかを検証する(論理的な対応の確認？)
  - インタフェースモデルや物理データの検証を行う(物理的な対応の確認？)
- データレイヤーへのインタフェースのカバー率の検証も有効

### 6.3.4 対応するメタデータの提供

- スケーラブルなアーキテクチャを実現する大変さの大半は、メタデータ駆動型のアーキテクチャを実現すること
- 検索性を高めるには、最終的にはすべてがカタログ、レジストリ、開発者ポータルに集約されなければならない

### 6.3.5 データの出所と移動

- **リネージ**はデータガバナンスの中でも非常に重要
  - データがどこで生まれ、どのように収集され、どのように下流で消費されたかを把握するための「鉄の弾丸」
  - 使途はコンプライアンス、法規制、倫理、アドバンストアナリティクスモデルの再現性と透明性
    - 要するに機械学習モデルのデータのバージョン管理みたいな話
- 常にリネージを把握するために、必ずデータレイヤーを用いることが原則となる
  - 残念ながら RDS、API、ストリームのすべての統合パターンを網羅してデータリネージを行えるプラットフォームはまだ存在しないため、自分で設計して構築する必要がある(バックエンドくらいは市販品を流用できるかも)
- **リネージの最低限の要件は、どのアプリケーションが、どのプラットフォームを使用して、どのデータを変換したかを特定すること**

## 6.5 まとめ

- Scaled Architecture はどんなタイプのアプリケーションも排除しない
  - マイクロサービスだけを推奨しているわけではない
- ドメインの依存はデータレイヤーとの間のみになり、代わりにメタデータがすべてをまとめる接着剤となる
  - この仕組みをうまく機能させるには、すべてのドメインが消費最適化された再利用可能な方法でデータを提供することが必要

---

7.1 データガバナンス
データガバナンスとデータセキュリティの関係性

許可されたパーティだけがアクセス
認証・認可の統一的な適用
データガバナンスはデータ管理に対する権限と統制を対応する資産含めて実行・強化する活動
⇨ 企業が成長し始めると問題が発生し、必要性が高まる

加えて、法規制に直面し、データがどこに保存され、どこから来たのか、何のために使われているのかドキュメント化することが要求されている。

データガバナンスは５つの側面がある

組織
プロセス
テクノロジー
人
データ
組織の役割
データ所有者：メタデータを管理
データ利用者：要件を設定
データ作成者：データを作成する内部・外部パーティ
データコンシューマー：データ利用者が意図した通りにデータを利用する内部・外部パーティ
アプリケーション所有者：アクセス制御の管理
データスチュワード：データポリシーとデータ標準の遵守
ガイドライン、ルール、活動、役割、責任を設定

大企業では、非中央集権的に各ドメインの人々が行う連合型組織になっている

データガバナンス部門が様々な役割を割り当てる場合、その責任とタスクが説明されていることが重要

図 7.1

データを明確に定義し、説明責任を果たし、その目的について合意が必要
ビジネス上のステークホルダーが関与する
技術視点だとインタフェース、SLA、プロトコル、バージョン管理

---

# 8 章 データを価値に変える

- データを価値に変えるために考えること
  - ビジネス要件
    - 要件に応じて、ビジネスインテリジェンス、リアルタイム意思決定、機械学習など、様々な手法を使える
  - 非機能的要件
    - データ変換の種類、速度、並列化のための最適化、消費パターン

## 8.4 ビジネス要件

- ビジネス上の目的と目標が明確に定義され、詳細に記述され、完全に定義されていることを確認することが、ソリューションの基礎になる
  - どのようなビジネス上の問題を解決する必要がるか
  - どのようなデータソースが必要なのか
  - どのようなソリューションが利用可能なのか
  - リアルタイムやオフラインで実行しなければならないデータ処理とは何か
  - 一貫性と要件は何か
  - 他のドメインが再利用することが可能な成果物とは何か
    - ?他のドメインが再利用できる必要は有るのか?

## 8.5 非機能要件

- ソリューション構築のビジネス要件定義の次は、非機能要件を明確にすること
- 非機能要件の例
  - コスト
  - スケーラビリティ
  - 性能
  - 遅延
  - 保守性
  - 容量
  - 多様性
  - 速度
  - 一貫性
  - セキュリティとガバナンス
  - 書き込みと呼び出しの特性

---

# 9 エンタープライズデータ資産の活用

- 企業内の様々なドメイン間でデータのコンテキストに一貫性がなく，データ品質のレベルにばらつきがあることが問題になることがある
- この課題に対処するにはマスターデータ管理(MDM)が必要
  - MDM は重要なデータを管理／流通させ，一貫性，品質，信頼性を確保するもの
  - データ保護法などにも効果がある
    - マスターデータの管理が不十分だと，不正の検出ができなかったり，規制当局から罰則を受けたりする可能性がある

## 9.1 マスターデータ管理について

- ほとんどの企業は顧客や製品などの共通点のあるデータリストを共有するシステムを持っている
  - これらのデータは重複している可能性があり，非効率だったり矛盾が生じたりする
- MDM はアプリケーションやシステム全体に対して，マスター管理しているバージョンのデータを流通させることで，データの不整合を検出し，解決する

---

## 9.3 MDM 参照アーキテクチャ

- MDM のプロセスはどのようなアプリケーションで,どのような一意の信頼できるデータが作成され，管理されているのかを特定するところから始める
- データはアプリケーションごとに異なる形式で保存されるため，それぞれのコンテキストを理解し，どのようなビジネスルール，形式，参照範囲がそのマスターデータに影響を与えるのかを把握しておくことが重要
- 重複する部分を識別したら，今度はデータレイヤーに向けて情報提供を開始する
- このプロセスではメタデータも配信される必要がある

### 9.3.3 マスター識別番号

- MDM の重要な要素として，マスターデータとローカルシステムからのデータを関連付けるマスター識別番号がある
- このマスター識別番号はどのデータがマスター管理されているのかを把握するために必要
- 一意のデータを識別し，マスター識別子を割り当てることはシステム内でローカルに行うのではなく，グローバルにのみ行うことができる
- そのためには様々なシステムからの全てのデータを再送信して再び認識してもらわないと行けない
- マスター識別子を配信する場合，MDM のマスター識別子を全ての管理部門に通知し，不整合の問題がおこならないようにすると良い
- マスターデータ管理の対象となる管理部門のみが MDM ハブからマスター識別子を取得する必要がある

  - MDM の対象でないシステムは独自のローカルな完全性を利用すること

- 所感
  - 大規模な会社にはなかな難しそう
  - トップダウンでやるべしなのかな

### 9.3.4 参照データとマスターデータ

- 参照データとマスターデータは明確に区別することがおすすめ
- 参照データとは，他のデータを定義，分類，整理，グループ化，カテゴリするために使用されるデータのこと
- マスターデータはコアとなる概念に関するもの
- 参照データの原則は，データレイヤーでデータを流通する際にはマスター識別子を使用すること
- メタデータとデータ品質コントロールを使えば，同一の一貫性のあるデータを使用できるのでデータ品質を保つことができる

## 9.4 エンタープライズデータのスコープの決定

- マスターデータと参照データの組織的なスコープをどのように定義するかということが難しい
- MDM ではエンタープライズデータを統一するという落とし穴にはまりがち
- スコープを広げ，結果的にあまりにも多くのデータをマスター管理してしまうと，データ統合，ガバナンス，調整作業が急激に膨れ上がってしまうから
- メタデータを使って，リネージ，データモデル，共有合意からドメイン間の重複部分や共通の関心事を見つけることができる

  - そしてスコープを決定することができる
  - メタデータの品質が高くなったら，機械学習を使ってどこに重なる部分があるか，どのデータを企業レベルで管理すべきかを推定することを検討すると良い
    - 筆者曰くできるのではないかとの意見

- 様々なレベルの重複が発見される場合がある
  - データの重複程度と，重要度を区別する

### エンタープライズデータ

- 企業全体に及ぶスコープと用途のあるデータのこと
- マスターデータと参照データの両方が含まれる
- その一貫性は重要であり，そのスコープはいくつかのドメインから全てのドメイン，あるいは企業の外まで様々に変化する場合がある

### ドメインデータ

- 一部のドメイン間で共有されるデータであり，全てのドメインで共有されるわけでないデータ
- データが重複するドメイン群にとっては管理することが重要だが，企業全体としての重要性はなく，法規制上の重要性もないデータ
- ドメインデータはいくつかのドメイン内で管理／保守されるが，グローバルレベルでは管理されない

### ローカルデータ

- 他のドメインで共有されたり，使用されたりしないデータ
- 一つのローカルドメインやシステムの中でのみ使用される

## 9.5 サービスとしての MDM とデータ品質

- 企業やドメインでの MDM の導入を成功させるためには，MDM 製品をドメインにサービスとして提供することを考えること
- MDM ソリューションは複雑で，導入が難しい
- インフラストラクチャーを抽象化して，MDM をサービスとしてドメインに提供することで非常に簡単に使える場合がある

## 9.6 キュレーションデータ

- マスターデータ管理はデータキュレーションと似ているところがある
- どちらも多様なソースからデータを収集し，それを統合することで，個々のデータよりも高い価値を持つようにするプロセス
- データキュレーションは他のチームが繰り返し行う統合作業を排除するもの
- MDM もキュレーションデータ作成も価値を提供し，データコンシューマの作業を楽にすることを目的としている
  - ETL,データクレンジング，データサイエンス，メタデータなどの技術を共通化する
- データキュレーションが MDM と異なるのは，既存のデータを修正するのか，あらたにデータを作成するのかが明示されていない点
  - データキュレーションであればコンテキストの変更が可能
- データキュレーションの大部分はスキーマ，テーブル，カラム情報，クエリ，などのメタデータの整理から始まる

### 9.6.1 メタデータ交換

- データに企業レベルでの意味的一貫性を持たせる方法として，メタデータを共有する方法がある
  - この方法ではデータそのものは変更や共有はされない
- メタデータを様々なドメインと共有するには，いくつかの方法がある
  - データカタログ
  - メタデータにはある特定のデータエンティティに関する情報(場所，アノテーション，属性，関係，意味など)を含めておく
  - エンティティが類似している場合はラベルやアノテーションを使って同じように表現できる

## 9.7 データガバナンスとの関係

- データキュレーションとマスターデータ管理との違いは，データガバナンスにとって重要になる
- MDM では，一般的にデータは一貫性の観点から調整される
- MDM は意味を変えて新しいデータを生成するわけでないので，データ所有者と管理部門は常に元のゴールデンソースシステムのデータ所有者まで辿ることができる
- 一方データキュレーションは既存のデータから新しいデータを作成または導入する場合があるため，新しいデータに対して所有権が発生することがある
- そのためデータキュレーションはドメインとより強く連携し，ドメイン内で実行される

## 9.8 まとめ

- マスターデータ管理が重要であることは明らか

  - なぜならユーザーは使用するデータに一貫性と正確性があればこそ，正しい判断を下すことができるから
  - MDM はエンタープライズレベルでの一貫性と品質を保証している

- MDM の導入を始めるにあたって，最もシンプルな導入スタイルである，リポジトリから始めるのが現実的な方法
- このスタイルでは運用システムと調整することなく，どのデータを調合する必要があるのかや，どのデータの品質が悪いかを知ることによって，迅速に価値を提供することができる
- 次のステップはスコープをはっきりさせること

  - 全てのデータを選択しようとするとだめ．企業レベルのデータ統一は落とし穴
  - 組織にとって価値の高いところから始めるべし

- 最後のステップは最終的な目標である共存を実現すること
  - つまり，改善されたものが元のソースシステムに直接戻ってくるようにすること

---

# 10 章 メタデータによるデータの民主化

- メタデータは、本書でここまで紹介してきたアーキテクチャに必要な情報をすべて提供する
- メタデータは各ツールに散在しているので、整理して統合しないといけない

---

筆者の経験上、メタデータ機能に対して互換性のないテクノロジーが既に社内に乱立していると、コントロールされた環境を作ろうという意気込みが削がれる

大きく 3 つの目標に絞って考えるのがよい

- 10-2. すべての企業領域とその属性及び関係を表す、エンタープライズメタデータモデルを構築する
- 10-3. 重要なメタデータのコレクションを定義し、API やラッパー、ストリームによってメタデータを収集・公開するために最適なアーキテクチャを決定します
- 10-4. セルフサービス機能とポータルを用いて、メタデータを民主化する

# 10.2 　エンタープライズメタデータモデル

最初はシンプルで小規模なものから始める

## 始めるうえで検討すべき観点

- どのようなビジネスメタデータが重要か
- システムの相互運用に必要なメタデータは何か
- どのようなプロセスやストリームでデータを取り込んでいるか
- モデルやスキーマはどこで作成され、管理されているか
- データガバナンス部門が適切に業務を遂行するために、どのような情報を、チームが中央に提供する必要があるか

上記の検討の後、各メタデータストリームについてコンテンツのライフサイクルをかき、すべての依存関係を明らかにする

→ 特定ベンダーに依存しない統一メタデータモデルが出来上がる

## まずまとめるべきところ

- アプリケーションのリスト
- 権威あるデータソース（ゴールデンソース）
- データベースとインタフェースのスキーマ
- データの所有権
- セキュリティ

## メタデータ管理の主要な対象領域をすべて示した概略図

主要なものだけでも、これだけ多くの領域がある

<img src="fig/10-2.png" width="480px">

---

# DDS(ドメインデータストア)流れ的に OK か考える

- ゴールデンソースシステムとは異なり，他のシステムからデータのコンテキストを消費して統合し，変更するためのもの
- DDS が新しいゴールデンデータセットを作成するとそれが新しいゴールデンソースになることがある
  - この場合はデータは全く新しいコンテキストをもち，新しい事実が生まれる
  - また新しい所有権がうまれる
    - 新しいデータは新しい所有権をうむ
    - 受け取ったゴールデンデータセットを転送することは許されない
    - 必要にない DDS は作成しない

---
