# ストレージと抽出

## データベースを駆動するデータ構造

- データをただファイルに追記するのをログとよび、これはシンプルだが優れたパフォーマンス
- 多くのデータベースの内部でログの仕組みは使われている

  - この本でのログは、追記だけが行われるレコードの並びを指しているらしい

- データベースから特定のキーの値を効率的に見つけるにはインデックスが必要
- インデックスは主たるデータから導出される追加のデータ構造
  - 多くのデータベースではインデックスの追加と削除が可能で、データベースの内容には影響しない
  - 影響があるのはクエリのパフォーマンスのみ
- 追加のデータ構造を管理しなければいけないので、オーバーヘッドが生じる

  - これは特に書き込みの時に生じる

- これはストレージシステムにおける重要なトレードオフ

### ハッシュインデックス

- インメモリのハッシュマップの中にはすべてのキーに対してデータファイル中のバイトオフセットをマッピングする
- 値をルックアップしたい場合にはハッシュマップを使えばデータファイル中のオフセットがわかるのでその場所までシークして値を読み出す
- Bitcask はハッシュマップを完全にメモリに置いておき、データはすべて追記する様にしている

  - 各キーに対する値が頻繁に更新される様な状況にあっている
  - 大量に書き込みは生じるが、各キーの多さは少なければ、すべてので参照データをインメモリに格納しておける

- ファイルの追記だけだと、容量が溢れることがあるので、それらにはコンパクション処理を行う
- コンパクションは、ログ中で重複しているキーを捨てて、それぞれのキーに対する最新の情報だけを残す処理
- 詳細項目の検討

  - ファイルフォーマット
    - CSV はログにとって最善のフォーマットではない
    - 最初に文字列の長さをバイトとしてエンコードして、生の文字列を続けるようなバイナリフォーマットの方が高速かつシンプル
      - なぜかはわからん
  - レコードの削除
    - キーおよびキーに関連づいた値を削除したいなら、データファイルに特別な削除のレコードを追加する必要がある(墓石と呼ばれる)
    - ログのセグメントをマージするプロセスはこの墓石を見れば削除されたキーに対するそれ以前の値を捨てることができる
  - クラッシュのリカバリ
    - インメモリのハッシュマップは再起動などで消えてしまう
    - そのため、インメモリハッシュマップを保存するようのディスクが必要
  - 部分的に書き込まれたレコード
    - ファイルにチェックサムが含まれているのでログの壊れた部分を削除したり無視したりできる
  - 並行性の制御
    - ログへの書き込みの追加はシーケンシャルな順序で行われるので、一般的にはライターのスレッドは 1 つだけにするという実装を選択することになる
    - データファイルのセグメントは追記のみが行われ、それ以外はイミュータブルなので読み取りは複数のスレッドから行える

- 追記のみのログは一見無駄が多く見え、ファイルの一部をそのまま更新し、古い値を新しい値で書き換えれば良いと思うが、追記のみを行う設計はいくつかの理由で優れていることがわかっている

  - セグメントの追記とマージはシーケンシャルな書き込み処理であり、ランダムな書き込みよりもはるかに高速
  - 並行処理とクラッシュリカバリはセグメントファイルが追記のみ、あるいはイミュータブルであれば非常にシンプルになる
  - 古いセグメントをマージすることでデータファイルが時間と共にフラグメンテーションを起こすと言う問題を避けられる

- とはいえ、ハッシュテーブルのインデックスにも制約はある
  - ハッシュテーブルはメモリ内に収まらないといけないので、キーの数が非常に多いとダメ
    - ディスク上のハッシュテーブルは高パフォーマンスを出せない
  - 範囲に対するクエリの効率が良くない
    - ハッシュマップの各キーをルックアップする必要がある

### SSTable と LSM ツリー

- Sorted String Table はキーでソートされている
  - 追加でそれぞれのキーは一度しか現れないという制約もある
  - 仮にファイルが利用可能なメモリ量よりも大きくなってもセグメントのマージをシンプルに効率的に行える様になる
  - ファイル中の特定のキーを探す際にすべてのキーをメモリに保存しておく必要はない
    - 範囲で探すことができ、全てのキーを持っておかずとも良い
    - メモリに入れているデータのインデックス間は疎でも良い
      - ソートされているから範囲で持って来れる

### SSTable の構築と管理

- red-black ツリーや AVL ツリーなどを使ってキーを任意の順序で挿入し、ソートされた順序で読み出す様にする
- データベースがクラッシュしてしまうと直近の書き込みが失われてしまうので、ディスク上に別個のログを持っておき、すべての書き込みを即座に追記している
- このログはソート順になっていないが、クラッシュ後のリストアだけを目的にしているため、問題にはならない

### SSTable から LSM ツリーの作成

- SSTable などのインデックス構造は log-structured ファイルシステム上に構築され、Log-Structured Merge Tree(LSM ツリー)と名付けられた
- Elasticsearch の全文検索も key-value インデックスと似ている
- 検索クエリ中の語に対してその語を使っているすべてのドキュメントを見つける

### パフォーマンスの最適化

- データベースに存在しないものを検索すると、何もしなければ時間がかかる
  - すべての key をルックアップして、また、古いセグメントに対しても同じことをする必要があるので
- これを最適化するにはストレージエンジンではブルームフィルターが追加される
- ブルームフィルタは集合の内容についての概要を保持するメモリ効率の良いデータ構造
- ブルームフィルタを使うとあるキーがデータベース中に存在しないことがわかるので存在しないキーのために不要なディスクの読み取りが多発することを防ぐことができる
- SSTable のコンパクションとマージの順序とタイミングの決定員は様々な戦略があり、一般的な選択肢としてはサイズごと、階層ごとのコンパクションがある
- LSM ツリーは極めて高い書き込みのスループットを支えられる(LSM についてもう少し読んでみる)

### B ツリー

- 最も広く使われているインデックス構造は B ツリー
- リレーショナルデータベースの標準インデックスでもあり、リレーショナルデータベース以外でもよく使われている
- SSTable と同様に B ツリーはキーと値のペアをキーでソートされた状態で保持する
- そのためキーと値のルックアップや範囲に対するクエリを効率よく処理できるが、それ以外は似ていない
- log-structed インデックスはデータベースを可変サイズのセグメントに分割し、常にセグメントをシーケンシャルに書き込む
- B ツリーはデータベースを固定サイズのブロック、またはページに分割する
- 1 つのページに一度に書き込む
- この設計はハードウェアとの関係性が密になる
- 各ページはアドレスあるいは場所によって識別できるのであるページから他のページを参照できる
  - このページ参照を使えばページのツリーを構築できる
- 1 つのページが B ツリーのルートになる
- キーをルックアップしたい場合はルートを出発点とする
- ページには複数のキーと子のページへの参照が含まれている
- それぞれの子はキーの連続的な範囲を受け持ち、参照のキーはそれらの子が受け持つハニの境界を示す
- ここら辺のデータ構造はみんなのデータ構造で実装されているのでチャレンジすると良いかも

### B ツリーの信頼性を高める

- ディスク上に追加の構造化データ,write-ahead ログを持たせることで信頼性を高めることができる
- これは追記のみが行われるファイルで、B ツリーへの全ての変更内容をツリーそのもののページに反映させる前に書き込む
- データベースがクラッシュ後に回復する際にはこのログを使って B ツリーを整合性能のとれた状態に回復させる
- また、並列操作がされる場合は拉致という軽量なロックで保護しなくてはいけず、これは追記だけのログ構造のアプローチの方がシンプル

### B ツリーと LSM ツリーの比較

- LSM ツリーは書き込みが高速で、B ツリーは読み取りが高速
- ただし、コンテキストによるので計測は重要

### LSM ツリーの利点/デメリット

- 書き込みがスループットが高い
- 圧縮率を高めることができる

  - B ツリーはフラグメンテーションのために未使用のママのディスク領域が生じる
  - LSM は定期的に SSTable を書き直してフラグメンテーションを除去する

- log-structed ストレージのデメリットはコンパクションの処理が実行中の読み書きのパフォーマンスに影響を及ぼすこと
  - レスポンスタイムをパーセンタイルでみると非常に高くなることがあり、予想しずらい
  - B ツリーは挙動の予測がしやすい
- コンパクションは書き込みのスループットが高い(おそらく、これは目的の書き込みではなく、内部的に実行されるコンパクションの書き込みなので、なければない方が良い？)
- ディスクの空きが出るまでコンパクションができないこともあり、そうなると読み取りの速度も遅くなる
- また、その様なことがないかをモニタリングする必要もある
- B ツリーのいいところはキーのインデックスが 1 箇所にしか出ないこと
  - log-structured は同じキーのコピーが異なるセグメントに複数置かれることもある
- このことから B ツリーは強いトランザクションのセマンティックを提供したいデータベースにあう
- B ツリーはデータベースのアーキテクチャにしっかりと定着しており、多くのワークロードに置いてコンスタントに良いパフォーマンスを発揮するのでしばらくの間は廃れない
- 新いデータストアでは log-structured インデックスの普及が進んでいる
- 個別のユースケースにどちらのタイプのストレージエンジンが適しているのかを簡単に判断できる易しいルールはないので実際に試すことが重要

### その他のインデックス構造

- ここまでは key-value インデックスのみだったが、これはリレーショナルモデルにおけるプライマリーキーインデックスの様なもの
- セカンダリインデックスは広く使われており、リレーショナルデータベースは CREATE INDEX コマンドを使って 1 つのテーブルに複数のインデックスを作成できる
- セカンダリインデックスは効率的に結合処理をするのに欠かせない
  - なんとなくわかる。プライマリーキーじゃないけど、キーを元に複数の値が欲しいとなると、キーによって迅速にデータを取得できる方が良いみたいな感じかな
- セカンダリインデックスは key-value インデックスから容易に構築できるが、主な違いはキーがユニークではないこと
- これに対する対処は以下の 2 つ
  - インデックス内のそれぞれの値をマッチする行の識別子のリストにすること(わけわからん)
    - {user_index:[{id:0,id:1,id:100,id:100000}]}こういうことか？
  - それぞれのキーに行の識別子を追加してキーをユニークにすること
    - {user_index+id:offset100}]}こういうこと？

### インデックスへの値の保存

- クエリが検索するのはインデックス中のキーだが、結果の値は 2 種類

  - 探していた実際の行
  - 別の場所に保存されている行への参照
    - これはヒープファイルというデータが順序づけされていないランダムなディスク

- ヒープファイルは複数のセカンダリインデックスがある場合にデータが複製されてしまうのを避けるため、ヒープファイルは広く使われている

  - 理由が飛躍していて意味わからん

- この場合、それぞれのインデックスはヒープファイルの場所を参照するだけであり、実際のデータが保存される場所は 1 つだけ

  - これが上の理由としたいのかもしれないが、そもそもセカンダリインデックスがあるとデータは複製しやすいのか？複製されやすいように読めてしまうけどあっている？

- データ更新時に前のデータよりも新しいデータが小さければ、ヒープファイルの場所を変える必要がないので、楽だが、大きい場合はヒープファイルのどこか新しいところを解放しないといけず、インデックスの更新なども必要になるので大変
  - もしくはヒープ中のもの場所に移転先を示すポインタを残しておく
- 場合によってはインデックスからヒープファイルに至る過程でホップが追加されてしまうが許容できない場合、インデックス付された行を直接インデックス内に保存してしまった方が好ましい場合もある
- 上記をクラスタ化インデックスという
  - ただし、この書き方は下で出てくるカバーリングインデックスの説明と同じな気がしてしまう
  - 調べてみると、B ツリーのリーフノードにデータを格納するのがクラスタ化インデックスみたいな感じで、B ツリーデータ上に直接データを保存するものな気がしている
- 非クラスタ化インデックスはおそらく、ヒープファイルの場所の参照情報が B ツリーのリーフノードに格納されているもの
- この中間がカバーリングインデックスと付加列を持つインデックス
  - これはテーブルの一部の列をインデックスに保存するもの
  - インデックスの役割をクエリに混ぜる(カバーリングする)って感じらしい
- 読み取りの代わりにストレージが余分に必要になるアプローチなので書き込みにはオーバーヘッドがかかる
- 複製によってアプリケーションから見えるデータに不整合が生じないようにしないといけないので、トランザクションの保証をする負担もかかる
  - クラスタ化インデックスもデータの複製は起きるのか？

### 複合インデックス

- 複数の列に対してクエリを行う場合、連結インデックスが良い
- これは単純に複数のフィールドを付け足していって 1 つのキーにしたもの

- 多次元インデックスは複数の列に対するクエリを処理するための方法としてさらに汎用性の高い方法

  - 特に地理空間データなどにとって重要

- 標準的な B ツリーや LSM ツリーインデックスでは複数の変数の範囲指定は扱えない
  - おそらく、複数のインデックスを貼ることはできるが、その数だけ B ツリーができる気がする
  - 複数の B ツリーを一度に満たすことは難しいということでは？
- 選択肢の 1 つとして、空間補充曲線を使って 2 次元の位置を単一の数値に変換してから通常の B ツリーインデックスを使うという方法がある
  - R ツリーなど
  - なかなかおもろいな

### 全文検索と曖昧インデックス

- 今までのインデックスでは厳密な検索のみしかサポートしていない
- あとは難しいことがつらつら書いてあってわけわからんかった
  - しかも詳細は他の教科書を見ろとのこと

### 全データのメモリでの保持

- インメモリデータベースはメモリを使うが、ログなどを使って永続性を保とうとする
- 直感に反するがインメモリデータベースのパフォーマンス上のメリットはディスクから読み取りせずに済むことではない
- ディスクベースのストレージエンジンであっても、十分なメモリがあれば直近で使われたディスク上のブロックをオペレーションシステムがメモリにキャッシュしてくれるのでディスクから読み取りをする必要が全くない場合もある
- インメモリデータベースが高速なのは、むしろメモリ内のデータ構造をディスクに書き込める形式にエンコードする必要がないから
- パフォーマンス以外での利点は、ディスクベースのインデックスでは実装が難しいデータモデルを提供できることがあること
  - 例えば Redis はプライオリティキューや集合といった様々なデータ構造に対するデータベースのようなインターフェイスを提供している
  - Redis は全てのデータをメモリ内に保持しているので、実装は比較的シンプル
- 近年の研究からはインメモリデータベースのアーキテクチャを拡張し、ディスク中心のアーキテクチャのオーバーヘッドを蘇らせることなく、利用可能なメモリよりもおお、いなデータセットをサポートできることが示されている
- これはアンチキャッシングアプローチで、メモリが十分でない時に最も長く使われていないデータをメモリからディスクに退避させ、将来そのデータが再びアクセスされた時にメモリにロードしなおす
- OS のスワップに似ているが、データベースはメモリにページよりも細かい個々のレコードの粒度を扱えるので OS よりもメモリを効率的に管理できる
- 不揮発メモリの技術が広く使われる様になればさらなる変化があるかも
  - 現時点では新しい研究分野だが、将来に向けて注目しておくべきことらしい

## トランザクション処理か、分析処理か？

- トランザクションは ACID である必要はないらしい
- トランザクション処理が意味するのは単にクライアントが低レイテンシーで読み書きを行うということだけ
- これはバッチ処理とは対照的な考え
- 様々なところでトランザクション処理は使われているが、データ分析となると、大量のレコードのスキャンや、その統計情報の計算などが必要になる
- 今までのパターンは OLTP(オンライントランザクションプロセス)
- 分析のパターンは OLAP(オンライン分析処理)
- SQL はどちらのパターンもうまく扱うことができる
- ただし、OLAP を OLTP でやることはしなくなり、代わりに別個のデータベースで分析を実行する流れが企業に生じた
- これがデータウェアハウス

### データウェアハウス

- ビジネス上で分析に必要となるデータは 1 つの今日が数十者異なるシステムで独立して運用することが多い
- これらのデータは高い可用性と低レイテンシーでのトランザクション処理が求められる
- そのためデータベース管理者は OLTP データベースを厳密に保護する
- OLTP はアプリケーションの DB として利用されることが多いので、データ分析者にはクエリを実行してほしくないもの
  - しかもそのクエリはデータ分析用なので、相当重い
- これに対し、データウェアハウスは独立したデータベースであり、OLTP の処理に影響を及ぼすことなく重要なデータに対するクエリをアナリストが実行できる
- データウェアハウスには企業内の様々な OLTP システム全てのデータのコピーがリードオンリーで置かれる
- データは OLTP データベースから取り出され、分析に適したスキーマに変換され、クリーンアップを経てデータウェアハウスにロードされる
- データをウェアハウスに取り込むこの処理は ETL
- 現在のほとんどの大企業はデータウェアハウスを持っている

  - ただし、これがスケールしなくなっているよねっていうのが DataMesh の話(この本にあるかは話からない)

- データウェアハウスのメリットは分析的なアクセスのパターンに最適化できること

### OLTP データベースとデータウェアハウスの相違点

- データウェアハウスのデータモデルはリレーショナルであることが一般的
  - これは SQL が分析的なクエリに適していることによる
- 似ているが、最適化されているクエリのパターンが OLTP とは違う

### スタートスノーフレーク：分析のためのスキーマ

- OLTP の領域ではアプリケーションの要求に応じて幅広く様々なデータモデルが使われている
- 一方分析の分野においてはデータモデルの多様性はあまりなく、多くのデータウェアハウスが極めてありふれたスタースキーマを使用している
- スキーマの中心にいるのはファクトとーぶる
- ファクトテーブルの各行は特定の時点で生じたイベントを表す
- 通常ファクトはのちの分析を柔軟に行えるよう、個別のイベントとして扱われる
- しかしこれはファクトテーブルが巨大になるということでもある
- ファクトテーブルの他の列はディメンションテーブルと呼ばれる他のテーブルを参照する外部キー
- ファクトテーブルの各行は 1 つのイベントを表現するが、ディメンションはそのイベントの人物、対照、日時、場所、方法、理由といったことを表す
- スノーフレークスキーマでは、ディメンションがさらにサブディメンションに分割される
- 典型的なデータウェアハウスではしばしばテーブルは大量の列を持つ
  - 列数が 100 以上になることは珍しくなく、場合によっては数百に及ぶ
  - ディメンションテーブルの列数も分析に関係するかもしれない全てのメタデータを含むため大きくなることがある

## 列指向ストレージ

- 多くの OLTP データベースは行指向でレイアウトされているので、テーブル内の 1 行の中にある値は全て隣り合うように配置されている
- 列指向の背景となる考え方は、それぞれの列に含まれる全ての値をまとめて保存する
- 分析では行ではなく、いくつかの列に対して大量のデータを必要とするケースが多いので、列指向であることが大事

### 列の圧縮

- 列指向ストレージは圧縮に適していることが多い
  - 列は同じ値が頻出しやすく、ビットマップエンコーディングなどがしやすい

### メモリの帯域とベクトル化処理

- 数百万行をスキャンしなければならないデータウェアハウスのクエリでは、ディスクからメモリへデータを移すための帯域が大きなボトルネックとなる
- 分析的なデータベースの開発者たちはメインメモリから CPU キャッシュへの帯域の効率的な利用、分岐の予測ミスと CPU の命令処理パイプライン中のバブル、現代的な CPU のシングルインストラクションマルチデータ(SIMD)命令の利用といったことも考慮する
  - よくわからん
  - CPU とかの勉強もするべきな気がする
