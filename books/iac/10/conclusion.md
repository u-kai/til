Deployment Packages Applications are often organized into deployment packages, with the package format depending on the type of the runtime environment. Examples of deployment package formats and associated runtimes are listed in Table 10-1. Table 10-1. Examples of target runtimes and application package formats Target runtime Example packages Server operating system Red Hat RPM files, Debian .deb files, Windows MSI installer packages Language runtime engine Ruby gems, Python pip packages, Java .jar, .war, and .ear files. Container runtime Docker images Application clusters Kubernetes Deployment Descriptors, Helm charts FaaS serverless Lambda deployment package A deployment package format is a standard that enables deployment tools or runtimes to extract the parts of the application and put them in the right places. Deploying Applications to Servers Servers, whether physical or virtual, are the traditional runtime platform. An application is packaged using an operating system packaging format such as an RPM, a .deb file, or a Windows MSI. Or it is packaged in a language runtime format, such as a Ruby gem or Java .war file. More recently, container images, such as Docker images, have gained popularity as a format for packaging and deploying applications to servers. Defining and provisioning servers as code is the topic of Chapter 11. This topic overlaps with application deployment, given the need to decide when and how to run deployment commands (see “Configuring a New Server Instance”). Packaging Applications in Containers Containers pull dependencies from the operating system into an application package, the container image, as shown in Figure 10-2.2 Figure 10-2. Dependencies may be installed on the host OS or bundled in containers Including dependencies in the container makes it larger than typical operating system or language packages, but has several advantages: A container creates a more consistent environment for running an application. Without a container, the application relies on libraries, configuration, user accounts, and other elements that may be different on different servers. A container bundles the runtime environment along with the application and its dependencies. A containerized application is mostly isolated from the server it runs on, which gives you flexibility for where you can run it. By packaging the application’s operating system context in the container image, you simplify and standardize the requirements for the host server. The server needs to have the container execution tooling installed, but little else. Reducing the variability of runtime environments for an application improves quality assurance. When you test a container instance in one environment, you can be reasonably confident it will behave the same in other environments. Deploying Applications to Server Clusters People have been deploying applications to groups of servers since before container-based application clusters were a thing. The usual model is to have a server cluster (as described in “Compute Resources”), and run an identical set of applications on each server. You package your applications the same way you would for a single server, repeating the deployment process for each server in the pool, perhaps using a remote command scripting tool like Capistrano or Fabric. See Figure 10-3. Figure 10-3. Applications are deployed to each server in a cluster If you deploy an application to multiple servers, you need to decide how to orchestrate the deployment. Do you deploy the application to all of the servers at once? Do you need to take the entire service offline while you do this? Or do you upgrade one server at a time? You can leverage incremental deployment to servers for progressive deployment strategies like the blue-green and canary deployment patterns (see “Changing Live Infrastructure” for more on these strategies). In addition to deploying application code onto servers, you may need to deploy other elements like changes to data structures or connectivity. Deploying Applications to Application Clusters As discussed in “Compute Resources”, an application hosting cluster is a pool of servers that runs one or more applications. Unlike a server cluster, where each server runs the same set of applications, different servers in an application cluster may run different groups of application instances (see Figure 10-4). When you deploy an application to the cluster, a scheduler decides which host servers to run instances of the application on. The schedule may change this distribution, adding and removing application instances across host servers according to different algorithms and settings. Figure 10-4. Applications are deployed to the cluster and distributed across host nodes In the old days,3 the most popular application clusters were Java-based (Tomcat, Websphere, Weblogic, JBoss, and others). A wave of cluster management systems emerged a few years ago, including Apache Mesos and DC/OS, many inspired by Google’s Borg.4 Systems focused on orchestrating container instances have overwhelmed application servers and cluster orchestrators in more recent years. Defining and provisioning clusters as code is the topic of Chapter 14. Once you have your cluster, it may be simple to deploy a single application onto it. Package the application with Docker and push it to the cluster. But more complex applications, with more moving parts, have more complex requirements. Packages for Deploying Applications to Clusters Modern applications often involve multiple processes and components deployed across complex infrastructure. A runtime environment needs to know how to run these various pieces: What are the minimum and maximum number of instances to run? How should the runtime know when to add or remove instances? How does the runtime know whether an instance is healthy or needs to be restarted? What storage needs to be provisioned and attached to each instance? What are the connectivity and security requirements? Different runtime platforms provide different functionality, and many have their own packaging and configuration format. Often, these platforms use a deployment manifest that refers to the actual deployment artifacts (for example, a container image), rather than an archive file that includes all of the deployable pieces. Examples of cluster application deployment manifests include: Helm charts for Kubernetes clusters Weave Cloud Kubernetes deployment manifests AWS ECS Services, which you can define as code using your favorite stack management tool Azure App Service Plans CNAB Cloud Native Application Bundle Different deployment manifests and packages work at different levels. Some are focused on a single deployable unit, so you need a manifest for each application. Some define a collection of deployable services. Depending on the tool, each of the services within the collection may have a separate manifest, with a higher-level manifest defining common elements and integration parameters. A manifest for the ShopSpinner web server deployment might look like the pseudocode shown in Example 10-1. Example 10-1. Example of an application cluster deployment manifest service:
デプロイメントパッケージ
アプリケーションは、デプロイメントパッケージに組織化されることが多く、パッケージ形式はランタイム環境の種類によって異なります。デプロイメントパッケージの形式と関連するランタイムの例を表 10-1 に示します。

表 10-1. 対象ランタイムとアプリケーションパッケージ形式の例

対象ランタイム 例のパッケージ
サーバーオペレーティングシステム Red Hat RPM ファイル、Debian .deb ファイル、Windows MSI インストーラーパッケージ
言語ランタイムエンジン Ruby gems、Python pip パッケージ、Java .jar、.war、.ear ファイル
コンテナランタイム Docker イメージ
アプリケーションクラスタ Kubernetes デプロイメントディスクリプタ、Helm チャート
FaaS サーバーレス Lambda デプロイメントパッケージ

デプロイメントパッケージ形式は、デプロイメントツールやランタイムがアプリケーションの各パーツを抽出し、適切な場所に配置するための標準です。

サーバーへのアプリケーションのデプロイ
サーバー（物理的または仮想）は伝統的なランタイムプラットフォームです。アプリケーションは、RPM、.deb ファイル、または Windows の MSI などのオペレーティングシステムパッケージング形式でパッケージ化されるか、Ruby の gem や Java の.war ファイルのような言語ランタイム形式でパッケージ化されます。より最近では、Docker イメージなどのコンテナイメージが、アプリケーションをパッケージ化してサーバーにデプロイするための形式として人気を集めています。新しいサーバーインスタンスの設定は、「新しいサーバーインスタンスの構成」を参照してください。

コンテナによるアプリケーションのパッケージ化
コンテナは、依存関係をホストオペレーティングシステムからアプリケーションパッケージであるコンテナイメージに取り込むことができます（図 10-2.2 参照）。依存関係をコンテナに含めること
