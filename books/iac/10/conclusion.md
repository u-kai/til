Deployment Packages Applications are often organized into deployment packages, with the package format depending on the type of the runtime environment. Examples of deployment package formats and associated runtimes are listed in Table 10-1. Table 10-1. Examples of target runtimes and application package formats Target runtime Example packages Server operating system Red Hat RPM files, Debian .deb files, Windows MSI installer packages Language runtime engine Ruby gems, Python pip packages, Java .jar, .war, and .ear files. Container runtime Docker images Application clusters Kubernetes Deployment Descriptors, Helm charts FaaS serverless Lambda deployment package A deployment package format is a standard that enables deployment tools or runtimes to extract the parts of the application and put them in the right places. Deploying Applications to Servers Servers, whether physical or virtual, are the traditional runtime platform. An application is packaged using an operating system packaging format such as an RPM, a .deb file, or a Windows MSI. Or it is packaged in a language runtime format, such as a Ruby gem or Java .war file. More recently, container images, such as Docker images, have gained popularity as a format for packaging and deploying applications to servers. Defining and provisioning servers as code is the topic of Chapter 11. This topic overlaps with application deployment, given the need to decide when and how to run deployment commands (see “Configuring a New Server Instance”). Packaging Applications in Containers Containers pull dependencies from the operating system into an application package, the container image, as shown in Figure 10-2.2 Figure 10-2. Dependencies may be installed on the host OS or bundled in containers Including dependencies in the container makes it larger than typical operating system or language packages, but has several advantages: A container creates a more consistent environment for running an application. Without a container, the application relies on libraries, configuration, user accounts, and other elements that may be different on different servers. A container bundles the runtime environment along with the application and its dependencies. A containerized application is mostly isolated from the server it runs on, which gives you flexibility for where you can run it. By packaging the application’s operating system context in the container image, you simplify and standardize the requirements for the host server. The server needs to have the container execution tooling installed, but little else. Reducing the variability of runtime environments for an application improves quality assurance. When you test a container instance in one environment, you can be reasonably confident it will behave the same in other environments. Deploying Applications to Server Clusters People have been deploying applications to groups of servers since before container-based application clusters were a thing. The usual model is to have a server cluster (as described in “Compute Resources”), and run an identical set of applications on each server. You package your applications the same way you would for a single server, repeating the deployment process for each server in the pool, perhaps using a remote command scripting tool like Capistrano or Fabric. See Figure 10-3. Figure 10-3. Applications are deployed to each server in a cluster If you deploy an application to multiple servers, you need to decide how to orchestrate the deployment. Do you deploy the application to all of the servers at once? Do you need to take the entire service offline while you do this? Or do you upgrade one server at a time? You can leverage incremental deployment to servers for progressive deployment strategies like the blue-green and canary deployment patterns (see “Changing Live Infrastructure” for more on these strategies). In addition to deploying application code onto servers, you may need to deploy other elements like changes to data structures or connectivity. Deploying Applications to Application Clusters As discussed in “Compute Resources”, an application hosting cluster is a pool of servers that runs one or more applications. Unlike a server cluster, where each server runs the same set of applications, different servers in an application cluster may run different groups of application instances (see Figure 10-4). When you deploy an application to the cluster, a scheduler decides which host servers to run instances of the application on. The schedule may change this distribution, adding and removing application instances across host servers according to different algorithms and settings. Figure 10-4. Applications are deployed to the cluster and distributed across host nodes In the old days,3 the most popular application clusters were Java-based (Tomcat, Websphere, Weblogic, JBoss, and others). A wave of cluster management systems emerged a few years ago, including Apache Mesos and DC/OS, many inspired by Google’s Borg.4 Systems focused on orchestrating container instances have overwhelmed application servers and cluster orchestrators in more recent years. Defining and provisioning clusters as code is the topic of Chapter 14. Once you have your cluster, it may be simple to deploy a single application onto it. Package the application with Docker and push it to the cluster. But more complex applications, with more moving parts, have more complex requirements. Packages for Deploying Applications to Clusters Modern applications often involve multiple processes and components deployed across complex infrastructure. A runtime environment needs to know how to run these various pieces: What are the minimum and maximum number of instances to run? How should the runtime know when to add or remove instances? How does the runtime know whether an instance is healthy or needs to be restarted? What storage needs to be provisioned and attached to each instance? What are the connectivity and security requirements? Different runtime platforms provide different functionality, and many have their own packaging and configuration format. Often, these platforms use a deployment manifest that refers to the actual deployment artifacts (for example, a container image), rather than an archive file that includes all of the deployable pieces. Examples of cluster application deployment manifests include: Helm charts for Kubernetes clusters Weave Cloud Kubernetes deployment manifests AWS ECS Services, which you can define as code using your favorite stack management tool Azure App Service Plans CNAB Cloud Native Application Bundle Different deployment manifests and packages work at different levels. Some are focused on a single deployable unit, so you need a manifest for each application. Some define a collection of deployable services. Depending on the tool, each of the services within the collection may have a separate manifest, with a higher-level manifest defining common elements and integration parameters. A manifest for the ShopSpinner web server deployment might look like the pseudocode shown in Example 10-1. Example 10-1. Example of an application cluster deployment manifest service:
展開パッケージ　アプリケーションは、ランタイム環境のタイプに応じてパッケージ形式に整理されることがよくあります。展開パッケージの形式と関連するランタイムの例は、表10-1に示されています。表10-1. ターゲットランタイムとアプリケーションパッケージ形式の例 ターゲットランタイムの例 パッケージ形式 サーバーのオペレーティングシステム Red Hat RPM ファイル、Debian .deb ファイル、Windows MSI インストーラーパッケージ 言語のランタイムエンジン Ruby gems、Python pip パッケージ、Java .jar、.war、.ear ファイル。 コンテナのランタイム Docker イメージ アプリケーションクラスタ Kubernetes 展開記述子、Helm チャート FaaS サーバーレス Lambda 展開パッケージ 展開パッケージ形式は、展開ツールやランタイムがアプリケーションの部分を抽出し、正しい場所に配置できるようにするための標準です。 サーバーへのアプリケーションの展開 サーバーは、物理的または仮想のいずれかの伝統的なランタイムプラットフォームです。 アプリケーションは、RPM、.deb ファイル、Windows MSI などのオペレーティングシステムのパッケージング形式、またはRuby gem やJava .war ファイルなどの言語のランタイム形式でパッケージ化されます。 最近では、Docker イメージなどのコンテナイメージが、アプリケーションのパッケージングと展開の形式として人気を集めています。 サーバーの定義とプロビジョニングは、第11章のトピックです。このトピックは、アプリケーションの展開に重なります。デプロイメントコマンドをいつ、どのように実行するかを決定する必要があります（「新しいサーバーインスタンスの設定」を参照）。 コンテナ内のアプリケーションのパッケージ化  コンテナは、依存関係をオペレーティングシステムからアプリケーションパッケージであるコンテナイメージに取り込むものです（図10-2参照）。 図10-2. 依存関係はホストOSにインストールされるか、コンテナにバンドルされます コンテナに依存関係を含めることで、通常のオペレーティングシステムや言語パッケージよりも大きなサイズになりますが、いくつかの利点があります。 コンテナは、アプリケーションを実行するためのより一貫した環境を作成します。 コンテナがない場合、アプリケーションは異なるサーバーで異なるライブラリ、設定、ユーザーアカウントなどに依存しています。 コンテナはランタイム環境とアプリケーションとその依存関係をまとめてバンドルします。 コンテナ化されたアプリケーションは、実行されるサーバーからほぼ分離されているため、実行場所に対して柔軟性があります。 アプリケーションのオペレーティングシステムのコンテキストをコンテナイメージにパッケージ化することで、ホストサーバーの要件を簡素化し、標準化することができます。 サーバーにはコンテナの実行ツールがインストールされている必要がありますが、それ以外はほとんど必要ありません。 アプリケーションの実行環境の変動を減らすことは、品質保証を向上させます。 コンテナインスタンスを1つの環境でテストすると、他の環境でも同じように動作することが比較的確実です。 サーバークラスターへのアプリケーションのデプロイメント 同じアプリケーションを複数のサーバーに展開することは、コンテナベースのアプリケーションクラスターが存在する前から行われてきました。 通常のモデルでは、サーバークラスター（「コンピューティングリソース」で説明されている）を持ち、各サーバーで同じセットのアプリケーションを実行します。 単一のサーバーの場合と同じように、アプリケーションをパッケージ化し、プール内の各サーバーに対してデプロイメントプロセスを繰り返します。たとえば、CapistranoやFabricといったリモートコマンドスクリプティングツールを使用することがあります。 図10-3を参照してください。 図10-3. アプリケーションはクラスターの各サーバーに展開されます アプリケーションを複数のサーバーに展開する場合、展開方法を決定する必要があります。全てのサーバーにアプリケーションを一斉に展開しますか？ この間、サービス全体をオフラインにする必要はありますか？ それとも1つずつサーバーをアップグレードしますか？ ブルーグリーンデプロイメントやカナリアデプロイメントパターンなどのプログレッシブデプロイメント戦略において、展開をサーバーに対して段階的に行うこともできます（これらの戦略については、「ライブインフラストラクチャの変更」を参照）。 サーバーへのアプリケーションのデプロイメント  コンピューティングリソース」で説明したように、アプリケーションホスティングクラスターは、1つ以上のアプリケーションを実行するサーバーのプールです。 サーバークラスターとは異なり、アプリケーションクラスターの異なるサーバーは、異なるアプリケーションインスタンスのグループを実行する場合があります（図10-4参照）。 アプリケーションをクラスターに展開すると、スケジューラがどのホストサーバーでアプリケーションのインスタンスを実行するかを決定します。スケジュールはこの分布を変更し、異なるアルゴリズムや設定に基づいてホストサーバー上のアプリケーションインスタンスを追加および削除することができます。 図10-4を参照してください。 図10-4. アプリケーションはクラスターに展開され、ホストノードに分散されます 昔は、最も人気のあるアプリケーションクラスタはJavaベース（Tomcat、Websphere、Weblogic、JBossなど）でした。数年前には、Apache MesosやDC/OSなどのクラスタ管理システムが登場し、多くのシステムがGoogleのBorgに触発されました。これらより最近の数年間では、コンテナインスタンスをオーケストレーションすることに特化したシステムが、アプリケーションサーバーやクラスタオーケストレーターを圧倒しています。 クラスターの定義とプロビジョニングは、第14章のトピックです。 クラスターができたら、単一のアプリケーションを簡単に展開できる場合があります。アプリケーションをDockerでパッケージ化し、クラスターにプッシュします。ただし、より複雑なアプリケーションは、より多くの動く部分と複雑な要件を持っています。 クラスターアプリケーションのデプロイメントパッケージ モダンなアプリケーションは、複数のプロセスやコンポーネントが複雑なインフラストラクチャに展開されることがよくあります。実行環境は、これらのさまざまな部分を実行する方法を知る必要があります。 何個のインスタンスを最小限から最大限に実行する必要がありますか？ ランタイムはインスタンスを追加または削除するタイミングをどのように知るのですか？ インスタンスが健全でないか再起動が必要かをランタイムはどのように知るのですか？ 各イン