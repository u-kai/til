Testing Applications with Infrastructure If you deliver infrastructure changes along the application delivery path, you can leverage automated
application tests. At each stage, after applying the infrastructure change, trigger the application test stage (see Figure 18-10). The progressive testing approach (“Progressive Testing”) uses application tests for integration testing. The application and infrastructure versions can be tied together and progressed through the rest of the delivery flow following the delivery-time integration pattern (see “Pattern: Delivery-Time Project Integration”). Or the infrastructure change can be pushed on to downstream environments without integrating with any application changes in progress, using apply-time integration (see “Pattern: Apply-Time Project Integration”).
Pushing changes to applications and infrastructure through as quickly as possible is ideal. But in practice, it’s not always possible to remove the friction from all types of changes in an organization. For example, if stakeholders require a deeper review of user-facing application changes, you may need to push routine infrastructure changes faster. Otherwise, your application release process may tie up urgent changes like security patches and minor changes like configuration updates. Testing Infrastructure Before Integrating A risk of applying infrastructure code to shared application development and test environments is that breaking those environments impacts other teams. So it’s a good idea to have delivery stages and environments for testing infrastructure code on their own, before promoting them to shared environments (see Figure 18-11).
This idea is a specific implementation of progressive testing (“Progressive Testing”) and delivery-time project integration (“Pattern: Delivery-Time Project Integration”). Using Infrastructure Code to Deploy Applications Infrastructure code defines what goes onto servers. Deploying an application involves putting things onto servers. So it may seem sensible to write infrastructure code to automate an application’s deployment
process. In practice, mixing the concerns of application deployment and infrastructure configuration becomes messy. The interface between application and infrastructure should be simple and clear. Operating system packaging systems like RPMs, .deb files, and .msi files are a well-defined interface for packaging and deploying applications. Infrastructure code can specify the package file to deploy, then let the deployment tool take over. Trouble comes when deploying an application involves multiple activities, and especially when it involves multiple moving parts. For example, I once wrote a Chef cookbook to deploy my team’s Dropwizard Java applications onto Linux virtual machines. The cookbook needed to: Download and unpack the new application version to a new folder Stop the process for the previous version of the application if it was running Update configuration files if required Update the symlink that points to the current version of the application to the new folder Run database schema migration scripts3 Start the process for the new application version Check that the new process is working correctly This cookbook was troublesome for our team, sometimes failing to detect when the previous process hadn’t terminated, or that the new process crashed a minute or so after starting. Fundamentally, this was a procedural script within a declarative infrastructure codebase. We had more success after deciding to package our applications as RPMs, which meant we could use tools and scripts specifically intended for deploying and upgrading applications. We wrote tests for our RPM packaging
process, which didn’t rely on the rest of our Chef codebase, so we could drill in on the specific issues that made our deployment unreliable. Another challenge with using infrastructure code to deploy applications is when the deployment process requires orchestrating multiple pieces. My team’s process worked fine when deploying our Dropwizard applications to a single server. It wasn’t suitable when we moved to load balancing an application across multiple servers. Even after moving to RPM packages, the cookbooks didn’t manage the deployment order across multiple servers. So the cluster would run mixed application versions during the deployment operation. And the database schema migration script should only run once, so we needed to implement locking to ensure that only the first server’s deployment process would run it. Our solution was to move the deployment operation out of the server configuration code, and into a script that pushed applications onto servers from a central deployment location — our build server. This script managed the order of deployment to servers and database schema migrations, implementing zero-downtime deployment by modifying the load balancer’s configuration for a rolling upgrade.4 Distributed, cloud native applications increase the challenge of orchestrating application deployments. Orchestrating changes to dozens, hundreds, or thousands of application instances can become messy indeed. Teams use deployment tools like Helm or Octopus Deploy to define the deployment of groups of applications. These tools enforce separation of concerns by focusing on deploying the set of applications, leaving the provisioning of the underlying cluster to other parts of the codebase. However, the most robust application deployment strategy is to keep each element loosely coupled. The easier and safer it is to deploy a change independently of other changes, the more reliable the entire system is.

インフラストラクチャとのアプリケーションのテスト
アプリケーションの配信経路にインフラストラクチャの変更を組み込むと、自動化されたアプリケーションのテストを活用することができます。各段階で、インフラストラクチャの変更を適用した後、アプリケーションのテストのステージをトリガーします（図18-10を参照）。プログレッシブなテストのアプローチ（"プログレッシブテスト"）は、統合テストにアプリケーションのテストを使用します。アプリケーションとインフラストラクチャのバージョンを結びつけ、配信時の統合パターン（「パターン：送料時プロジェクト統合」）に従って、残りの配信フローで進めることができます。または、インフラストラクチャの変更を、進行中のアプリケーションの変更と統合せずに、下流の環境にプッシュすることもできます（「パターン：アプライ時プロジェクト統合」を参照）。

アプリケーションとインフラストラクチャの変更をできるだけ迅速に適用することが理想的です。しかし、組織内のすべての種類の変更から摩擦を取り除くことは常に可能とは限りません。たとえば、利害関係者がユーザー向けのアプリケーションの変更により詳細なレビューを要求する場合、ルーチンのインフラストラクチャの変更をより速く押し進める必要があるかもしれません。そうしないと、セキュリティパッチや構成の更新などの緊急の変更がアプリケーションのリリースプロセスに縛られる可能性があります。

統合前のインフラストラクチャのテスト
インフラストラクチャのコードを共有のアプリケーション開発およびテスト環境に適用するリスクは、これらの環境に影響を与えることです。そのためには、共有環境に昇格する前に、テスト用のインフラストラクチャのコードに適用するための配信段階と環境を用意しておくと良いでしょう（図18-11を参照）。

インフラストラクチャのコードを使用してアプリケーションを展開する
インフラストラクチャのコードはサーバーに何を配置するかを定義します。アプリケーションの展開には、サーバーに物事を配置することが含まれます。そのため、アプリケーションの展開プロセスを自動化するために、インフラストラクチャのコードを書くことは合理的に思えるかもしれません。しかし、実際には、アプリケーションの展開とインフラストラクチャの設定の関心を混在させると混乱します。アプリケーションとインフラストラクチャの間のインターフェースはシンプルで明確であるべきです。RPM、.debファイル、.msiファイルなどのオペレーティングシステムのパッケージングシステムは、アプリケーションのパッケージングと展開のための明確なインターフェースです。インフラストラクチャのコードでは、展開するパッケージファイルを指定し、展開ツールに任せることができます。問題は、アプリケーションの展開に複数のアクティビティが関与する場合、特に複数の移動部品が関与する場合に発生します。たとえば、私はかつてチームのDropwizard JavaアプリケーションをLinux仮想マシンに展開するためのChefのクックブックを書きました。そのクックブックは次のようなことをする必要がありました。新しいアプリケーションのバージョンを新しいフォルダにダウンロードして展開する、前のバージョンのアプリケーションのプロセスが実行中の場合は停止する、必要に応じて設定ファイルを更新する、新しいフォルダを指すシンボリックリンクを更新する、データベースのスキーママイグレーションスクリプトを実行する、新しいアプリケーションのバージョンのプロセスを開始する、新しいプロセスが正常に動作していることを確認する

このクックブックはチームにとって問題であり、以前のプロセスが終了していないことや、新しいプロセスが開始してから1分ほどでクラッシュしてしまうことを検出できないことがありました。基本的に、これは宣言的なインフラストラクチャのコードベース内の手続き的なスクリプトでした。私たちはRPMとしてアプリケーションをパッケージ化することを決めた後、成功を収めました。これにより、アプリケーションの展開とアップグレードに特化したツールやスクリプトを使用することができました。私たちはRPMパッケージングプロセスに対してテストを書きましたが、これはChefのコードベースの残りに依存しないものでしたので、展開の信頼性の問題に焦点を当てることができました。

インフラストラクチャのコードを使用してアプリケーションを展開する場合の別の課題は、展開プロセスが複数の要素を組み合わせる必要がある場合です。私たちのチームのプロセスは、単一のサーバーにDropwizardアプリケーションを展開する場合には問題ありませんでした。ただし、複数のサーバーにアプリケーションをロードバランスする場合には適していませんでした。RPMパッケージに移行した後も、クックブックでは複数のサーバー間での展開の順序を管理できませんでした。そのため、展開操作中にクラスターが混合したアプリケーションバージョンを実行してしまいました。また、データベースのスキーママイグレーションスクリプトは1回だけ実行する必要があるため、最初のサーバーの展開プロセスのみが実行するようにロックを実装する必要がありました。私たちの解決策は、サーバーコンフィギュレーションコードから展開操作を外に移し、ビルドサーバーからアプリケーションをサーバーにプッシュするスクリプトに移すことでした。このスクリプトは、展開の順序とデータベースのスキーママイグレーションをサーバーに対して管理し、ローリングアップグレードのためにロードバランサーの設定を変更することでゼロダウンタイム展開を実現しました。

分散型のクラウドネイティブアプリケーションでは、アプリケーションの展開を調整することがさらに困難になります。数十、数百、数千のアプリケーションインスタンスへの変更を調整することは非常に複雑になることがあります。チームは、HelmやOctopus Deployのような展開ツールを使用して、アプリケーションのグループの展開を定義します。これらのツールは、アプリケーションのセットを展開することに焦点を当てることで関心の分離を実現し、基盤となるクラスターのプロビジョニングをコードベースの他の部分に委ねます。しかし、最も堅牢なアプリケーション展開戦略は、各要素を緩く結合したままにしておくことです。他の変更とは独立して変更を展開することが容易かつ安全であればあるほど、システム全体の信頼性が高まります。