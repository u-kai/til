Clusters for Governance One of the benefits of having separate clusters for different parts of the delivery process is that the governance requirements are usually different for different stages in the process. Production has tighter requirements because services running there are the most business-critical, and the data is the most sensitive. Quite often, different parts of a system have different governance and compliance requirements that cut across delivery stages. The most common example is services that handle credit card numbers, which are subject to PCI standards. Other examples include services that deal with customer personal data, which may be subject to regimes such as GDPR. Hosting services that are subject to stricter standards on dedicated clusters can simplify and strengthen compliance and auditing. You can impose stronger controls on these clusters, applications running on them, and delivery of code changes to them. Clusters hosting services with less strict compliance requirements can have streamlined governance processes and controls. As an example, you could have two clusters, one used for development, testing, and production hosting for regulated services, and one for the unregulated services. Or you may split cluster instances by delivery stage and by regulation requirements, as illustrated in Figure 14-12.
Clusters for Teams Yet another factor for organizing multiple clusters is team ownership. Often, different teams are responsible for delivering and running different types of applications and services, which may have different hosting requirements. For example, a team owning customer-facing services may have different requirements for governance and availability than a team that owns services for an internal department. A cluster allocated to a team can be optimized for the requirements of that team and its applications.
Service Mesh A service mesh is a decentralized network of services that dynamically manages connectivity between parts of a distributed system. It moves networking capabilities from the infrastructure layer to the application runtime layer of the model described in “The Parts of an Infrastructure System”. In a typical service mesh implementation, each application instance delegates communication with other instances to a sidecar process (see Figure 14-13).
Some of the services that a service mesh can provide to applications include: Routing Direct traffic to the most appropriate instance of a given application, wherever it is currently running. Dynamic routing with a service mesh enables advanced deployment scenarios, such as blue-green and canary, as described in “Changing Live Infrastructure”. Availability Enforce rules for limiting numbers of requests; for example, circuit breakers. Security Handle encryption, including certificates. Authentication Enforce rules on which services can connect to which. Manage certificates for peer-to-peer authentication. Observability, monitoring, and troubleshooting Record connections and other events so that people can trace requests through complex distributed systems. A service mesh works well in combination with an application hosting cluster. The application cluster dynamically provides compute resources decoupled from lower-level resources. The service mesh dynamically manages application communication decoupled from lower-level networking resources. The benefits of this model are: It simplifies application development, by moving common concerns out of the application and into the sidecar. It makes it easier to build and improve common concerns across your estate, since you only need to deploy updates to the sidecar, without needing to make code changes to all of your applications and services. It handles the dynamic nature of application deployment, since the same orchestration and scheduling system that deploys and configures application instances (e.g., in containers) can deploy and configure the sidecar instances along with them. Some examples of service meshes include HashiCorp Consul, Envoy, Istio, and Linkerd. Service meshes are most commonly associated with containerized systems. However, you can implement the model in noncontainerized systems; for example, by deploying sidecar processes onto virtual machines. A service mesh adds complexity. As with cloud native architectural models like microservices, a service mesh is appealing because it simplifies the development of individual applications. However, the complexity does not disappear; you’ve only moved it out into the infrastructure. So your organization needs to be prepared to manage this, including being ready for a steep learning process.
It’s essential to keep clear boundaries between networking implemented at the infrastructure level, and networking implemented in the service mesh. Without a good design and implementation discipline, you may duplicate and intermingle concerns. Your system is harder to understand, riskier to change, and harder to troubleshoot.
ガバナンスのためのクラスター
配信プロセスの異なる部分ごとに別々のクラスターを持つ利点の一つは、プロセスの異なる段階で通常異なるガバナンス要件があることです。プロダクションでは、実行されているサービスが最もビジネスに重要であり、データが最も機密性が高いため、より厳格な要件があります。しばしば、システムのさまざまな部分には、デリバリーステージを横断する異なるガバナンスとコンプライアンスの要件があります。最も一般的な例は、PCI基準に準拠するクレジットカード番号を処理するサービスです。その他の例には、GDPRなどの規制の対象となる顧客の個人データを扱うサービスがあります。専用クラスターに厳格な基準が適用されるホスティングサービスを利用することで、コンプライアンスと監査を簡素化し強化することができます。これらのクラスターやそれらで実行されるアプリケーション、コード変更のデリバリーには、より強力な制御を課すことができます。より制約の緩いコンプライアンス要件を持つクラスターは、簡素化されたガバナンスのプロセスと制御を持つことができます。例えば、開発、テスト、規制されたサービスのプロダクションホスティングのために使用される1つのクラスターと、規制されていないサービスのためのもう1つのクラスターを用意することができます。または、デリバリーステージと規制要件ごとにクラスターインスタンスを分割することもできます（図14-12参照）。

チームの所有権のためのクラスター
複数のクラスターを組織するためのもう一つの要素は、チームの所有権です。異なるチームは通常、異なる種類のアプリケーションやサービスを提供および実行する責任を持っており、異なるホスティングの要件がある場合があります。例えば、顧客向けサービスを所有するチームは、内部部署向けのサービスを所有するチームとは異なるガバナンスと可用性の要件を持つ場合があります。チームに割り当てられたクラスターは、そのチームとそのアプリケーションの要件に合わせて最適化することができます。

サービスメッシュ
サービスメッシュは、分散システムのパーツ間の接続性を動的に管理する分散ネットワークのことです。それは「インフラストラクチャシステムのパーツ」で説明されているモデルのインフラストラクチャレイヤからアプリケーションランタイムレイヤまでのネットワーキング機能を移動します。典型的なサービスメッシュの実装では、各アプリケーションインスタンスは他のインスタンスとの通信をサイドカープロセスに委任します（図14-13参照）。

サービスメッシュがアプリケーションに提供できるサービスの一部には以下があります：ルーティング、現在の実行場所に関係なく、指定されたアプリケーションの最適なインスタンスにトラフィックを直接送信します。サービスメッシュによる動的なルーティングは、ブルーグリーンやキャナリーなどの高度なデプロイシナリオを可能にします。可用性は、要求数を制限するルールを適用します。例えば、サーキットブレーカーです。セキュリティは、証明書を含む暗号化を処理します。認証は、どのサービスがどのサービスに接続できるかに関するルールを強制します。ピア間認証のための証明書を管理します。観測、モニタリング、トラブルシューティングは、コネクションやその他のイベントを記録するため、複雑な分散システムでリクエストを追跡できるようにします。サービスメッシュは、アプリケーションホスティングクラスターとの組み合わせでうまく機能します。アプリケーションクラスターは、下位のリソースから切り離された計算リソースを動的に提供します。サービスメッシュは、下位のネットワーキングリソースから切り離されたアプリケーション間の通信を動的に管理します。このモデルの利点は次のとおりです：共通の関心事をアプリケーションからサイドカープロセスに移動することにより、アプリケーション開発を簡素化します。アプリケーションとサービス全体のコードを変更する必要がなく、エステート全体で共通の関心事を構築および改善することが容易になります。アプリケーションインスタンス（たとえばコンテナ内のもの）をデプロイおよび構成するオーケストレーションおよびスケジューリングシステムは、同じシステムがサイドカーインスタンスもデプロイおよび構成できるため、アプリケーションデプロイメントの動的な性質を扱うことができます。サービスメッシュの例には、HashiCorp Consul、Envoy、Istio、Linkerdなどがあります。サービスメッシュは、主にコンテナ化システムと関連付けられています。ただし、仮想マシンにサイドカープロセスをデプロイすることなど、ノンコンテナ化システムでもこのモデルを実装することができます。サービスメッシュは複雑さを追加します。マイクロサービスなどのクラウドネイティブなアーキテクチャモデルと同様に、サービスメッシュは個々のアプリケーションの開発を簡素化するため魅力的です。ただし、複雑さはなくなるわけではありません。複雑さはインフラストラクチャに移動するだけです。そのため、組織はこれを管理する準備が整っている必要があります。急激な学習過程にも対応している必要があります。

インフラストラクチャレベルで実装されているネットワーキングとサービスメッシュで実装されているネットワーキングの間には明確な境界を保つことが重要です。適切な設計と実装の原則がなければ、重複や互い混ざり合い、詳細が理解しにくくなり、変更のリスクが高まり、トラブルシューティングが困難になります。