Pushing Incomplete Changes to Production How can you deliver a significant change to your production system as a series of small, incremental changes while keeping the service working? Some of those small changes may not be useful on their own. It may not be practical to remove existing functionality until the entire set of changes is complete. “Example of Refactoring” showed two incremental steps, extracting a container cluster from one stack into its own stack, and then replacing the cluster solution within the new stack. Each of these steps is large, so would probably be implemented as a series of smaller code pushes. However, many of the smaller changes would make the cluster unusable on its own. So you need to find ways to make those smaller changes while keeping the existing code and functionality in place. There are different techniques you can use, depending on the situation. Parallel Instances The second step of the cluster replacement example starts with the original container solution in its own stack, and ends with the new container solution (see Figure 21-6).
The existing solution is a packaged Kubernetes distribution called KubeCan.4 The team is switching to FKS, a managed cluster service provided by its cloud platform.5 See “Application Cluster Solutions” for more on clusters as a service and packaged cluster distributions. It isn’t practical to turn the KubeCan cluster into an FKS cluster in small steps. But the team can run the two clusters in parallel. There are a few different ways to run the two different container stacks in parallel with a single instance of the original stack. One option is to have a parameter for the main stack to choose which cluster stack to integrate with (see Figure 21-7).
With this option, one of the stacks is enabled and will handle live workloads. The second stack is disabled but still present. The team can test the second stack in a fully operational environment, exercise and develop its delivery pipeline and test suite, and integrate it with other parts of the infrastructure in each environment. Why Extract the Old Container Solution at All? Considering that we’ve ended up creating a standalone stack with the new container solution, we arguably could have skipped the step of extracting the old solution into its own stack. We could have just created the new stack with the new solution from scratch. By extracting the old solution, it’s easier to make sure our new solution matches the old solution’s behavior. The extracted stack clearly defines how the cluster integrates with other infrastructure. By using the extracted stack in production, we guarantee the integration points are correct. Adding automated tests and a new pipeline for the extracted stack ensures that we find out immediately when one of our changes breaks something. If we leave the old cluster solution in the original stack and build the new one separately, swapping it out will be disruptive. We won’t know until the end if we’ve made an incompatible design or implementation decision. It would take time to integrate the new stack with other parts of the infrastructure, and to test, debug, and fix problems. Another option is to integrate both stacks with the main stack (see Figure 21-8).
With this arrangement, you can direct part of your workload to each of the cluster stacks. You can divide the workload in different ways: Workload percentage Direct part of the workload to each stack. Usually, the old stack handles most of the load at first, with the new stack taking a small percentage to evaluate how well it works. As the new stack beds in, you can dial the load up over time. After the new stack successfully manages 100% of the load and everyone is ready, you can decommission the old stack. This option assumes the new stack has all of the capabilities of the old stack, and that there aren’t any issues with data or messaging being split across the stacks. Service migration Migrate services one by one to the new cluster. Workloads in the main stack, such as network connections or messages, are directed to whichever stack instance the relevant service is running on. This option is especially useful when you need to modify service applications to move them to the new stack. It often requires more complex integration, perhaps even between the old and new cluster stacks. This complexity may be justified for migrating a complex service portfolio.6 User partitioning In some cases, different sets of users are directed to different stack implementations. Testers and internal users are often the first group. They can conduct exploratory tests and exercise the new system before risking “real” customers. In some cases, you might follow this by giving access to customers who opt-in to alpha testing or preview services. These cases make more sense when the service running on the new stack has changes that users will notice. Running new and old parts of the system conditionally, or in parallel, is a type of branch by abstraction. Progressively shifting portions of a workload onto new parts of a system is a canary release. Dark launching describes putting a new system capability into production, but not exposing it to production workloads, so your team can test it.

不完全な変更を本番環境にプッシュする方法はありますか？サービスが動作したままで、一連の小さな、段階的な変更として大きな変更を本番システムに提供する方法はありますか？これらの小さな変更の中には単体では有用ではないものもあります。一連の変更が完了するまで既存の機能を削除することは実用的ではないかもしれません。 「リファクタリングの例」では、コンテナクラスタを1つのスタックから別のスタックに抽出し、その後、新しいスタック内のクラスタソリューションを置換するという2つの段階的なステップが示されています。これらの各ステップは大きいため、おそらく一連の小さなコードプッシュとして実装されるでしょう。ただし、多くの小さな変更は、コンテナクラスタを単独では使用できなくする可能性があります。したがって、既存のコードと機能を維持しながらこれらの小さな変更を行う方法を見つける必要があります。具体的な状況に応じて使用できるさまざまな技術があります。

並列インスタンス
クラスタ置換の例の2番目のステップでは、元のコンテナソリューションを独立したスタックで開始し、新しいコンテナソリューションで終了します（図21-6を参照）。
既存のソリューションは、KubeCanと呼ばれるパッケージ化されたKubernetesディストリビューションです。チームはそれを自社のクラウドプラットフォームで提供される管理クラスタサービスであるFKSに切り替えています。クラスタを小さなステップでFKSクラスタにすることは実用的ではありませんが、チームは両方のクラスタを並列して実行することができます。2つの異なるコンテナスタックを元のスタックの単一のインスタンスと並行して実行するためのいくつかの異なる方法があります。一つのオプションは、メインスタックにクラスタスタックを統合するためのパラメータを持つことです（図21-7を参照）。
このオプションでは、2つのスタックのうち1つが有効になり、ライブのワークロードを処理します。2番目のスタックは無効になっていますが、まだ存在しています。チームは、第二のスタックを完全に動作する環境でテストし、デリバリーパイプラインとテストスイートを試験し、各環境の他のインフラストラクチャと統合することができます。

なぜ古いコンテナソリューションを抽出するのですか？新しいコンテナソリューションが含まれたスタンドアロンのスタックを作成したことを考えると、古いソリューションを独自のスタックに抽出する手順をスキップすることもできます。新しいソリューションが古いソリューションの動作と一致するようにするのはより簡単です。抽出されたスタックは、クラスタが他のインフラストラクチャと統合する方法を明確に定義しています。抽出されたスタックを本番環境で使用することで、統合ポイントが正しいことを保証します。抽出されたスタックに対して自動化されたテストと新しいパイプラインを追加することで、私たちの変更が何かを壊した場合にすぐに気付くことができます。古いクラスタソリューションを元のスタックに残して新しいクラスタソリューションを個別にビルドすると、交換が中断されます。互換性のない設計や実装の決定があったかどうかは最後までわかりません。新しいスタックをインフラストラクチャの他の部分と統合し、問題をテスト、デバッグ、修正するには時間がかかります。
もう1つのオプションは、両方のスタックを主スタックに統合することです（図21-8を参照）。
この配置では、ワークロードの一部をクラスタスタックごとに指示することができます。ワークロードを異なる方法で分割することができます。
- ワークロードの割合：ワークロードの一部を各スタックに指示します。通常、最初は古いスタックが大部分の負荷を処理し、新しいスタックがうまく機能するかどうかを評価するために一部の負荷を含めます。新しいスタックが100％の負荷を正常に処理し、準備が整ったら、古いスタックを廃止できます。
- サービスの移行：1つずつサービスを新しいクラスタに移行します。ネットワーク接続やメッセージなどのメインスタックのワークロードは、関連するサービスが実行されているスタックインスタンスに指示されます。このオプションは、サービスアプリケーションを変更して新しいスタックに移動する必要がある場合に特に有用です。古いクラスタスタックと新しいクラスタスタックの間で継続的な統合が必要な場合もあります。これは、複雑なサービスポートフォリオの移行には正当化されるかもしれません。
- ユーザーパーティショニング：一部の場合、異なるユーザーセットを異なるスタック実装に指示することができます。テスターや内部ユーザーが最初のグループとなることがよくあります。彼らは、リアルの顧客をリスクに晒す前に新しいシステムを試して検証することができます。場合によっては、アルファテストやプレビューサービスに参加したい顧客にアクセスを提供したりすることもあります。これらの場合は、新しいスタックで実行されるサービスにユーザーが気づく変更がある場合により意味があります。新しい部分と古い部分のシステムを条件付きまたは並列に実行することは、「分岐による抽象化」の一種です。ワークロードの一部をシステムの新しい部分に段階的にシフトすることはカナリアリリースと呼ばれます。新しいシステムの機能を本番ワークロードに公開せずに導入することをダークランチングと呼びます。このように、チームはそれをテストすることができます。