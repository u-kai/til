- Service Pipeline と Environment Pipeline があるよね
- Service Pipeline を異なるサービス間である程度共通化できると様々なタスクを節約できるのでいいよね
- 一つの ServicePipeline に複数の Service を紐づけることは、サービスのアジリティを損なうのでやめた方がいい
- Service Pipeline の役目はソースコードをデプロイ可能な状態に変換すること
- 疑問

  - アーティファクトリポジトリとコンテナリポジトリは違う？
  - バイナリ作ってからコンテナに入れる？
    - 確かにこれだと早い気もするけど,Dockerfile のなかでマルチステージビルドのようにしないとコンテナの一貫性が落ちるのでは？

- Service Pipeline のなかで k8s のリントをしているけど、この本では service 用のレポジトリと manifest 用のリポジトリはわけない感じなのか？
  - それとも分けた上で同じ pipeline でやるのか？
- OSS とかめっちゃでかい組織の中であれば HELM のようなパッケージマネージャーを使ってパッケージ化するのがいいけど、小さいチームで自分たちのサービスを自分たちの環境で試したい人が少ないのであれば YAML のままがいいらしい

  - まあそうやろな

- 全部がうまくいったらそのサービスが気になる人たちに通知を行う
  - これは顧客とかではなく、そのサービスの QA とか？それとも、このサービスに依存している他のサービス開発者？
- Pipeline を通過したらそれはリリース可能ってことだから Version を tag としてつけるの良い
- feature ブランチの pull request を契機にして feature branch に対して pipeline を実行するのが良いとされる
- feature branch の service pipeline で作られるのは統合テストに利用できるリリース前のアーティファクト??
- main branch の service pipeline は他のチームがデプロイ可能なリリースを作成する？

- 正確には二つのわずかに違う pipline がある
  - Validate a change in a feature branch
    - main branch と同じようなステップを pipeline で実行するけど、アーティファクトにブランチの名前をヴァージョンかアーティファクトの名前の一部につける
      - 変更全てに対して pipeline を実行するのは時間がかかるので、必要なステップだけを実行する??
        - 変更パスとかの話をしているのか？
  - Validate a pull request/change request
    - pull request が正当か、最新の変更から生成されたアーティファクトかを検証する??
    - feature branch で全ての変更に対して pipeline が実行されるのを防ぐための素晴らしいオプションが validate pull request??
      - そもそも失敗する pull request に対して pipeline を実行せずに済むからって感じ？
- これらはあんまり具体が理解できてない
- これらはテストがしっかりできていることが前提ではある
- Pipeline で必要な機能は、
  - webhook でのトリガー
  - artifact repository へのアップロードが可能であること
    - これって container 使う場合でも必要なんか？
    - 図では build and test の後に artifact repository に対して push している
    - これは何？
  - container registry へのアップロードが可能であること
  - helm repository へのアップロードが可能であること
- リポジトリに dockerfile も manifest も必要だよねって書いてあるけど、リポジトリって分離しないのがこの本の主張なんか？

- Service Pipeline で考慮すること

  - 厳密なステップは避けるべし

    - 例で言うと Helm を使うべきでない時に helm のステップをわざわざ入れるのはよくないよね的な
    - ってことは binary の artifact もいらんってことなんかな？

  - サービスの構成要素のライフサイクルを理解する
    - 変更が早いものと遅いものを分ければうまく成長できるよね的なことだと思う
  - 組織にとって何が良いのかを見つける

    - 最適化するものには最適化した方が良いよね？って感じ
    - 重要なサービスによってリリースとデプロイの遅延が発生している場合は他のサービスをカバーする前にサービスパイプラインの準備をして完全に機能させることに重点を置く
    - １つのサービスで組織の 80％のケースが問題になっていることを

  - いらんもんは作るな
    - helm を紹介し続けているけど、必要ないのであればそのためのステップを作る必要はないよね

- Tekton の優位性など

  - めっちゃ柔軟
  - 先進的な pipeline を作ることができる
  - task 間でデータの受け渡しができる
  - event trigger のおかげで event を取得できる
  - dashboard とか CLI があるものもいいよね

- ただめっちゃ task や pipeline の定義などに時間を費やすことになるかも

  - そのため tekton では catalog みたいなものをだして、共通のものを share するようにしている
  - だから 1 から定義することを心配しないでも良いよ

- Tekton はかなり成熟したプロジェクトだけどそれなりにチャンレンジはあるよ

  - k8s cluster に tekton をインストールする必要も管理する必要もある
  - もし、アプリケーションワークロードと分離したいのであればクラスターを分けることがいいよね
  - tekton をローカルで動かすのは簡単ではない
    - 開発の目的では k8s に手動で触れることに依存するかも？？
    - tekton を使うのであれば YAML で表現できる宣言的なアプローチに限られる

- Dagger は Tekton を置き換えるものではないけど、違うモチベーションで生まれている
- Dagger は好きなプログラミング言語でどこでも動くパイプラインを開発者が構築可能にしたもの
- Dagger は k8s に依存しない
- ローカルでもリモートでも動く
  - おそらく Dagger Runtime が必要？
- CRD とか YAML がいらないので開発者は Dagger の Pipeline だけを気にすればよくなる
- Dagger が OCI 準拠のコンテナランタイムを動かしているように見えるので、Dagger は一種のコンテナオーケストレーションツールって感じか？

- local でできることは強い

  - 逆に言うと k8s でも勝手に開発できるローカルのような環境を用意すればよくね？

- Dagger は k8s でも実行できるし、キャッシュもできるのでそこら辺も賢い

  - Dagger の Pipeline Engine が k8s クラスター上でインストールされるらしい
  - k8s 意外にも VM とでも OK らしい

- k8s の全て Yaml で宣言するって言うアプローチからは Dagger は外れる
- ここら辺は開発に期待

- GitHubActions だとコストがかかるとか、クラウド利用の規制がある場合は無理みたいな？
- 変更したところを見て動かす Pipeline とかを決めることもできるけど、一つのサービスにつき一つのリポジトリにしておけば、そういう煩わしさも無くなるので、リポジトリは分割した方が良いのでは？
  - でも、これってめっちゃリポジトリできんか？
  - サービスって何？アーキテクチャ量子とはまた違うと思うんだけど、そうなるとサービスの中に多くのアーキテクチャ量子ができてきもおかしくない気がしてる
  - そうなるとまあ、そこそこ一つのリポジトリにもデプロイする単位のサービスはあるのかな？
  - それかアーキテクチャ量子ごとにリポジトリ切りなさい、であれば相当の数のリポジトリが乱立する気もする
